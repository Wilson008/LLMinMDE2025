@inproceedings{10.1145/3670474.3685948,
author = {Batten, Christopher and Pinckney, Nathaniel and Liu, Mingjie and Ren, Haoxing and Khailany, Brucek},
title = {PyHDL-Eval: An LLM Evaluation Framework for Hardware Design Using Python-Embedded DSLs},
year = {2024},
isbn = {9798400706998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670474.3685948},
doi = {10.1145/3670474.3685948},
abstract = {Embedding hardware design frameworks within Python is a promising technique to improve the productivity of hardware engineers. At the same time, there is significant interest in using large-language models (LLMs) to improve key chip design tasks. This paper describes PyHDL-Eval, a new framework for evaluating LLMs on specification-to-RTL tasks in the context of Python-embedded domain-specific languages (DSLs). The framework includes 168 problems, Verilog reference solutions, Verilog test benches, Python test scripts, and workflow orchestration scripts. We use the framework to conduct a detailed case study comparing five LLMs (CodeGemma 7B, Llama3 8B/70B, GPT4, and GPT4 Turbo) targeting Verilog and five Python-embedded DSLs (PyMTL3, PyRTL, MyHDL, Migen, and Amaranth). Our results demonstrate the promise of in-context learning when applied to smaller models (e.g., pass rate for CodeGemma 7B improves from 14.9\% to 32.7\% on Verilog) and Python-embedded DSLs (e.g., pass rate for LLama3 70B improves from 0.6\% to 33.0\% on PyMTL3). We find LLMs perform better when targeting Verilog as compared to Python-embedded DSLs (e.g., pass rate for GPT4 Turbo is 72.2\% on Verilog and 29.8-62.0\% on the Python-embedded DSLs) despite using a popular general-purpose host language. PyHDL-Eval will serve as a useful framework for future research at the intersection of Python-embedded DSLs and LLMs.},
booktitle = {Proceedings of the 2024 ACM/IEEE International Symposium on Machine Learning for CAD},
articleno = {10},
numpages = {17},
keywords = {Python-embedded domain-specific languages, hardware description languages, large language models},
location = {Salt Lake City, UT, USA},
series = {MLCAD '24}
}

@inbook{10.1145/3728725.3728757,
author = {Xia, Weiyi and Zhang, Yinggang and Zhao, Ben and Liu, Wei and Han, Linjie and Ye, Qifu},
title = {Intelligent PLC Code Generation in HCPS 2.0: A Multi-dimensional Taxonomy and Evolutionary Framework},
year = {2025},
isbn = {9798400713453},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3728725.3728757},
abstract = {The manufacturing industry is accelerating towards the New-Generation Intelligent Manufacturing, where the automatic generation of Programmable Logic Controllers (PLCs) code serves as a key technology, crucial for enhancing the intelligence and efficiency of manufacturing systems. Traditional manual programming has become increasingly inadequate to meet the demands for flexibility and real-time performance in intelligent manufacturing. This paper reviews the integration of intelligent manufacturing and PLC technologies, highlighting the core role of Human-Cyber-Physical Systems (HCPS) and demonstrating how it effectively guides theoretical research and engineering practices in new-generation intelligent manufacturing. We innovatively classify automatic PLC code generation methods through multiple dimensions and propose a new framework for Structured Text (ST) code generation. Finally, this paper discusses future trends in controller code generation, identifying multimodal-driven intelligent generation, adaptive learning and real-time optimization, and cloud-edge collaborative intelligent generation as significant directions, forming a technical roadmap of "parallel promotion and integrated development" to support comprehensive intelligent transformation and upgrading of manufacturing.},
booktitle = {Proceedings of the 2025 2nd International Conference on Generative Artificial Intelligence and Information Security},
pages = {202–212},
numpages = {11}
}

@inproceedings{10.1145/3639474.3640084,
author = {Sa\u{g}lam, Timur and Hahner, Sebastian and Schmid, Larissa and Burger, Erik},
title = {Automated Detection of AI-Obfuscated Plagiarism in Modeling Assignments},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640084},
doi = {10.1145/3639474.3640084},
abstract = {Plagiarism is a widespread problem in computer science education, exacerbated by the impracticability of manual inspection in large courses. Even worse, tools based on large language models like ChatGPT have made it easier than ever to obfuscate plagiarized solutions. Additionally, most plagiarism detectors only apply to code, and only a few approaches exist for modeling assignments, which lack broad resilience to obfuscation attacks. This paper presents a novel approach for automated plagiarism detection in modeling assignments that combines automated analysis with human inspection. We evaluate our approach with real-world assignments and plagiarism obfuscated by ChatGPT. Our results show that we achieve a significantly higher detection rate for AI-generated attacks and a broader resilience than the state-of-the-art.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {297–308},
numpages = {12},
keywords = {plagiarism detection, obfuscation, ChatGPT, artificial intelligence},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@article{10.1145/3357334,
author = {Saini, Naveen and Saha, Sriparna and Bhattacharyya, Pushpak and Tuteja, Himanshu},
title = {Textual Entailment--Based Figure Summarization for Biomedical Articles},
year = {2020},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1s},
issn = {1551-6857},
url = {https://doi.org/10.1145/3357334},
doi = {10.1145/3357334},
abstract = {This article proposes a novel unsupervised approach (FigSum++) for automatic figure summarization in biomedical scientific articles using a multi-objective evolutionary algorithm. The problem is treated as an optimization problem where relevant sentences in the summary for a given figure are selected based on various sentence scoring features (or objective functions), such as the textual entailment score between sentences in the summary and a figure’s caption, the number of sentences referring to that figure, semantic similarity between sentences and a figure’s caption, and the number of overlapping words between sentences and a figure’s caption. These objective functions are optimized simultaneously using multi-objective binary differential evolution (MBDE). MBDE consists of a set of solutions, and each solution represents a subset of sentences to be selected in the summary. MBDE generally uses a single differential evolution variant, but in the current study, an ensemble of two different differential evolution variants measuring diversity among solutions and convergence toward global optimal solution, respectively, is employed for efficient search. Usually, in any summarization system, diversity among sentences (called anti-redundancy) in the summary is a very critical feature, and it is calculated in terms of similarity (like cosine similarity) among sentences. In this article, a new way of measuring diversity in terms of textual entailment is proposed. To represent the sentences of the article in the form of numeric vectors, the recently proposed BioBERT pre-trained language model in biomedical text mining is utilized. An ablation study has also been presented to determine the importance of different objective functions. For evaluation of the proposed technique, two benchmark biomedical datasets containing 91 and 84 figures are considered. Our proposed system obtains 5\% and 11\% improvements in terms of the F-measure metric over two datasets, compared to the state-of-the-art unsupervised methods.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = apr,
articleno = {35},
numpages = {24},
keywords = {Figure-assisted text summarization, evolutionary computing, multi-objective optimization (MOO), textual entailment}
}

@article{10.1145/3571226,
author = {Cambronero, Jos\'{e} and Gulwani, Sumit and Le, Vu and Perelman, Daniel and Radhakrishna, Arjun and Simon, Clint and Tiwari, Ashish},
title = {FlashFill++: Scaling Programming by Example by Cutting to the Chase},
year = {2023},
issue_date = {January 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {POPL},
url = {https://doi.org/10.1145/3571226},
doi = {10.1145/3571226},
abstract = {Programming-by-Examples (PBE) involves synthesizing an "intended program" from a small set of user-provided input-output examples. A key PBE strategy has been to restrict the search to a carefully designed small domain-specific language (DSL) with "effectively-invertible" (EI) operators at the top and "effectively-enumerable" (EE) operators at the bottom. This facilitates an effective combination of top-down synthesis strategy (which backpropagates outputs over various paths in the DSL using inverse functions) with a bottom-up synthesis strategy (which propagates inputs over various paths in the DSL). We address the problem of scaling synthesis to large DSLs with several non-EI/EE operators. This is motivated by the need to support a richer class of transformations and the need for readable code generation. We propose a novel solution strategy that relies on propagating fewer values and over fewer paths.    Our first key idea is that of "cut functions" that prune the set of values being propagated by using knowledge of the sub-DSL on the other side. Cuts can be designed to preserve completeness of synthesis; however, DSL designers may use incomplete cuts to have finer control over the kind of programs synthesized. In either case, cuts make search feasible for non-EI/EE operators and efficient for deep DSLs. Our second key idea is that of "guarded DSLs" that allow a precedence on DSL operators, which dynamically controls exploration of various paths in the DSL. This makes search efficient over grammars with large fanouts without losing recall. It also makes ranking simpler yet more effective in learning an intended program from very few examples. Both cuts and precedence provide a mechanism to the DSL designer to restrict search to a reasonable, and possibly incomplete, space of programs.    Using cuts and gDSLs, we have built FlashFill++, an industrial-strength PBE engine for performing rich string transformations, including datetime and number manipulations. The FlashFill++ gDSL is designed to enable readable code generation in different target languages including Excel's formula language, PowerFx, and Python. We show FlashFill++ is more expressive, more performant, and generates better quality code than comparable existing PBE systems. FlashFill++ is being deployed in several mass-market products ranging from spreadsheet software to notebooks and business intelligence applications, each with millions of users.},
journal = {Proc. ACM Program. Lang.},
month = jan,
articleno = {33},
numpages = {30},
keywords = {domain-specific languages, programming by example, string transformations}
}

@inproceedings{10.1145/3658271.3658342,
author = {Albuquerque, Beatriz Ventorini Lins de and Cunha, Antonio Fernando Souza da and Souza, Leonardo and Siqueira, Sean Wolfgand Matsui and Santos, Rodrigo Pereira dos},
title = {Generating and Reviewing Programming Codes with Large Language Models: A Systematic Mapping Study},
year = {2024},
isbn = {9798400709968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658271.3658342},
doi = {10.1145/3658271.3658342},
abstract = {Context: The proliferation of technologies based on Large Language Models (LLM) is reshaping various domains, also impacting on programming code creation and review. Problem: The decision-making process in adopting LLM in software development demands an understanding of associated challenges and diverse application possibilities. Solution: This study addresses the identified challenges linked to LLM utilization in programming code processes. It explores models, utilization strategies, challenges, and coping mechanisms, focusing on the perspectives of researchers in software development. IS Theory: Drawing on Task-Technology Fit (TTF) theory, the research examines the alignment between task characteristics in code generation and review, and LLM technology attributes to discern performance impacts and utilization patterns. Method: Employing the Systematic Mapping of the Literature method, the research analyzes 19 selected studies from digital databases—IEEE Digital Library, Compendex Engineering Village, and Scopus—out of 1,257 retrieved results. Summary of Results: The research reveals 23 models, 13 utilization strategies, 15 challenges, and 14 coping mechanisms associated with LLM in programming code processes, offering a comprehensive understanding of the application landscape. Contributions to IS: Contributing to the Information Systems (IS) field, This study provides valuable insights into the utilization of LLM in programming code generation and review. The identified models, strategies, challenges, and coping mechanisms offer practical guidance for decision-making processes related to LLM technology adoption. The research aims to support the IS community in effectively navigating the complexities of integrating large language models into the dynamic software development lifecycle.},
booktitle = {Proceedings of the 20th Brazilian Symposium on Information Systems},
articleno = {70},
numpages = {10},
keywords = {Code Generation, LLM, automatic refactoring, code auto-suggestion, code completion, natural language models, neural network, systematic mapping study, transformer architecture},
location = {Juiz de Fora, Brazil},
series = {SBSI '24}
}

@inproceedings{10.1145/3715336.3735798,
author = {Boecking, Nils Wakan and Azari Gargari, Parastou and Reichel, Sarah and Hoffmann, Sven and Richter, Tobias and Wulf, Volker},
title = {Chat with Standards: An Assistant for the Provision of Normative Knowledge for Practical Use in Welding},
year = {2025},
isbn = {9798400714856},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3715336.3735798},
doi = {10.1145/3715336.3735798},
abstract = {Standards form an important basis for the manufacture of high-quality and safe products. As the standards landscape becomes more complex over time, the mandatory interpretation is becoming increasingly challenging and knowledge gained from experience in dealing with the standards plays a key role. This paper uses welding—as a manufacturing process that is highly regulated by standards—to demonstrate the possibilities that large language models (LLMs) offer to assist people and shows how knowledge management can be supported in applying these standards. Therefore, a chatbot prototype specialising in the specific requirements of welding standards was developed and evaluated on the methodological framework of a design case study. The results show that LLMs have the potential to improve access to complex standards beyond simple databases and document searches and facilitate compliance with these requirements. However, there are certain limitations regarding normative language and the need for referencing.},
booktitle = {Proceedings of the 2025 ACM Designing Interactive Systems Conference},
pages = {2171–2188},
numpages = {18},
keywords = {Chatbot, Standards, Welding, Knowledge Management, User Study},
location = {
},
series = {DIS '25}
}

@inproceedings{10.1145/3503222.3507778,
author = {Jangda, Abhinav and Huang, Jun and Liu, Guodong and Sabet, Amir Hossein Nodehi and Maleki, Saeed and Miao, Youshan and Musuvathi, Madanlal and Mytkowicz, Todd and Saarikivi, Olli},
title = {Breaking the computation and communication abstraction barrier in distributed machine learning workloads},
year = {2022},
isbn = {9781450392051},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503222.3507778},
doi = {10.1145/3503222.3507778},
abstract = {Recent trends towards large machine learning models require both training and inference tasks to be distributed. Considering the huge cost of training these models, it is imperative to unlock optimizations in computation and communication to obtain best performance. However, the current logical separation between computation and communication kernels in machine learning frameworks misses optimization opportunities across this barrier. Breaking this abstraction can provide many optimizations to improve the performance of distributed workloads. However, manually applying these optimizations requires modifying the underlying computation and communication libraries for each scenario, which is both time consuming and error-prone.  Therefore, we present CoCoNet, which contains (i) a domain specific language to express a distributed machine learning program in the form of computation and communication operations, (ii) a set of semantics preserving transformations to optimize the program, and (iii) a compiler to generate jointly optimized communication and computation GPU kernels. Providing both computation and communication as first class constructs allows users to work on a high-level abstraction and apply powerful optimizations, such as fusion or overlapping of communication and computation. CoCoNet enabled us to optimize data-, model- and pipeline-parallel workloads in large language models with only a few lines of code. Our experiments show that CoCoNet significantly outperforms state-of-the-art distributed machine learning implementations.},
booktitle = {Proceedings of the 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {402–416},
numpages = {15},
keywords = {CUDA, Code Generation, Collective Communication, Compiler Optimizations, Distributed Machine Learning, MPI},
location = {Lausanne, Switzerland},
series = {ASPLOS '22}
}

@inproceedings{10.1145/3583780.3614812,
author = {Askari, Arian and Aliannejadi, Mohammad and Abolghasemi, Amin and Kanoulas, Evangelos and Verberne, Suzan},
title = {CLosER: Conversational Legal Longformer with Expertise-Aware Passage Response Ranker for Long Contexts},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3614812},
doi = {10.1145/3583780.3614812},
abstract = {In this paper, we investigate the task of response ranking in conversational legal search. We propose a novel method for conversational passage response retrieval (ConvPR) for long conversations in domains with mixed levels of expertise. Conversational legal search is challenging because the domain includes long, multi-participant dialogues with domain-specific language. Furthermore, as opposed to other domains, there typically is a large knowledge gap between the questioner (a layperson) and the responders (lawyers), participating in the same conversation. We collect and release a large-scale real-world dataset called LegalConv with nearly one million legal conversations from a legal community question answering (CQA) platform. We address the particular challenges of processing legal conversations, with our novel Conversational Legal Longformer with Expertise-Aware Response Ranker, called CLosER. The proposed method has two main innovations compared to state-of-the-art methods for ConvPR: (i) Expertise-Aware Post-Training; a learning objective that takes into account the knowledge gap difference between participants to the conversation; and (ii) a simple but effective strategy for re-ordering the context utterances in long conversations to overcome the limitations of the sparse attention mechanism of the Longformer architecture. Evaluation on LegalConv shows that our proposed method substantially and significantly outperforms existing state-of-the-art models on the response selection task. Our analysis indicates that our Expertise-Aware PostTraining, i.e., continued pre-training or domain/task adaptation, plays an important role in the achieved effectiveness. Our proposed method is generalizable to other tasks with domain-specific challenges and can facilitate future research on conversational search in other domains.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {25–35},
numpages = {11},
keywords = {conversational legal search, conversational search for long context, response ranking in legal domain},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@article{10.1145/3702987,
author = {Zhang, Sai and Xing, Zhenchang and Guo, Ronghui and Xu, Fangzhou and Chen, Lei and Zhang, Zhaoyuan and Zhang, Xiaowang and Feng, Zhiyong and Zhuang, Zhiqiang},
title = {Empowering Agile-Based Generative Software Development through Human-AI Teamwork},
year = {2025},
issue_date = {July 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {6},
issn = {1049-331X},
url = {https://doi.org/10.1145/3702987},
doi = {10.1145/3702987},
abstract = {In software development, the raw requirements proposed by users are frequently incomplete, which impedes the complete implementation of software functionalities. With the emergence of large language models, the exploration of generating software through user requirements has attracted attention. Recent methods with the top-down waterfall model employ a questioning approach for requirement completion, attempting to explore further user requirements. However, users, constrained by their domain knowledge, result in a lack of effective acceptance criteria during the requirement completion, failing to fully capture the implicit needs of the user. Moreover, the cumulative errors of the waterfall model can lead to discrepancies between the generated code and user requirements. The Agile methodologies reduce cumulative errors of the waterfall model through lightweight iteration and collaboration with users, but the challenge lies in ensuring semantic consistency between user requirements and the code generated by the agent. To address these challenges, we propose AgileGen, an agile-based generative software development through human-AI teamwork. Unlike existing questioning agents, AgileGen adopts a novel collaborative approach that breaks free from the constraints of domain knowledge by initiating the end-user perspective to complete the acceptance criteria. By introducing the Gherkin language, AgileGen attempts for the first time to use testable requirement descriptions as a bridge for semantic consistency between requirements and code, aiming to ensure that software products meet actual user requirements by defining user scenarios that include acceptance criteria. Additionally, we innovate in the human-AI teamwork model, allowing users to participate in decision-making processes they do well and significantly enhancing the completeness of software functionality. To ensure semantic consistency between requirements and generated code, we derive consistency factors from Gherkin to drive the subsequent software code generation. Finally, to improve the reliability of user scenarios, we also introduce a memory pool mechanism, collecting user decision-making scenarios and recommending them to new users with similar requirements. AgileGen, as a user-friendly interactive system, significantly outperformed existing best methods by 16.4\% and garnered higher user satisfaction.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jul,
articleno = {156},
numpages = {46},
keywords = {Agile, Human-AI Teamwork, Generative Software Development, User Requirement, Gherkin}
}

@article{10.1145/3712002,
author = {Murillo, Juan Manuel and Garcia-Alonso, Jose and Moguel, Enrique and Barzen, Johanna and Leymann, Frank and Ali, Shaukat and Yue, Tao and Arcaini, Paolo and P\'{e}rez-Castillo, Ricardo and Garc\'{\i}a-Rodr\'{\i}guez de Guzm\'{a}n, Ignacio and Piattini, Mario and Ruiz-Cort\'{e}s, Antonio and Brogi, Antonio and Zhao, Jianjun and Miranskyy, Andriy and Wimmer, Manuel},
title = {Quantum Software Engineering: Roadmap and Challenges Ahead},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3712002},
doi = {10.1145/3712002},
abstract = {As quantum computers advance, the complexity of the software they can execute increases as well. To ensure this software is efficient, maintainable, reusable, and cost-effective—key qualities of any industry-grade software—mature software engineering practices must be applied throughout its design, development, and operation. However, the significant differences between classical and quantum software make it challenging to directly apply classical software engineering methods to quantum systems. This challenge has led to the emergence of Quantum Software Engineering (QSE) as a distinct field within the broader software engineering landscape. In this work, a group of active researchers analyze in depth the current state of QSE research. From this analysis, the key areas of QSE are identified and explored in order to determine the most relevant open challenges that should be addressed in the next years. These challenges help identify necessary breakthroughs and future research directions for advancing QSE.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {154},
numpages = {48},
keywords = {Quantum Software Engineering, open challenges, Quantum Computing, QSE}
}

@inproceedings{10.5555/3712729.3712978,
author = {Barat, Souvik and Yadav, Abhishek and Thogaru, Himabindu and Kulkarni, Vinay and Bhattacharya, Kaustav},
title = {Imparting Adaptiveness and Resilience to Parcel Delivery Networks: A Digital Twin Centric Simulation Based Approach},
year = {2025},
isbn = {9798331534202},
publisher = {IEEE Press},
abstract = {Contemporary parcel delivery companies face a significant surge in demand, along with increased customer expectations for flawless and timely delivery. They must meet these expectations within a shrinking window of opportunity in an increasingly competitive world while dealing with various micro and macro level uncertainties. Current industry practice relying on localized analysis to meet these expectations has turned out ineffective. This paper argues that imparting adaptiveness and resilience to parcel delivery network is the key to a pragmatic solution. It presents a holistic approach based on simulatable digital twins and composable agents to enable "in silico" business experimentation wherein a set of what-if scenarios are simulated to help evaluate efficacy of current strategy and identify suitable modifications to the strategy if necessary. The paper illustrates the proposed approach on a case study from the parcel industry and demonstrates its utility and efficacy on a set of real-life scenarios.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {2999–3010},
numpages = {12},
location = {Orlando, Florida, USA},
series = {WSC '24}
}

@article{10.1145/3731209,
author = {Ma, Jiaju and Agrawala, Maneesh},
title = {MoVer: Motion Verification for Motion Graphics Animations},
year = {2025},
issue_date = {August 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3731209},
doi = {10.1145/3731209},
abstract = {While large vision-language models can generate motion graphics animations from text prompts, they regularly fail to include all spatio-temporal properties described in the prompt. We introduce MoVer, a motion verification DSL based on first-order logic that can check spatio-temporal properties of a motion graphics animation. We identify a general set of such properties that people commonly use to describe animations (e.g., the direction and timing of motions, the relative positioning of objects, etc.). We implement these properties as predicates in MoVer and provide an execution engine that can apply a MoVer program to any input SVG-based motion graphics animation. We then demonstrate how MoVer can be used in an LLM-based synthesis and verification pipeline for iteratively refining motion graphics animations. Given a text prompt, our pipeline synthesizes a motion graphics animation and a corresponding MoVer program. Executing the verification program on the animation yields a report of the predicates that failed and the report can be automatically fed back to LLM to iteratively correct the animation. To evaluate our pipeline, we build a synthetic dataset of 5600 text prompts paired with ground truth MoVer verification programs. We find that while our LLM-based pipeline is able to automatically generate a correct motion graphics animation for 58.8\% of the test prompts without any iteration, this number raises to 93.6\% with up to 50 correction iterations. Our code and dataset are at https://mover-dsl.github.io.},
journal = {ACM Trans. Graph.},
month = jul,
articleno = {33},
numpages = {17},
keywords = {verification, iterative refinement, large language models, motion graphics, visual programs, SVG}
}

@article{10.1145/3715111,
author = {Abrah\~{a}o, Silvia and Grundy, John and Pezz\`{e}, Mauro and Storey, Margaret-Anne and Tamburri, Damian A.},
title = {Software Engineering by and for Humans in an AI Era},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3715111},
doi = {10.1145/3715111},
abstract = {The landscape of software engineering is undergoing a transformative shift driven by advancements in machine learning, Artificial Intelligence (AI), and autonomous systems. This roadmap article explores how these technologies are reshaping the field, positioning humans not only as end users but also as critical components within expansive software ecosystems. We examine the challenges and opportunities arising from this human-centered paradigm, including ethical considerations, fairness, and the intricate interplay between technical and human factors. By recognizing humans at the heart of the software lifecycle—spanning professional engineers, end users, and end user developers—we emphasize the importance of inclusivity, human-aligned workflows, and the seamless integration of AI-augmented socio-technical systems. As software systems evolve to become more intelligent and human-centric, software engineering practices must adapt to this new reality. This article provides a comprehensive examination of this transformation, outlining current trends, key challenges, and opportunities that define the emerging research and practice landscape, and envisioning a future where software engineering and AI work synergistically to place humans at the core of the ecosystem.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {129},
numpages = {46},
keywords = {Software engineering, Human and social aspects, Large language models}
}

@article{10.1145/3702231,
author = {ter Beek, Maurice and Broy, Manfred and Dongol, Brijesh},
title = {The Role of Formal Methods in Computer Science Education},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {4},
issn = {2153-2184},
url = {https://doi.org/10.1145/3702231},
doi = {10.1145/3702231},
journal = {ACM Inroads},
month = nov,
pages = {58–66},
numpages = {9}
}

@inproceedings{10.1145/3664647.3681405,
author = {Liu, Yihao and Xue, Feng and Ming, Anlong and Zhao, Mingshuai and Ma, Huadong and Sebe, Nicu},
title = {SM4Depth: Seamless Monocular Metric Depth Estimation across Multiple Cameras and Scenes by One Model},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681405},
doi = {10.1145/3664647.3681405},
abstract = {In the last year, universal monocular metric depth estimation (universal MMDE) has gained considerable attention, serving as the foundation model for various multimedia tasks, such as video and image editing. Nonetheless, current approaches face challenges in maintaining consistent accuracy across diverse scenes without scene-specific parameters and pre-training, hindering the practicality of MMDE. Furthermore, these methods rely on extensive datasets comprising millions, if not tens of millions, of data for training, leading to significant time and hardware expenses. This paper presents SM4Depth, a model that seamlessly works for both indoor and outdoor scenes, without needing extensive training data and GPU clusters. Firstly, to obtain consistent depth across diverse scenes, we propose a novel metric scale modeling, i.e., variation- based unnormalized depth bins. It reduces the ambiguity of the conventional metric bins and enables better adaptation to large depth gaps of scenes during training. Secondly, we propose a ''divide and conquer'' solution to reduce reliance on massive training data. Instead of estimating directly from the vast solution space, the metric bins are estimated from multiple solution sub-spaces to reduce complexity. Additionally, we introduce an uncut depth dataset, BUPT Depth, to evaluate the depth accuracy and consistency across various indoor and outdoor scenes. Trained on a consumer-grade GPU using just 150K RGB-D pairs, SM4Depth achieves outstanding performance on the most never-before-seen datasets, especially maintaining consistent accuracy across indoors and outdoors. The code can be found here.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {3469–3478},
numpages = {10},
keywords = {domain-aware bin estimation, seamless monocular metric depth estimation},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@article{10.1145/3763242,
author = {Weyns, Danny},
title = {Reflection, Quick Reference Guide and Future Outlook to Autonomous and Adaptive Systems},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1556-4665},
url = {https://doi.org/10.1145/3763242},
doi = {10.1145/3763242},
abstract = {Researchers and engineers of autonomous and adaptive systems have always been fascinated by computing systems that have the ability to solve problems independently. In this reflection article, we look at three main families of such computing systems that emerged over the past two decades: Self-Organizing Systems, Self-Adaptive Systems, and Symbiotic HAI Systems that leverage the collective capabilities of Humans and AI-empowered autonomous and adaptive systems. For each family of these systems, we highlight the foundations, principles, and approaches, as well as system engineering. To conclude, we look at a number of challenges for future research in three key areas of this fascinating field: technical, ethical, and regulatory. These challenges open new fundamental and engineering problems for autonomous and adaptive systems.},
note = {Just Accepted},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = sep,
keywords = {self-organizing systems, self-adaptive systems, AI-empowered autonomous and adaptive systems}
}

@article{10.1145/3715750,
author = {Gao, Yi and Hu, Xing and Yang, Xiaohu and Xia, Xin},
title = {Automated Unit Test Refactoring},
year = {2025},
issue_date = {July 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {FSE},
url = {https://doi.org/10.1145/3715750},
doi = {10.1145/3715750},
abstract = {Test smells arise from poor design practices and insufficient domain knowledge, which can lower the quality of test code and make it harder to maintain and update. Manually refactoring of test smells is time-consuming and error-prone, highlighting the necessity for automated approaches. Current rule-based refactoring methods often struggle in scenarios not covered by predefined rules and lack the flexibility needed to handle diverse cases effectively. In this paper, we propose a novel approach called UTRefactor, a context-enhanced, LLM-based framework for automatic test refactoring in Java projects. UTRefactor extracts relevant context from test code and leverages an external knowledge base that includes test smell definitions, descriptions, and DSL-based refactoring rules. By simulating the manual refactoring process through a chain-of-thought approach, UTRefactor guides the LLM to eliminate test smells in a step-by-step process, ensuring both accuracy and consistency throughout the refactoring. Additionally, we implement a checkpoint mechanism to facilitate comprehensive refactoring, particularly when multiple smells are present. We evaluate UTRefactor on 879 tests from six open-source Java projects, reducing the number of test smells from 2,375 to 265, achieving an 89\% reduction. UTRefactor outperforms direct LLM-based refactoring methods by 61.82\% in smell elimination and significantly surpasses the performance of a rule-based test smell refactoring tool. Our results demonstrate the effectiveness of UTRefactor in enhancing test code quality while minimizing manual involvement.},
journal = {Proc. ACM Softw. Eng.},
month = jun,
articleno = {FSE033},
numpages = {21},
keywords = {Large Language Models, Test Refactoring, Test Smells}
}

@inproceedings{10.1145/3632971.3632981,
author = {Ji, Xiaoliu and Cao, Yang and Ni, Xuanfan and Wang, Xi and Mao, Xueying and Li, Piji and Guo, Chunjie},
title = {Neural Machine Translation for Chinese Patent Medicine Instructions},
year = {2024},
isbn = {9798400707704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632971.3632981},
doi = {10.1145/3632971.3632981},
abstract = {Abstract. Insufficient research has been conducted on the validity of datasets pertaining to the translation of Chinese Patent Medicine Instructions into English. Upon analyzing the Chinese and English texts generated by prominent translation engines, we observe that the readability of translation is a sore point and the English translation standards lack consistency. There exists a restricted range of internet search platforms that are specifically designed for the purpose of Chinese Patent Medicine (CPM). The focus of these platforms centers on the domain of specialized terminology related to Chinese herbal medicine. To address these problems, we initially develop a Chinese Patent Medicine Instruction Dataset (CPMID) for Chinese-English translation. This dataset comprises 11,695 Chinese-English entries to be meticulously annotated and validated. We benchmark the task by training and testing multiple baselines including traditional models Seq2Seq+Attention (LSTM) and Transformer, pre-trained and released translation models SMaLL-100, NLLB-200, mBART-50, and ChatGPT. The dataset demonstrates the accuracy and effectiveness with improvement of 42.5 BLEU, surpassing prior state-of-the-art by over 54.7\%. The primary objective of utilizing this dataset in future R&amp;D is to provide a reliable retrieval system for foreign users of Chinese Patent Medicine (CPM). We believe that the implementation of CPMID has the potential to facilitate the modernization of Traditional Chinese Medicine (TCM) and significantly contribute to the field of Modern Medicine (MM).},
booktitle = {Proceedings of the 2023 International Joint Conference on Robotics and Artificial Intelligence},
pages = {155–160},
numpages = {6},
keywords = {Chinese Patent Medicine Instructions, Large Language Models, Neural Machine Translation, Transformer},
location = {Shanghai, China},
series = {JCRAI '23}
}

@article{10.1145/3712302,
author = {Hosseini, Elahe and Srinivas, Abhinav and Nazari, Najmeh and Hale, Charity and Rafatirad, Setareh and Homayoun, Houman},
title = {Large Language Models for Opioid-Induced Respiratory Depression Prediction in Hospitalized Patients: A Retrospective Study},
year = {2025},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {2},
url = {https://doi.org/10.1145/3712302},
doi = {10.1145/3712302},
abstract = {Opioid-induced adverse events pose significant risks to hospitalized patients. However, there is a limited understanding of which patients on general care floors are at risk for Opioid-Induced Respiratory Depression (OIRD). This study aims to bridge that knowledge gap by utilizing the advancements of AI to interpret Electronic Medical Records (EMRs). Recently, Large Language Models (LLMs) have gained attention for their exceptional capabilities in understanding human language, which makes them crucial for AI systems in healthcare that focus on clinical narratives. In this study, we extracted 2,663 hospitalized adult patient records from UC Davis Medical Center archives between January 2010 and April 2020 to identify patients at high risk of OIRD. For this purpose, we employed clinical language models (BioBERT, ClinicalBERT, and GatorTron) and fine-tuned them on the OIRD dataset. Additionally, we leveraged the capabilities of GPT-4, a state-of-the-art LLM, to select the most informative risk factors and enhance the accuracy of the predictive models.},
journal = {ACM Trans. Comput. Healthcare},
month = apr,
articleno = {27},
numpages = {14},
keywords = {Opioid-Induced Respiratory Depression (OIRD), Large Language Models (LLMs)}
}

@article{10.1145/3632860,
author = {Patton, Noah and Rahmani, Kia and Missula, Meghana and Biswas, Joydeep and Dillig, I\c{s}\i{}l},
title = {Programming-by-Demonstration for Long-Horizon Robot Tasks},
year = {2024},
issue_date = {January 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {POPL},
url = {https://doi.org/10.1145/3632860},
doi = {10.1145/3632860},
abstract = {The goal of programmatic Learning from Demonstration (LfD) is to learn a policy in a programming language that can be used to control a robot’s behavior from a set of user demonstrations. This paper presents a new programmatic LfD algorithm that targets long-horizon robot tasks which require synthesizing programs with complex control flow structures, including nested loops with multiple conditionals. Our proposed method first learns a program sketch that captures the target program’s control flow and then completes this sketch using an LLM-guided search procedure that incorporates a novel technique for proving unrealizability of programming-by-demonstration problems. We have implemented our approach in a new tool called prolex and present the results of a comprehensive experimental evaluation on 120 benchmarks involving complex tasks and environments. We show that, given a 120 second time limit, prolex can find a program consistent with the demonstrations in 80\% of the cases. Furthermore, for 81\% of the tasks for which a solution is returned, prolex is able to find the ground truth program with just one demonstration. In comparison, CVC5, a syntaxguided synthesis tool, is only able to solve 25\% of the cases even when given the ground truth program sketch, and an LLM-based approach, GPT-Synth, is unable to solve any of the tasks due to the environment complexity.},
journal = {Proc. ACM Program. Lang.},
month = jan,
articleno = {18},
numpages = {34},
keywords = {Abstract Interpretation, Program Synthesis, Learning from Demonstrations}
}

@article{10.1145/3757062,
author = {Yang, Fu-Chia and Guo, Siqi and Mousas, Christos},
title = {Exploring Familiarity and Knowledgeability in Conversational Virtual Agents},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1544-3558},
url = {https://doi.org/10.1145/3757062},
doi = {10.1145/3757062},
abstract = {In this study, we examined the impact of agent familiarity and knowledgeability on several variables spanning agent perceptions (i.e., perceived knowledge, familiarity, trust, anthropomorphism, uncanny valley effect, and likability), social and emotional experiences (i.e., co-presence, rapport, cognitive process expectations, and willingness for future interaction), and conversation dynamics (i.e., conversation transcript, participants’ response word count, and response time). We created two virtual agents for the study: a digital replica of a professor from our department (i.e., familiar agent) and an agent with similar demographic variables (i.e., age, gender, and ethnicity) but with a fabricated appearance and voice (i.e., unfamiliar agent). We implemented both agents to exhibit two levels of knowledgeability (i.e., low and high) in the domain of game development and course-specific information. We used large language models (LLMs) to provide the agents with persona information and domain knowledge through prompt engineering. For our user study, we followed a 2 (familiarity: unfamiliar vs. familiar agent)  (times)  2 (knowledgeability: low vs. high knowledgeability) within-group study design and recruited 32 participants who engaged in a five-minute, conversation-based virtual reality (VR) interaction with all four experimental conditions: unfamiliar agent with low knowledgeability (ULK), unfamiliar agent with high knowledgeability (UHK), familiar agent with low knowledgeability (FLK), and familiar agent with high knowledgeability (FHK). The findings demonstrated a significant main effect of agent familiarity on perceived knowledge, suggesting that familiarity plays a crucial role in shaping users’ perception of the agent's knowledgeability level. Besides perceived knowledge, familiarity also affected all other variables, apart from co-presence. Conversely, agent knowledgeability affected perceived familiarity, trust, anthropomorphism, cognitive process expectations, willingness for future interaction, conversation content, and participants’ response word count. Finally, we found an interaction effect between agent familiarity and perceived knowledge, indicating that familiarity has a significant influence on users’ perceptions of the agent's knowledgeability. This study contributes to the field of conversational human-agent interaction in VR by providing empirical evidence on how adapting both familiarity and knowledgeability of virtual agents can significantly enhance user experience, offering valuable insights into designing more engaging, trustworthy, and effective embodied conversational agents.},
note = {Just Accepted},
journal = {ACM Trans. Appl. Percept.},
month = jul,
keywords = {Virtual Reality, Familiarity, Knowledgeability, Embodied Conversational Agents, Large Language Models}
}

@article{10.1145/3712311.3712323,
author = {Bonifati, Angela and Ozsu, M. Tamer and Tian, Yuanyuan and Voigt, Hannes and Yu, Wenyuan and Zhang, enjie},
title = {A Roadmap to Graph Analytics},
year = {2025},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {4},
issn = {0163-5808},
url = {https://doi.org/10.1145/3712311.3712323},
doi = {10.1145/3712311.3712323},
abstract = {Graphs are ubiquitous data structures used in a large spectrum of applications, spanning from transportation networks, financial networks, social networks, product-order transactions and biomedical applications [33]. A recent survey on the usage of graph applications from real users has highlighted the fact that analytics is the most time-consuming task as opposed to testing, cleaning and ETL [32].},
journal = {SIGMOD Rec.},
month = jan,
pages = {43–51},
numpages = {9}
}

@article{10.1145/3708520,
author = {Cederbladh, Johan and Cicchetti, Antonio and Jongeling, Robbert},
title = {A Road-Map to Readily Available Early Validation and Verification of System Behaviour in Model-Based Systems Engineering using Software Engineering Best Practices},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3708520},
doi = {10.1145/3708520},
abstract = {In this article, we discuss how we can facilitate the growing need for early validation and verification (V&amp;V) of system behaviour in Model-Based Systems Engineering (MBSyE). Several aspects, such as reducing cost and time to market, push companies towards integration of V&amp;V methods earlier in development to support effective decision-making. One foundational methodology seeing increased attention in industry is the use of MBSyE, which brings benefits of models with well-defined syntax and semantics to support V&amp;V activities, rather than relying on natural language text documentation. Despite their promise, industrial adoption of these practices is still challenging.This article presents a vision for readily available early V&amp;V. We present a summary of the literature on early V&amp;V in MBSyE and position existing challenges regarding potential solutions and future investigations towards this vision. We elaborate our vision by means of challenges with a specific emphasis on early V&amp;V of system behaviour. We identify three specific challenge areas: Creating and managing Models, Organisational systems engineering aspects, and early V&amp;V Methods. Finally, we outline a road-map to address these categories of challenges, in which we propose the transfer of established best practices from the software engineering domain to support emerging technologies in the systems engineering domain.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {151},
numpages = {30},
keywords = {Validation, Verification, Models, Early, Systems, Behaviour}
}

@inproceedings{10.1145/3691620.3695277,
author = {Sahoo, Priyam and Pujar, Saurabh and Nalawade, Ganesh and Genhardt, Richard and Mandel, Louis and Buratti, Luca},
title = {Ansible Lightspeed: A Code Generation Service for IT Automation},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695277},
doi = {10.1145/3691620.3695277},
abstract = {The availability of Large Language Models (LLMs) which can generate code, has made it possible to create tools that improve developer productivity. Integrated development environments or IDEs which developers use to write software are often used as an interface to interact with LLMs. Although many such tools have been released, almost all of them focus on general-purpose programming languages. Domain-specific languages, such as those crucial for Information Technology (IT) automation, have not received much attention. Ansible is one such YAML-based IT automation-specific language. Ansible Lightspeed is an LLM-based service designed explicitly to generate Ansible YAML, given natural language prompt.In this paper, we present the design and implementation of the Ansible Lightspeed service. We then evaluate its utility to developers using diverse indicators, including extended utilization, analysis of user edited suggestions, as well as user sentiments analysis. The evaluation is based on data collected for 10,696 real users including 3,910 returning users. The code for Ansible Lightspeed service and the analysis framework is made available for others to use.To our knowledge, our study is the first to involve thousands of users of code assistants for domain-specific languages. We are also the first code completion tool to present N-Day user retention figures, which is 13.66\% on Day 30. We propose an improved version of user acceptance rate, called Strong Acceptance rate, where a suggestion is considered accepted only if less than 50\% of it is edited and these edits do not change critical parts of the suggestion. By focusing on Ansible, Lightspeed is able to achieve a strong acceptance rate of 49.08\% for multi-line Ansible task suggestions. With our findings we provide insights into the effectiveness of small, dedicated models in a domain-specific context. We hope this work serves as a reference for software engineering and machine learning researchers exploring code completion.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2148–2158},
numpages = {11},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3723178.3723209,
author = {Baul, Saikat and Ahamed, Jubayer and Islam, Md. Ariful and Mazumder, Md. Khairul Alam and Sultan, Tofayet and Nandi, Dip},
title = {A comprehensive study to assist decision-makers in determining software design between four UML diagrams},
year = {2025},
isbn = {9798400713828},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723178.3723209},
doi = {10.1145/3723178.3723209},
abstract = {UML is a graphical language that allows software engineers and developers to design, describe, and represent software systems. While UML cannot be defined as a programming language, it provides graphical representations which help software developers in understanding various results of programs or defects. UML diagrams are essential in software engineering as they offer a standardized approach for visually expressing system design and behavior. A clear and well-defined visual representation of the code's structure and flow allows developers to effectively allocate resources, set work priorities, and improve the overall efficiency of the development process. The interdependence of these diagrams requires their consistency, as any discrepancies may result in problems during software development processes that depend on them. Establishing defined consistency criteria and recognizing, analyzing, and resolving any differences is essential. This research study investigates the enhancement of software design by strategically choosing UML (Unified Modelling Language) diagrams, with a specific focus on Class, Sequence, Use Case, and Activity diagrams. This study aims to determine the advantages and suitable uses of each diagram form to improve the clarity and effectiveness of the design process. The study evaluates the strengths of different diagrams in various settings and contexts. It offers advice to assist in selecting the most appropriate diagram depending on specific design criteria. In our study, we provide a comprehensive analysis of the UML diagram. Also, we provide a decision-making method. The decision-makers will choose a suitable diagram for their project by following the phases.},
booktitle = {Proceedings of the 3rd International Conference on Computing Advancements},
pages = {232–238},
numpages = {7},
keywords = {Class diagrams, Decision-making, Software architecture, UML diagrams, Use case diagrams},
location = {
},
series = {ICCA '24}
}

@inproceedings{10.1145/3533767.3534396,
author = {Zhang, Jialu and Mytkowicz, Todd and Kaufman, Mike and Piskac, Ruzica and Lahiri, Shuvendu K.},
title = {Using pre-trained language models to resolve textual and semantic merge conflicts (experience paper)},
year = {2022},
isbn = {9781450393799},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3533767.3534396},
doi = {10.1145/3533767.3534396},
abstract = {Program merging is standard practice when developers integrate their individual changes to a common code base. When the merge algorithm fails, this is called a merge conflict. The conflict either manifests as a textual merge conflict where the merge fails to produce code, or as a semantic merge conflict where the merged code results in compiler errors or broken tests. Resolving these conflicts for large code projects is expensive because it requires developers to manually identify the sources of conflicts and correct them.   In this paper, we explore the feasibility of automatically repairing merge conflicts (both textual and semantic) using k-shot learning with pre-trained large neural language models (LM) such as GPT-3. One of the challenges in leveraging such language models is fitting the examples and the queries within a small prompt (2048 tokens). We evaluate LMs and k-shot learning for both textual and semantic merge conflicts for Microsoft Edge. Our results are mixed: on one-hand, LMs provide the state-of-the-art (SOTA) performance on semantic merge conflict resolution for Edge compared to earlier symbolic approaches; on the other hand, LMs do not yet obviate the benefits of special purpose domain-specific languages (DSL) for restricted patterns for program synthesis.},
booktitle = {Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {77–88},
numpages = {12},
keywords = {GPT-3, Resolving merge conflicts, k-shot learning, language model},
location = {Virtual, South Korea},
series = {ISSTA 2022}
}

@article{10.1145/3638243,
author = {Oakes, Bentley James and Famelis, Michalis and Sahraoui, Houari},
title = {Building Domain-Specific Machine Learning Workflows: A Conceptual Framework for the State of the Practice},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3638243},
doi = {10.1145/3638243},
abstract = {Domain experts are increasingly employing machine learning to solve their domain-specific problems. This article presents to software engineering researchers the six key challenges that a domain expert faces in addressing their problem with a computational workflow, and the underlying executable implementation. These challenges arise out of our conceptual framework which presents the “route” of transformations that a domain expert may choose to take while developing their solution.To ground our conceptual framework in the state of the practice, this article discusses a selection of available textual and graphical workflow systems and their support for the transformations described in our framework. Example studies from the literature in various domains are also examined to highlight the tools used by the domain experts as well as a classification of the domain specificity and machine learning usage of their problem, workflow, and implementation.The state of the practice informs our discussion of the six key challenges, where we identify which challenges and transformations are not sufficiently addressed by available tools. We also suggest possible research directions for software engineering researchers to increase the automation of these tools and disseminate best-practice techniques between software engineering and various scientific domains.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {91},
numpages = {50},
keywords = {Computational workflow, workflow composition, domain experts, machine learning, machine learning pipelines, software engineering framework}
}

@inproceedings{10.1145/3644032.3644456,
author = {Canizares, Pablo C. and \'{A}vila, Daniel and Perez-Soler, Sara and Guerra, Esther and De Lara, Juan},
title = {Coverage-based Strategies for the Automated Synthesis of Test Scenarios for Conversational Agents},
year = {2024},
isbn = {9798400705885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644032.3644456},
doi = {10.1145/3644032.3644456},
abstract = {Conversational agents - or chatbots - are increasingly used as the user interface to many software services. While open-domain chatbots like ChatGPT excel in their ability to chat about any topic, task-oriented conversational agents are designed to perform goal-oriented tasks (e.g., booking or shopping) guided by a dialogue-based user interaction, which is explicitly designed. Like any kind of software system, task-oriented conversational agents need to be properly tested to ensure their quality. For this purpose, some tools permit defining and executing conversation test cases. However, there are currently no established means to assess the coverage of the design of a task-oriented agent by a test suite, or mechanisms to automate quality test case generation ensuring the agent coverage.To attack this problem, we propose test coverage criteria for task-oriented conversational agents, and define coverage-based strategies to synthesise test scenarios, some oriented to test case reduction. We provide an implementation of the criteria and the strategies that is independent of the agent development platform. Finally, we report on their evaluation on open-source Dialogflow and Rasa agents, and a comparison against a state-of-the-art testing tool. The experiment shows benefits in terms of test generation correctness, increased coverage and reduced testing time.},
booktitle = {Proceedings of the 5th ACM/IEEE International Conference on Automation of Software Test (AST 2024)},
pages = {23–33},
numpages = {11},
keywords = {testing, test suite generation, task-oriented conversational agents},
location = {Lisbon, Portugal},
series = {AST '24}
}

@inproceedings{10.1145/3706598.3714327,
author = {Yang, Jackie (Junrui) and Shi, Yingtian and Gu, Chris and Zheng, Zhang and Jain, Anisha and Li, Tianshi and Lam, Monica S. and Landay, James A.},
title = {GenieWizard: Multimodal App Feature Discovery with Large Language Models},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714327},
doi = {10.1145/3706598.3714327},
abstract = {Multimodal interactions are more flexible, efficient, and adaptable than graphical interactions, allowing users to execute commands beyond simply tapping GUI buttons. However, the flexibility of multimodal commands makes it hard for designers to prototype and provide design specifications for developers. It is also hard for developers to anticipate what actions users may want. We present GenieWizard, a tool to aid developers in discovering potential features to implement in multimodal interfaces. GenieWizard supports user-desired command discovery early in the implementation process, streamlining the development process. GenieWizard uses an LLM to generate potential user interactions and parse these interactions into a form that can be used to discover the missing features for developers. Our evaluations showed that GenieWizard can reliably simulate user interactions and identify missing features. Also, in a study (N = 12), we demonstrated that developers using GenieWizard can identify and implement 42\% of the missing features of multimodal apps compared to only 10\% without GenieWizard.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {936},
numpages = {17},
keywords = {Multimodal interfaces, developer tools, large language models, feature discovery, interaction simulation, voice interfaces, touch interfaces, semantic parsing, multimodal app development},
location = {
},
series = {CHI '25}
}

@article{10.1145/3758326,
author = {Aguzzi, Gianluca and Farabegoli, Nicolas and Viroli, Mirko},
title = {A Language-based Approach to Macroprogramming for IoT Systems through Large Language Models},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3758326},
doi = {10.1145/3758326},
abstract = {Large language models (LLMs) have transformed software engineering, particularly in code generation, where they assist developers in writing functions or entire programs. However, code generation remains challenging when the target domain is complex, as is the case with Internet of Things (IoT) systems. The challenge lies in capturing the entire system behavior within a single specification. developers often model only a subset of the system’s functionality, focusing primarily on individual device behavior or data processing aspects, which may not address the core challenges of IoT, such as large-scale distributed coordination and emergent behavior. To address this, macroprogramming paradigms have been proposed as a means to specify the collective behavior of IoT systems more holistically. Among these approaches, aggregate computing stands out for its ability to express system-wide properties through a top-down, global-to-local perspective. Despite its potential, the adoption of aggregate computing remains limited due to the complexity of writing and maintaining such programs. To overcome these barriers, we propose a language-based approach based on macroprogramming that leverages LLMs for IoT code generation. Specifically, we employ the in-context learning capabilities of LLMs, guiding them to generate code based on an aggregate computing abstraction. This creates code that reflects system-wide properties and frees programmers from writing low-level code by letting them specify desired global properties in natural language. The LLM then translates these specifications into executable code, thus facilitating the development of collective intelligence applications in IoT systems.},
note = {Just Accepted},
journal = {ACM Trans. Internet Things},
month = aug,
keywords = {Large Language Models, Macroprogramming, Internet of Things, Aggregate Computing, Code Generation}
}

@article{10.1145/3696379,
author = {Bui, Minh-Thanh and Boffa, Matteo and Valentim, Rodolfo Vieira and Navarro, Jose Manuel and Chen, Fuxing and Bao, Xiaosheng and Houidi, Zied Ben and Rossi, Dario},
title = {A Systematic Comparison of Large Language Models Performance for Intrusion Detection},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {CoNEXT4},
url = {https://doi.org/10.1145/3696379},
doi = {10.1145/3696379},
abstract = {We explore the capabilities of Large Language Models (LLMs) to assist or substitute devices (i.e., firewalls) and humans (i.e., security experts) respectively in the detection and analysis of security incidents. We leverage transformer-based technologies, from relatively small to foundational sizes, to address the problem of correctly identifying the attack severity (and accessorily identifying and explaining the attack type). We contrast a broad range of LLM techniques (prompting, retrieval augmented generation, and fine-tuning of several models) using state-of-the-art machine learning models as a baseline. Using proprietary data from commercial deployment, our study provides an unbiased picture of the strengths and weaknesses of LLM for intrusion detection.},
journal = {Proc. ACM Netw.},
month = nov,
articleno = {22},
numpages = {23},
keywords = {computing methodologies, firewalls, intrusion detection systems, machine learning, natural language processing, security and privacy}
}

@inproceedings{10.1145/3718958.3750503,
author = {Yan, Zihan and Li, Dan and Chen, Li and Xiong, Dian and Gao, Kaihui and Zhang, Yiwei and Yan, Rui and Zhang, Menglei and Zhang, Bochun and Jiang, Zhuo and Ye, Jianxi and Lin, Haibin},
title = {From ATOP to ZCube: Automated Topology Optimization Pipeline and A Highly Cost-Effective Network Topology for Large Model Training},
year = {2025},
isbn = {9798400715242},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3718958.3750503},
doi = {10.1145/3718958.3750503},
abstract = {The development of large language models (LLMs) poses new challenges in data center network topology design. To assist in exploring topology design, we propose ATOP, an Automated Topology Optimization Pipeline, which models network topology as a set of hyperparameters, enabling the discovery of potential topologies. With various optimization algorithms and customizable optimization objectives, ATOP achieves automated topology optimization on a scale of tens of thousands of GPUs. We apply ATOP on network topologies for 256, 1024, 4096, and 16384 GPUs, optimizing performance under LLMs training traffic patterns, collective communication performance, fault tolerance, and network cost. We also evaluate ATOP in different scenarios: building, optimizing, and expanding a data center. From ATOP's results, we discover a new topology — ZCube, which reaches the highest cost-effectiveness across various GPU scales. Simulation results show that ZCube, compared to the previous state-of-the-art topologies, including Rail-optimized Fat-tree (ROFT), Rail-only, and HPN, improves end-to-end LLM training speed by 3\% to 7\% and reduces network hardware costs by 26\% to 46\%. We also construct ZCube on a real-world testbed. Results show that ZCube reduces hardware costs by 25\% compared to Rail-Optimized Topology while maintaining the same all-reduce and all-to-all performance.},
booktitle = {Proceedings of the ACM SIGCOMM 2025 Conference},
pages = {861–881},
numpages = {21},
keywords = {data center networks, network topology, AI infrastructure},
location = {S\~{a}o Francisco Convent, Coimbra, Portugal},
series = {SIGCOMM '25}
}

@article{10.1145/3731752,
author = {Liang, Qingyuan and Sun, Zeyu and Zhao, Yifan and Gong, Zhihao and Wang, Guoqing and Chen, Yizhou and Zhang, Lu and Liang, Guangtai and Wang, Qianxiang},
title = {Bipartite-Grammar Aware Pretraining for XML-SQL Code Updating},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3731752},
doi = {10.1145/3731752},
abstract = {The eXtensible Markup Language (XML) is a file format widely used for data transmission in modern software development. In recent years, embedding SQL statements in XML files (i.e., XML-SQL) has become a popular way for developing applications with database access capability. Typically, XML-SQL code snippets demonstrate similar functionalities and structures, leading to repetitive programming work. Therefore, leveraging pre-trained code models for automated code generation presents a promising way to alleviate duplicated efforts and enhance the efficiency of developing XML-SQL code. However, XML-SQL code has strong domain-specific characteristics that general pre-trained code models typically struggle to fully harness, thereby leading to limited overall performance of general pre-trained code models. In this paper, we aim to address the challenge of handling this domain-specific knowledge. First, we propose a code updating task and construct the corresponding TwinXSQL dataset to better evaluate the model’s code generation performance in the XML-SQL domain. Then, we leverage the common characteristics of XML-SQL and other programming languages (i.e., all programming languages impose grammar constraints on behaviour) to design a bipartite-grammar-aware training framework (named BGA) for unsupervised pre-training, thereby improving the transfer of general-purpose code models to the XML-SQL domain. Specifically, we divide the XML-SQL code into two types of grammatical components: structure components and value components. During pre-training, we undertake three tasks, each designed to learn the internal information of these grammatical components and the relationships between them, enabling the pre-training process to better incorporate previously unlearned domain-specific knowledge of XML-SQL code. Our experimental results show that our trained model XSQLT5-base (220M) improves accuracy by 13.8\% compared to the similarly sized CodeT5-base (220M). Additionally, our experiments reveal that ChatGPT, due to its inability to fully learn the XML-SQL domain knowledge, achieves a much lower generation accuracy even with few-shot samples compared to our XSQLT5-base (220M) model.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
keywords = {XML, Pre-training, Large Language Models, Code Generation, Software Evolution}
}

@article{10.1145/3656296,
author = {Wang, Changjie and Scazzariello, Mariano and Farshin, Alireza and Ferlin, Simone and Kosti\'{c}, Dejan and Chiesa, Marco},
title = {NetConfEval: Can LLMs Facilitate Network Configuration?},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {CoNEXT2},
url = {https://doi.org/10.1145/3656296},
doi = {10.1145/3656296},
abstract = {This paper explores opportunities to utilize Large Language Models (LLMs) to make network configuration human-friendly, simplifying the configuration of network devices \&amp; development of routing algorithms and minimizing errors. We design a set of benchmarks (NetConfEval) to examine the effectiveness of different models in facilitating and automating network configuration. More specifically, we focus on the scenarios where LLMs translate high-level policies, requirements, and descriptions (i.e., specified in natural language) into low-level network configurations \&amp; Python code. NetConfEval considers four tasks that could potentially facilitate network configuration, such as (i) generating high-level requirements into a formal specification format, (ii) generating API/function calls from high-level requirements, (iii) developing routing algorithms based on high-level descriptions, and (iv) generating low-level configuration for existing and new protocols based on input documentation. Learning from the results of our study, we propose a set of principles to design LLM-based systems to configure networks. Finally, we present two GPT-4-based prototypes to (i) automatically configure P4-enabled devices from a set of high-level requirements and (ii) integrate LLMs into existing network synthesizers.},
journal = {Proc. ACM Netw.},
month = jun,
articleno = {7},
numpages = {25},
keywords = {benchmark, code generation, function calling, large language models (llms), network configuration, network synthesizer, p4, rag, routing algorithms}
}

@article{10.1145/3580480,
author = {Du, Kelvin and Xing, Frank and Cambria, Erik},
title = {Incorporating Multiple Knowledge Sources for Targeted Aspect-based Financial Sentiment Analysis},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {3},
issn = {2158-656X},
url = {https://doi.org/10.1145/3580480},
doi = {10.1145/3580480},
abstract = {Combining symbolic and subsymbolic methods has become a promising strategy as research tasks in AI grow increasingly complicated and require higher levels of understanding. Targeted Aspect-based Financial Sentiment Analysis (TABFSA) is an example of such complicated tasks, as it involves processes like information extraction, information specification, and domain adaptation. However, little is known about the design principles of such hybrid models leveraging external lexical knowledge. To fill this gap, we define anterior, parallel, and posterior knowledge integration and propose incorporating multiple lexical knowledge sources strategically into the fine-tuning process of pre-trained transformer models for TABFSA. Experiments on the Financial Opinion mining and Question Answering challenge (FiQA) Task 1 and SemEval 2017 Task 5 datasets show that the knowledge-enabled models systematically improve upon their plain deep learning counterparts, and some outperform state-of-the-art results reported in terms of aspect sentiment analysis error. We discover that parallel knowledge integration is the most effective and domain-specific lexical knowledge is more important according to our ablation analysis.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = jun,
articleno = {23},
numpages = {24},
keywords = {Financial sentiment analysis, neural networks, knowledge enabled system, deep learning, transformer models}
}

@inproceedings{10.1145/3723498.3723726,
author = {van Rozen, Riemer},
title = {Live Game Design: Prototyping at the Speed of Play},
year = {2025},
isbn = {9798400718564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723498.3723726},
doi = {10.1145/3723498.3723726},
abstract = {Automated Game Design empowers game designers with languages, techniques and tools that automate iterative design processes. However, these tools currently lack suitable input and feedback mechanisms for creating rules and perceiving how changes affect running game prototypes. As a result, iterating takes too long, forming mental models about cause-and-effect relationships is difficult, and learning how to program can be tedious and frustrating. We investigate how Live Programming can accelerate game design iterations, make visual tools more accessible and engaging, and provide immediate feedback that brings code to life. We propose Live Game Design, a novel approach for rapid game prototyping that introduces mini-cycles to help designers of all skill levels explore, learn, and see a prototype come alive. We introduce Vie (pronounced /vi/), a game-making game for simultaneously prototyping and playtesting simple 2D games using Machinations. In an observational study, we evaluate the app during a Game-Based Learning tutorial for children aged 8 to 14. Our results show Vie is accessible to novices and Live Game Design enables prototyping at the speed of play.},
booktitle = {Proceedings of the 20th International Conference on the Foundations of Digital Games},
articleno = {26},
numpages = {12},
keywords = {automated game design, live programming, game mechanics, mixed-initiative design, prototyping, playtesting, game-based learning},
location = {
},
series = {FDG '25}
}

@inproceedings{10.1145/3706598.3713613,
author = {Li, Brenna and Tauseef, Saba and Truong, Khai N. and Mariakakis, Alex},
title = {A Comparative Analysis of Information Gathering by Chatbots, Questionnaires, and Humans in Clinical Pre-Consultation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713613},
doi = {10.1145/3706598.3713613},
abstract = {Information gathering is an important capability that allows chatbots to understand and respond to users’ needs, yet the effectiveness of LLM-powered chatbots at this task remains underexplored. Our work investigates this question in the context of clinical pre-consultation, wherein patients provide information to an intermediary before meeting with a physician to facilitate communication and reduce consultation inefficiencies. We conducted a study at a walk-in clinic with 45 patients who interacted with one of three conversational agents: a chatbot, a questionnaire, and a Wizard-of-Oz. We analyzed patients’ messages using metrics adapted from Grice’s maxims to assess the quality of information gathered at each conversation turn. We found that the Wizard and LLM were more successful than the questionnaire because they modified questions and asked follow-ups when participants provided unsatisfactory answers. However, the LLM did not ask nearly as many follow-up questions as the Wizard, particularly when participants provided unclear answers.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {639},
numpages = {17},
keywords = {Pre-consultation, chatbot, LLM, primary care, walk-in clinic},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3661167.3661220,
author = {G\'{o}mez-Abajo, Pablo and P\'{e}rez-Soler, Sara and Ca\~{n}izares, Pablo C. and Guerra, Esther and de Lara, Juan},
title = {Mutation Testing for Task-Oriented Chatbots},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661220},
doi = {10.1145/3661167.3661220},
abstract = {Conversational agents, or chatbots, are increasingly used to access all sorts of services using natural language. While open-domain chatbots – like ChatGPT – can converse on any topic, task-oriented chatbots – the focus of this paper – are designed for specific tasks, like booking a flight, obtaining customer support, or setting an appointment. Like any other software, task-oriented chatbots need to be properly tested, usually by defining and executing test scenarios (i.e., sequences of user-chatbot interactions). However, there is currently a lack of methods to quantify the completeness and strength of such test scenarios, which can lead to low-quality tests, and hence to buggy chatbots. To fill this gap, we propose adapting mutation testing (MuT) for task-oriented chatbots. To this end, we introduce a set of mutation operators that emulate faults in chatbot designs, an architecture that enables MuT on chatbots built using heterogeneous technologies, and a practical realisation as an Eclipse plugin. Moreover, we evaluate the applicability, effectiveness and efficiency of our approach on open-source chatbots, with promising results.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {232–241},
numpages = {10},
keywords = {Botium, Dialogflow, Mutation testing, Rasa, Task-oriented chatbots},
location = {Salerno, Italy},
series = {EASE '24}
}

@inproceedings{10.1145/3747912.3747966,
author = {Zhu, Linkai and Zhu, Xiaolian and Liu, Lu and Yin, Bin and Li, Xiaojuan},
title = {From Regulation to Execution: Generating GDPR-Compliant Smart Contracts for Cross-Border Data Transfer},
year = {2025},
isbn = {9798400715136},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3747912.3747966},
doi = {10.1145/3747912.3747966},
abstract = {Privacy policy about sharing data in different countries make it hard to create smart contracts on blockchain that follow the rules. This research suggests a new way to automatically turn legal rules into smart contracts. The method uses a special language for law to change regulations into Solidity code. We make a tool that changes legal rules into code with conditions, time limits, and permissions. We find a mechanism to check the logic of the rules. And integrate a system that puts everything together into a full smart contract with checks and alerts.  This system will check if the contract works right and follows the privacy policy in GDPR.},
booktitle = {Proceedings of the 2025 International Conference on Software Engineering and Computer Applications},
pages = {49–52},
numpages = {4},
keywords = {Cross-border Data Transfer, Privacy Regulation Compliance, Smart Legal Contracts, Solidity Code Generation},
location = {
},
series = {SECA '25}
}

@article{10.1145/3709616.3709617,
author = {Neumann, Peter G.},
title = {ACM Risks Forum Quarterly Summary},
year = {2025},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/3709616.3709617},
doi = {10.1145/3709616.3709617},
abstract = {This is an annotated summary of the main items contributed to the ACM Risks Forum in the most recent quarter, orgnanized categorically. References (R i j) to the online Risks Forum denote RISKS vol i number j. Cited RISKS items generally identify contributors and sources, together with URLs. Official RISKS archives are available at www.risks.org, with nice html formatting and search engine courtesy of Lindsay Marshall at Newcastle: http://catless.ncl.ac.uk/Risks/i.j.html (also ftp://www.sri.com/risks). CACM Inside Risks: https://www.csl.sri.com/users/neumann/insiderisks.html},
journal = {SIGSOFT Softw. Eng. Notes},
month = jan,
pages = {4–7},
numpages = {4}
}

@inproceedings{10.1145/3637528.3671622,
author = {Fischer, Sophie and Gemmell, Carlos and Tecklenburg, Niklas and Mackie, Iain and Rossetto, Federico and Dalton, Jeffrey},
title = {GRILLBot In Practice: Lessons and Tradeoffs Deploying Large Language Models for Adaptable Conversational Task Assistants},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671622},
doi = {10.1145/3637528.3671622},
abstract = {We tackle the challenge of building real-world multimodal assistants for complex real-world tasks. We describe the practicalities and challenges of developing and deploying GRILLBot, a leading (first and second prize winning in 2022 and 2023) system deployed in the Alexa Prize TaskBot Challenge. Building on our Open Assistant Toolkit (OAT) framework, we propose a hybrid architecture that leverages Large Language Models (LLMs) and specialised models tuned for specific subtasks requiring very low latency. OAT allows us to define when, how and which LLMs should be used in a structured and deployable manner. For knowledge-grounded question answering and live task adaptations, we show that LLM reasoning abilities over task context and world knowledge outweigh latency concerns. For dialogue state management, we implement a code generation approach and show that specialised smaller models have 84\% effectiveness with 100x lower latency. Overall, we provide insights and discuss tradeoffs for deploying both traditional models and LLMs to users in complex real-world multimodal environments in the Alexa TaskBot challenge. These experiences will continue to evolve as LLMs become more capable and efficient -- fundamentally reshaping OAT and future assistant architectures.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4951–4961},
numpages = {11},
keywords = {conversational task assistants, large language models},
location = {Barcelona, Spain},
series = {KDD '24}
}

@article{10.1145/3673226,
author = {Uhrmacher, Adelinde M and Frazier, Peter and H\"{a}hnle, Reiner and Kl\"{u}gl, Franziska and Lorig, Fabian and Lud\"{a}scher, Bertram and Nenzi, Laura and Ruiz-Martin, Cristina and Rumpe, Bernhard and Szabo, Claudia and Wainer, Gabriel and Wilsdorf, Pia},
title = {Context, Composition, Automation, and Communication: The C2AC Roadmap for Modeling and Simulation},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {4},
issn = {1049-3301},
url = {https://doi.org/10.1145/3673226},
doi = {10.1145/3673226},
abstract = {Simulation has become, in many application areas, a sine qua non. Most recently, COVID-19 has underlined the importance of simulation studies and limitations in current practices and methods. We identify four goals of methodological work for addressing these limitations. The first is to provide better support for capturing, representing, and evaluating the context of simulation studies, including research questions, assumptions, requirements, and activities contributing to a simulation study. In addition, the composition of simulation models and other simulation studies’ products must be supported beyond syntactical coherence, including aspects of semantics and purpose, enabling their effective reuse. A higher degree of automating simulation studies will contribute to more systematic, standardized simulation studies and their efficiency. Finally, it is essential to invest increased effort into effectively communicating results and the processes involved in simulation studies to enable their use in research and decision making. These goals are not pursued independently of each other, but they will benefit from and sometimes even rely on advances in other sub-fields. In this article, we explore the basis and interdependencies evident in current research and practice and delineate future research directions based on these considerations.},
journal = {ACM Trans. Model. Comput. Simul.},
month = aug,
articleno = {23},
numpages = {51},
keywords = {Modeling, simulation, state of the art, open challenges, reuse, composition, communication, reproducibility, automation, intelligent modeling and simulation lifecycle}
}

@inbook{10.1145/3676536.3689923,
author = {Bohm Agostini, Nicolas and Gozzi, Giovanni and Fiorito, Michele and Barone, Claudio and Curzel, Serena and Limaye, Ankur and Minutoli, Marco and Castellana, Vito Giovanni and Manzano, Joseph and Ferrandi, Fabrizio and Tumeo, Antonino},
title = {Extending High-Level Synthesis with AI/ML Methods},
year = {2025},
isbn = {9798400710773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676536.3689923},
abstract = {Artificial Intelligence (AI) and Machine Learning (ML) methods offer significant opportunities to improve the quality of results in high-level synthesis (HLS). For instance, they can be used to model and predict metrics of the final design (e.g., area, considering aspects such as interconnect overhead for different device technologies), thereby facilitating exploration when searching for the best design trade-offs. Additionally, they can help identify hidden correlations across various phases of synthesis and the optimizations performed, enabling the identification of the most effective pipelines. Furthermore, these methods can greatly facilitate and enhance the design space exploration for the synthesis process in terms of both time and quality of results. This paper discusses the opportunities and challenges of augmenting HLS with AI/ML, using as an example the SODA Synthesizer, an open-source hardware generation toolchain that includes SODA-OPT, a hardware/software partitioning and pre-optimization tool developed with the MLIR framework, and PandA-Bambu, a state-of-the-art HLS tool. SODA interfaces with OpenROAD to provide a complete end-to-end toolchain.},
booktitle = {Proceedings of the 43rd IEEE/ACM International Conference on Computer-Aided Design},
articleno = {28},
numpages = {6}
}

@inproceedings{10.1145/3640543.3645203,
author = {Rao, Nikitha and Tsay, Jason and Kate, Kiran and Hellendoorn, Vincent and Hirzel, Martin},
title = {AI for Low-Code for AI},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640543.3645203},
doi = {10.1145/3640543.3645203},
abstract = {Low-code programming allows citizen developers to create programs with minimal coding effort, typically via visual (e.g. drag-and-drop) interfaces. In parallel, recent AI-powered tools such as Copilot and ChatGPT generate programs from natural language instructions. We argue that these modalities are complementary: tools like ChatGPT greatly reduce the need to memorize large APIs but still require their users to read (and modify) textual programs, whereas visual tools abstract away most or all program text but struggle to provide easy access to large APIs. At their intersection, we propose LowCoder, the first low-code tool for developing AI pipelines that supports both a visual programming interface (LowCoderVP) and an AI-powered natural language interface (LowCoderNL). We leverage this tool to provide some of the first insights into whether and how these two modalities help programmers by conducting a user study. We task 20 developers with varying levels of AI expertise with implementing four ML pipelines using LowCoder, replacing the LowCoderNL component with a simple keyword search in half the tasks. Overall, we find that LowCoder is especially useful for (i)&nbsp;Discoverability: using LowCoderNL, participants discovered new operators in 75\% of the tasks, compared to just 32.5\% and 27.5\% using web search or scrolling through options respectively in the keyword-search condition, and (ii)&nbsp;Iterative Composition: 82.5\% of tasks were successfully completed and many initial pipelines were further successfully improved. Qualitative analysis shows that AI helps users discover how to implement constructs when they know what to do, but still fails to support novices when they lack clarity on what they want to accomplish. Overall, our work highlights the benefits of combining the power of AI with low-code programming.},
booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {837–852},
numpages = {16},
location = {Greenville, SC, USA},
series = {IUI '24}
}

@inproceedings{10.1145/3624007.3624053,
author = {Magalh\~{a}es, Jos\'{e} Wesley de Souza and Woodruff, Jackson and Polgreen, Elizabeth and O'Boyle, Michael F. P.},
title = {C2TACO: Lifting Tensor Code to TACO},
year = {2023},
isbn = {9798400704062},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624007.3624053},
doi = {10.1145/3624007.3624053},
abstract = {Domain-specific languages (DSLs) promise a significant performance and portability advantage over traditional languages. DSLs are designed to be high-level and platform-independent, allowing an optimizing compiler significant leeway when targeting a particular device. Such languages are particularly popular with emerging tensor algebra workloads. However, DSLs present their own challenge: they require programmers to learn new programming languages and put in significant effort to migrate legacy code.    We present C2TACO, a synthesis tool for synthesizing TACO, a well-known tensor DSL, from C code. We develop a smart, enumerative synthesizer that uses automatically generated IO examples and source-code analysis to efficiently generate code. C2TACO is able to synthesize 95\% bench marks from a tensor benchmark suite, out-performing an alternative neural machine translation technique, and demonstrates substantially higher levels of accuracy when evaluated against two state-of-the-art existing schemes, TF-Coder and ChatGPT. Our synthesized TACO programs are, by design, portable achieving significant performance improvement when evaluated on a multi-core and GPU platform.},
booktitle = {Proceedings of the 22nd ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {42–56},
numpages = {15},
keywords = {Program Lifting, Synthesis, TACO, Tensor Algebra},
location = {Cascais, Portugal},
series = {GPCE 2023}
}

@inproceedings{10.1145/3643660.3643945,
author = {Lethbridge, Timothy},
title = {TAMVE: Properties of Design Technologies to Address Challenges to Software Design in the Era of Agility and Frameworks},
year = {2024},
isbn = {9798400705632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643660.3643945},
doi = {10.1145/3643660.3643945},
abstract = {It has been over 20 years since software design started the transition from the era of big design documents to the era where agility and the use of sophisticated frameworks has become standard. Design in both eras faced challenges: Big documents are rarely maintained properly; agility results in design either being skipped, lost, or dispersed into multiple small files; frameworks such as Ruby on Rails tend to impose a design on the system, encouraging developers to jump into coding. In this position paper, we suggest how design technologies and notations should have five properties that would help overcome many of the challenges to design in the current era. They should be Textual, Analysable, Multi-technology, Visualizable and Example-rich; we use the acronym TAMVE as a mnemonic for this. We explain how the Umple technology goes a considerable distance towards this achieving the TAMVE vision.},
booktitle = {Proceedings of the 1st International Workshop on Designing Software},
pages = {56–59},
numpages = {4},
keywords = {software design, frameworks, agility, umple, modeling},
location = {Lisbon, Portugal},
series = {Designing '24}
}

@article{10.1145/3720449,
author = {Li, Zongjie and Wu, Daoyuan and Wang, Shuai and Su, Zhendong},
title = {API-Guided Dataset Synthesis to Finetune Large Code Models},
year = {2025},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {OOPSLA1},
url = {https://doi.org/10.1145/3720449},
doi = {10.1145/3720449},
abstract = {Large code models (LCMs), pre-trained on vast code corpora, have demonstrated remarkable performance        across a wide array of code-related tasks. Supervised fine-tuning (SFT) plays a vital role in aligning these models        with specific requirements and enhancing their performance in particular domains. However, synthesizing        high-quality SFT datasets poses a significant challenge due to the uneven quality of datasets and the scarcity        of domain-specific datasets.        Inspired by APIs as high-level abstractions of code that encapsulate rich semantic information in a concise        structure, we propose DataScope, an API-guided dataset synthesis framework designed to enhance the SFT        process for LCMs in both general and domain-specific scenarios. DataScope comprises two main components:        Dslt and Dgen. On the one hand, Dslt employs API coverage as a core metric, enabling efficient dataset        synthesis in general scenarios by selecting subsets of existing (uneven-quality) datasets with higher API        coverage. On the other hand, Dgen recasts domain dataset synthesis as a process of using API-specified        high-level functionality and deliberately constituted code skeletons to synthesize concrete code.        Extensive experiments demonstrate DataScope’s effectiveness, with models fine-tuned on its synthesized        datasets outperforming those tuned on unoptimized datasets five times larger. Furthermore, a series of analyses        on model internals, relevant hyperparameters, and case studies provide additional evidence for the efficacy        of our proposed methods. These findings underscore the significance of dataset quality in SFT and advance        the field of LCMs by providing an efficient, cost-effective framework for constructing high-quality datasets,        which in turn lead to more powerful and tailored LCMs for both general and domain-specific scenarios.},
journal = {Proc. ACM Program. Lang.},
month = apr,
articleno = {108},
numpages = {30},
keywords = {API coverage, Code synthesis, Large code models}
}

@article{10.1145/3706119,
author = {Fatemi, Sorouralsadat and Hu, Yuheng and Mousavi, Maryam},
title = {A Comparative Analysis of Instruction Fine-Tuning Large Language Models for Financial Text Classification},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {2158-656X},
url = {https://doi.org/10.1145/3706119},
doi = {10.1145/3706119},
abstract = {Large Language Models (LLMs) have demonstrated impressive capabilities across diverse Natural Language Processing (NLP) tasks, including language understanding, reasoning, and generation. However, general-domain LLMs often struggle with financial tasks due to the technical and specialized nature of financial texts. This study investigates the efficacy of instruction fine-tuning smaller-scale LLMs, including Mistral-7B, Llama3-8B, and Phi3-mini, to enhance their performance in financial text classification tasks. We fine-tuned both instruction-tuned and base models across four financial classification tasks, achieving significant improvements in task-specific performance. Furthermore, we evaluated the zero-shot capabilities of these fine-tuned models on three unseen complex financial tasks, including argument classification, deal completeness classification, and causal classification. Our results indicate while base model fine-tuning led to greater degradation, instruction-tuned models maintained more robust performance. To address this degradation, we employed model merging techniques, integrating single-task domain-specific fine-tuned models with the base model. Using this merging method resulted in significant enhancements in zero-shot performance, even exceeding the original model’s accuracy on certain datasets. Our findings underscore the effectiveness of instruction fine-tuning and model merging for adapting LLMs to specialized financial text classification tasks.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = feb,
articleno = {6},
numpages = {30},
keywords = {Large language models, parameter-efficient fine-tuning, instruction fine-tuning, text classification, finance}
}

@inproceedings{10.1145/3677052.3698651,
author = {Chen, Zekai and Chen, Po-Yu and Buet-Golfouse, Francois},
title = {Online Personalizing White-box LLMs Generation with Neural Bandits},
year = {2024},
isbn = {9798400710810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677052.3698651},
doi = {10.1145/3677052.3698651},
abstract = {Personalized content generation by Large Language Models (LLMs) in finance presents a challenge: efficiently adapting text to individual preferences without creating unique models for each user. This study introduces an innovative online method for financial applications, employing neural bandit algorithms to dynamically optimize soft instruction embeddings based on user feedback, enhancing personalization in white-box LLMs. Through experiments on public generation tasks, we demonstrate significant performance improvements. Notably, our NeuralTS implementation achieves up to a 62.9\% improvement in ROUGE scores and a 2.76\% increase in LLM-agent evaluation for personalized content generation. This research showcases the efficacy of neural bandits in refining LLM outputs to align with client-specific needs and regulatory requirements, marking a pivotal step towards feasible and effective adaptive text generation in finance. Our method offers a promising and scalable solution for financial institutions to enhance client engagement, improve risk assessment, and streamline regulatory reporting.},
booktitle = {Proceedings of the 5th ACM International Conference on AI in Finance},
pages = {711–718},
numpages = {8},
keywords = {Large language models, multi-armed bandits, personalization},
location = {Brooklyn, NY, USA},
series = {ICAIF '24}
}

