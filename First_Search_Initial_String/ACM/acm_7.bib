@inproceedings{10.1145/3677052.3698671,
author = {Sarmah, Bhaskarjit and Mehta, Dhagash and Hall, Benika and Rao, Rohan and Patel, Sunil and Pasquali, Stefano},
title = {HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction},
year = {2024},
isbn = {9798400710810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677052.3698671},
doi = {10.1145/3677052.3698671},
abstract = {Extraction and interpretation of intricate information from unstructured text data arising in financial applications, such as earnings call transcripts, present substantial challenges to large language models (LLMs) even using the current best practices to use Retrieval Augmented Generation (RAG) (referred to as VectorRAG techniques which utilize vector databases for information retrieval) due to challenges such as domain specific terminology and complex formats of the documents. We introduce a novel approach based on a combination, called HybridRAG, of the Knowledge Graphs (KGs) based RAG techniques (called GraphRAG) and VectorRAG techniques to enhance question-answer (Q&amp;A) systems for information extraction from financial documents that is shown to be capable of generating accurate and contextually relevant answers. Using experiments on a set of financial earning call transcripts documents which come in the form of Q&amp;A format, and hence provide a natural set of pairs of ground-truth Q&amp;As, we show that HybridRAG which retrieves context from both vector database and KG outperforms both traditional VectorRAG and GraphRAG individually when evaluated at both the retrieval and generation stages in terms of retrieval accuracy and answer generation. The proposed technique has applications beyond the financial domain.},
booktitle = {Proceedings of the 5th ACM International Conference on AI in Finance},
pages = {608–616},
numpages = {9},
location = {Brooklyn, NY, USA},
series = {ICAIF '24}
}

@article{10.1145/3689789,
author = {Mariano, Benjamin and Wang, Ziteng and Pailoor, Shankara and Collberg, Christian and Dillig, I\c{s}il},
title = {Control-Flow Deobfuscation using Trace-Informed Compositional Program Synthesis},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {OOPSLA2},
url = {https://doi.org/10.1145/3689789},
doi = {10.1145/3689789},
abstract = {Code deobfuscation, which attempts to simplify code that has been intentionally obfuscated to prevent understanding, is a critical technique for downstream security analysis tasks like malware detection. While there has been significant prior work on code deobfuscation, most techniques either do not handle control flow obfuscations that modify control flow or they target specific classes of control flow obfuscations, making them unsuitable for handling new types of obfuscations or combinations of existing ones. In this paper, we study a new deobfuscation technique that is based on program synthesis and that can handle a broad class of control flow obfuscations. Given an obfuscated program P, our approach aims to synthesize a smallest program that is a control-flow reduction of P and that is semantically equivalent. Since our method does not assume knowledge about the types of obfuscations that have been applied to the original program, the underlying synthesis problem ends up being very challenging. To address this challenge, we propose a novel trace-informed compositional synthesis algorithm that leverages hints present in dynamic traces of the obfuscated program to decompose the synthesis problem into a set of simpler subproblems. In particular, we show how dynamic traces can be useful for inferring a suitable control-flow skeleton of the deobfuscated program and performing independent synthesis of each basic block. We have implemented this approach in a tool called Chisel and evaluate it on 546 benchmarks that have been obfuscated using combinations of six different obfuscation techniques. Our evaluation shows that our approach is effective and that it produces code that is almost identical (modulo variable renaming) to the original (non-obfuscated) program in 86\% of cases. Our evaluation also shows that Chisel significantly outperforms existing techniques.},
journal = {Proc. ACM Program. Lang.},
month = oct,
articleno = {349},
numpages = {31},
keywords = {Deobfuscation, Obfuscation, Program Synthesis}
}

@inproceedings{10.1145/3613904.3642055,
author = {Yu, Zhengyan and Namkung, Hun and Guo, Jiang and Milner, Henry and Goldfoot, Joel and Wang, Yang and Sekar, Vyas},
title = {SEAM-EZ: Simplifying Stateful Analytics through Visual Programming},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642055},
doi = {10.1145/3613904.3642055},
abstract = {Across many domains (e.g., media/entertainment, mobile apps, finance, IoT, cybersecurity), there is a growing need for stateful analytics over streams of events to meet key business outcomes. Stateful analytics over event streams entails carefully modeling the sequence, timing, and contextual correlations of events to dynamic attributes. Unfortunately, existing frameworks and languages (e.g., SQL, Flink, Spark) entail significant code complexity and expert effort to express such stateful analytics because of their dynamic and stateful nature. Our overarching goal is to simplify and democratize stateful analytics. Through an iterative design and evaluation process including a foundational user study and two rounds of formative evaluations with 15 industry practitioners, we created SEAM-EZ, a no-code visual programming platform for quickly creating and validating stateful metrics. SEAM-EZ features a node-graph editor, interactive tooltips, embedded data views, and auto-suggestion features to facilitate the creation and validation of stateful analytics. We then conducted three real-world case studies of SEAM-EZ with 20 additional practitioners. Our results suggest that practitioners who previously could not or had to spend significant effort to create stateful metrics using traditional tools such as SQL or Spark can now easily and quickly create and validate such metrics using SEAM-EZ.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {1041},
numpages = {23},
keywords = {data analytics, metrics, stateful computation, visual programming},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3745034.3745070,
author = {Huang, Runqing and Xu, Weicheng and Qi, Xianxian and Wang, Yu},
title = {Protein-Protein Interaction Extraction based on Multi-feature Fusion and Entity Enhancement},
year = {2025},
isbn = {9798400714399},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3745034.3745070},
doi = {10.1145/3745034.3745070},
abstract = {Relationships between protein entities are a crucial component of the biomedical knowledge system. However, this information is often embedded in unstructured text, making its automatic extraction and conversion into structured data essential for biomedical knowledge mining and downstream applications, such as drug discovery, disease research, and precision medicine. Accurate extraction of protein-protein interactions not only enhances the understanding of biological processes but also facilitates the development of computational models for predicting protein functions, identifying potential therapeutic targets, and understanding disease mechanisms at the molecular level. In this study, we propose a novel approach aimed at extracting relational information between protein entities. The deep semantics are effectively captured by combining contextual semantic information with detailed word-level features. Additionally, we introduce an enhanced protein entity recognition strategy, further improving the accuracy of protein entity relationship extraction. We evaluate the method on five standard datasets for protein-protein interaction (PPI) extraction. Experimental results demonstrate that the proposed model significantly outperforms existing approaches and achieves excellent performance in the PPI extraction task.},
booktitle = {Proceedings of the 4th International Conference on Biomedical and Intelligent Systems},
pages = {229–234},
numpages = {6},
keywords = {Entity enhancement, Feature fusion, PPI, Relation extraction},
location = {
},
series = {IC-BIS '25}
}

@inproceedings{10.1109/SCW63240.2024.00256,
author = {Vu, Anh Duc and Kehrer, Timo},
title = {Towards Generating Contracts for Scientific Data Analysis Workflows},
year = {2025},
isbn = {9798350355543},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SCW63240.2024.00256},
doi = {10.1109/SCW63240.2024.00256},
abstract = {To increase the dependability and portability of scientific data analysis workflows (DAWs), recent work has proposed contract-driven design of DAWs, providing verifiable expectations and obligations to ensure that tasks run in a proper environment and produce correct results. However, the specification of suitable contracts is still left to the discretion of DAW developers, imposing labor-intensive manual work which likely hampers the widespread adoption of contracts in scientific practice. We report about work-in-progress of developing a pipeline empowered by Large Language Models for automatically generating code contracts from logical workflow descriptions. We instantiate this pipeline within the workflow system Nextflow, and evaluate its contract generation capabilities in an experiment using real-world Nextflow modules. Our findings indicate that we generate a substantial amount of contracts serving as starting point for DAW developers. Our approach demonstrates potential in assisting domain scientists with contract-driven design of DAWs, laying the groundwork for its future adoption.},
booktitle = {Proceedings of the SC '24 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {2048–2055},
numpages = {8},
location = {Atlanta, GA, USA},
series = {SC-W '24}
}

@inproceedings{10.1145/3620666.3651351,
author = {Guan, Yue and Yu, Changming and Zhou, Yangjie and Leng, Jingwen and Li, Chao and Guo, Minyi},
title = {Fractal: Joint Multi-Level Sparse Pattern Tuning of Accuracy and Performance for DNN Pruning},
year = {2024},
isbn = {9798400703867},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3620666.3651351},
doi = {10.1145/3620666.3651351},
abstract = {Model pruning, which eliminates redundant parameters and reduces computational complexity, emerges as a viable strategy for efficient deep neural network (DNN) deployment. Owing to the irregular memory access and computation patterns in the sparse DNN models after pruning, existing arts have suggested various structured sparse patterns to enhance sparse DNN performance. In this work, we propose a unique perspective of understanding existing sparse pattern design as computation-skipping after tiling the tensor computation into multi-level hierarchies. This unified perspective opens up a new design space of multi-level sparse tiling to maximize the sparsity benefits of DNNs, as opposed to the single-level choice in current practices. We present Fractal, an auto-tuning system for sparse patterns that identifies the optimal multi-level sparse tiling pattern. We introduce PatternIR, a novel high-level intermediate representation (IR), to express a diverse range of multi-level sparse patterns. By leveraging insights from prior dense operator optimizations, we translate PatternIR into low-level compiler IRs, facilitating further operator optimization and code generation. Our evaluations demonstrate that Fractal yields substantial speedups of up to on average 3.16\texttimes{} on CUDA Core, 2.52\texttimes{} on TensorCore of GPUs compared to the state-of-art dense baseline under 75\% sparsity while upholding minimal accuracy degradation compared to prior sparse operator libraries.},
booktitle = {Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
pages = {416–430},
numpages = {15},
keywords = {structural pruning, sparse tensor compiler, sparse computation acceleration, deep learning},
location = {La Jolla, CA, USA},
series = {ASPLOS '24}
}

@article{10.1145/3729287,
author = {Wang, Bo and Li, Tianyu and Li, Ruishi and Mathur, Umang and Saxena, Prateek},
title = {Program Skeletons for Automated Program Translation},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {PLDI},
url = {https://doi.org/10.1145/3729287},
doi = {10.1145/3729287},
abstract = {Translating software between programming languages is a challenging task, for which automated techniques have been elusive and hard to scale up to larger programs. A key difficulty in cross-language translation is that one has to re-express the intended behavior of the source program into idiomatic constructs of a different target language. This task needs abstracting away from the source language-specific details, while keeping the overall functionality the same. In this work, we propose a novel and systematic approach for making such translation amenable to automation based on a framework we call program skeletons. A program skeleton retains the high-level structure of the source program by abstracting away and effectively summarizing lower-level concrete code fragments, which can be mechanically translated to the target programming language. A skeleton, by design, permits many different ways of filling in the concrete implementation for fragments, which can work in conjunction with existing data-driven code synthesizers. Most importantly, skeletons can conceptually enable sound decomposition, i.e., if each individual fragment is correctly translated, taken together with the mechanically translated skeleton, the final translated program is deemed to be correct as a whole. We present a prototype system called SKEL embodying the idea of skeleton-based translation from Python to JavaScript. Our results show promising scalability compared to prior works. For 9 real-world Python programs, some with more than about 1k lines of code, 95\% of their code fragments can be automatically translated, while about 5\% require manual effort. All the final translations are correct with respect to whole-program test suites.},
journal = {Proc. ACM Program. Lang.},
month = jun,
articleno = {184},
numpages = {25},
keywords = {Large Language Models, Program Synthesis, Program Translation}
}

@article{10.1145/3689799,
author = {Drosos, Georgios-Petros and Sotiropoulos, Thodoris and Alexopoulos, Georgios and Mitropoulos, Dimitris and Su, Zhendong},
title = {When Your Infrastructure Is a Buggy Program: Understanding Faults in Infrastructure as Code Ecosystems},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {OOPSLA2},
url = {https://doi.org/10.1145/3689799},
doi = {10.1145/3689799},
abstract = {Modern applications have become increasingly complex and their manual installation and configuration is  no longer practical. Instead, IT organizations heavily rely on Infrastructure as Code (IaC) technologies, to automate the provisioning, configuration, and maintenance of computing infrastructures and systems. IaC systems typically offer declarative, domain-specific languages (DSLs) that allow system administrators and developers to write high-level programs that specify the desired state of their infrastructure in a reliable, predictable, and documented fashion. Just like traditional programs, IaC software is not immune to faults, with issues ranging from deployment failures to critical misconfigurations that often impact production systems used by millions of end users. Surprisingly, despite its crucial role in global infrastructure management, the tooling and techniques for ensuring IaC reliability still have room for improvement.     In this work, we conduct a comprehensive analysis of 360 bugs identified in IaC software within prominent IaC ecosystems including Ansible, Puppet, and Chef. Our work is the first in-depth exploration of bug characteristics in these widely-used IaC environments. Through our analysis we aim to understand: (1) how these bugs manifest, (2) their underlying root causes, (3) their reproduction requirements in terms of system state (e.g., operating system versions) or input characteristics, and (4) how these bugs are fixed. Based on our findings, we evaluate the state-of-the-art techniques for IaC reliability, identify their limitations, and provide a set of recommendations for future research. We believe that our study helps researchers to (1) better understand the complexity and peculiarities of IaC software, and (2) develop advanced tooling for more reliable and robust system configurations.},
journal = {Proc. ACM Program. Lang.},
month = oct,
articleno = {359},
numpages = {31},
keywords = {Ansible, Chef, IaC, Puppet, bug, deployment, infrastructure as code, testing}
}

@inproceedings{10.1145/3726010.3726012,
author = {Liu, Fei and Ren, Huanhuan and Guan, Yu and Li, Na},
title = {Enhancing Automotive PDF Chatbots: A Graph RAG Approach with Custom Function Calling for Locally Deployed Ollama Models},
year = {2025},
isbn = {9798400712845},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3726010.3726012},
doi = {10.1145/3726010.3726012},
abstract = {This research explores state-of-the-art retrieval augmented generation (RAG) methodologies utilizing a locally hosted Ollama model to address the rising demand for streamlined offline PDF chatbots in the automotive industry. In this paper we present a Langchain-based optimization of the a forementioned framework for modeling all input text from automotive documents. For example, using JoinChpy which use specialized finetuning to a base model where it is fine-tuned adding specialized modifications, the first on PDF and retrieval algorithms as well as context compression strictly for automotive literature We define embedding pipeline classes and graph RAG agents.To instantiate our methodology, we developed our own automotive industry document dataset and compared the enhanced graph RAG and self-RAG agents with the original RAG baseline on our automotive dataset as well as QuAC and CANARD. The results demonstrate a consistent increase along the dimensions, in correctness, swiftness, relevance, and fidelity, specifically for automotive domain specific content. Hence offering a guideline on how to implement a local RAG in automotive setting, thus serving as a significant contribution to the research in an industrial context to process information and make a step towards smart manufacturing.},
booktitle = {Proceedings of the 2024 International Conference on Artificial Intelligence, Digital Media Technology and Interaction Design},
pages = {6–13},
numpages = {8},
keywords = {Automotive Industry, Graph RAG, Langchain, Ollama, PDF Processing},
location = {
},
series = {ICADI '24}
}

@inproceedings{10.1145/3626246.3653378,
author = {Pavlenko, Anna and Cahoon, Joyce and Zhu, Yiwen and Kroth, Brian and Nelson, Michael and Carter, Andrew and Liao, David and Wright, Travis and Camacho-Rodr\'{\i}guez, Jes\'{u}s and Saur, Karla},
title = {Vertically Autoscaling Monolithic Applications with CaaSPER: Scalable Container-as-a-Service Performance Enhanced Resizing Algorithm for the Cloud},
year = {2024},
isbn = {9798400704222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626246.3653378},
doi = {10.1145/3626246.3653378},
abstract = {Kubernetes has emerged as a prominent open-source platform for managing cloud applications, including stateful databases. These monolithic applications rely on vertical scaling, adjusting CPU cores based on load fluctuations. However, our analysis of Kubernetes-based Database-as-a-Service (DBaaS) offerings at Microsoft revealed that many customers consistently over-provision resources for peak workloads, neglecting cost-saving opportunities through resource scale-down. We found that there is a gap in the ability of existing vertical autoscaling tools to minimize resource slack and respond promptly to throttling, leading to increased costs and impacting crucial metrics such as throughput and availability.To address this challenge, we propose CaaSPER, a vertical autoscaling algorithm that blends reactive and proactive strategies. By dynamically adjusting CPU resources, CaaSPER minimizes resource slack, maintains optimal CPU utilization, and reduces throttling. Importantly, customers have the flexibility to prioritize either cost savings or high performance based on their preferences. Extensive testing demonstrates that CaaSPER effectively reduces throttling and keeps CPU utilization within target levels. CaaSPER is designed to be application-agnostic and platform-agnostic, with potential for extension to other applications requiring vertical autoscaling.},
booktitle = {Companion of the 2024 International Conference on Management of Data},
pages = {241–254},
numpages = {14},
keywords = {containers, kubernetes, resource optimization, vertical auto-scaling},
location = {Santiago AA, Chile},
series = {SIGMOD '24}
}

@inproceedings{10.1145/3711896.3737233,
author = {Ghassel, Abdellah and Robinson, Ian and Tanase, Gabriel and Cooper, Hal and Thompson, Bryan and Han, Zhen and Ioannidis, Vassilis and Adeshina, Soji and Rangwala, Huzefa},
title = {Hierarchical Lexical Graph for Enhanced Multi-Hop Retrieval},
year = {2025},
isbn = {9798400714542},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711896.3737233},
doi = {10.1145/3711896.3737233},
abstract = {Retrieval-Augmented Generation (RAG) grounds large language models in external evidence, yet it still falters when answers must be pieced together across semantically distant documents. We close this gap with the Hierarchical Lexical Graph (HLG), a three-tier index that (i) traces every atomic proposition to its source(ii) clusters propositions into latent topics, and (iii) links entities and relations to expose cross-document paths. On top of HLG we build two complementary, plug-and-play retrievers: StatementGraphRAG, which performs fine-grained entity-aware beam search over propositions for high-precision factoid questions, and TopicGraphRAG, which selects coarse topics before expanding along entity links to supply broad yet relevant context for exploratory queries. Additionally, existing benchmarks lack the complexity required to rigorously evaluate multi-hop summarization systems, often focusing on single-document queries or limited datasets. To address this, we introduce a synthetic dataset generation pipeline that curates realistic, multi-document question-answer pairs, enabling robust evaluation of multi-hop retrieval systems. Extensive experiments across five datasets demonstrate that our methods outperform naive chunk-based RAG, achieving an average relative improvement of 23.1\% in retrieval recall and correctness. Open-source Python library is available at https://github.com/awslabs/graphrag-toolkit.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2},
pages = {4457–4466},
numpages = {10},
keywords = {data generation, graph structures, question answering},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3626246.3653389,
author = {de la R\'{u}a Mart\'{\i}nez, Javier and Buso, Fabio and Kouzoupis, Antonios and Ormenisan, Alexandru A. and Niazi, Salman and Bzhalava, Davit and Mak, Kenneth and Jouffrey, Victor and Ronstr\"{o}m, Mikael and Cunningham, Raymond and Zangis, Ralfs and Mukhedkar, Dhananjay and Khazanchi, Ayushman and Vlassov, Vladimir and Dowling, Jim},
title = {The Hopsworks Feature Store for Machine Learning},
year = {2024},
isbn = {9798400704222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626246.3653389},
doi = {10.1145/3626246.3653389},
abstract = {Data management is the most challenging aspect of building Machine Learning (ML) systems. ML systems can read large volumes of historical data when training models, but inference workloads are more varied, depending on whether it is a batch or online ML system. The feature store for ML has recently emerged as a single data platform for managing ML data throughout the ML lifecycle, from feature engineering to model training to inference.  In this paper, we present the Hopsworks feature store for machine learning as a highly available platform for managing feature data with API support for columnar, row-oriented, and similarity search query workloads. We introduce and address challenges solved by the feature stores related to feature reuse, how to organize data transformations, and how to ensure correct and consistent data between feature engineering, model training, and model inference. We present the engineering challenges in building high-performance query services for a feature store and show how Hopsworks outperforms existing cloud feature stores for training and online inference query workloads.},
booktitle = {Companion of the 2024 International Conference on Management of Data},
pages = {135–147},
numpages = {13},
keywords = {arrow flight, duckdb, feature store, mlops, rondb},
location = {Santiago AA, Chile},
series = {SIGMOD '24}
}

@inproceedings{10.1145/3613424.3623794,
author = {Xu, Ceyu and Sharma, Pragya and Wang, Tianshu and Wills, Lisa Wu},
title = {Fast, Robust and Transferable Prediction for Hardware Logic Synthesis},
year = {2023},
isbn = {9798400703294},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613424.3623794},
doi = {10.1145/3613424.3623794},
abstract = {The increasing complexity of computer chips and the slow logic synthesis process have become major bottlenecks in the hardware design process, also hindering the ability of hardware generators to make informed design decisions while considering hardware costs. While various models have been proposed to predict physical characteristics of hardware designs, they often suffer from limited domain adaptability and open-source hardware design data scarcity. In this paper, we present SNS v2, a fast, robust, and transferable hardware synthesis predictor based on deep learning models. Inspired by modern natural language processing models, SNS v2 adopts a three-phase training approach encompassing pre-training, fine-tuning, and domain adaptation, enabling it to leverage more abundant unlabeled and off-domain training data. Additionally, we propose a novel contrastive learning approach based on circuit equivalence to enhance model robustness. Our experiments demonstrate that SNS v2 achieves two to three orders of magnitude faster speed compared to conventional EDA tools, while maintaining state-of-the-art prediction accuracy. We also show that SNS v2 can be seamlessly integrated into hardware generator frameworks for real-time cost estimation, resulting in higher quality design recommendations in a significantly reduced time frame.},
booktitle = {Proceedings of the 56th Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {167–179},
numpages = {13},
keywords = {Integrated Circuits, Logic Synthesis Prediction, Neural Networks, RTL-level Synthesis},
location = {Toronto, ON, Canada},
series = {MICRO '23}
}

@article{10.1145/3689754,
author = {Bembenek, Aaron and Greenberg, Michael and Chong, Stephen},
title = {Making Formulog Fast: An Argument for Unconventional Datalog Evaluation},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {OOPSLA2},
url = {https://doi.org/10.1145/3689754},
doi = {10.1145/3689754},
abstract = {With its combination of Datalog, SMT solving, and functional programming, the language Formulog provides an appealing mix of features for implementing SMT-based static analyses (e.g., refinement type checking, symbolic execution) in a natural, declarative way. At the same time, the performance of its custom Datalog solver can be an impediment to using Formulog beyond prototyping—a common problem for Datalog variants that aspire to solve large problem instances. In this work we speed up Formulog evaluation, with some surprising results: while 2.2\texttimes{} speedups can be obtained by using the conventional techniques for high-performance Datalog (e.g., compilation, specialized data structures), the big wins come by abandoning the central assumption in modern performant Datalog engines, semi-naive Datalog evaluation. In the place of semi-naive evaluation, we develop eager evaluation, a concurrent Datalog evaluation algorithm that explores the logical inference space via a depth-first traversal order. In practice, eager evaluation leads to an advantageous distribution of Formulog’s SMT workload to external SMT solvers and improved SMT solving times: our eager evaluation extensions to the Formulog interpreter and Souffl\'{e}’s code generator achieve mean 5.2\texttimes{} and 7.6\texttimes{} speedups, respectively, over the optimized code generated by off-the-shelf Souffl\'{e} on SMT-heavy Formulog benchmarks.                                All in all, using compilation and eager evaluation (as appropriate), Formulog implementations of refinement type checking, bottom-up pointer analysis, and symbolic execution achieve speedups on 20 out of 23 benchmarks over previously published, hand-tuned analyses written in F♯, Java, and C++, providing strong evidence that Formulog can be the basis of a realistic platform for SMT-based static analysis. Moreover, our experience adds nuance to the conventional wisdom that traditional semi-naive evaluation is the one-size-fits-all best Datalog evaluation algorithm for static analysis workloads.},
journal = {Proc. ACM Program. Lang.},
month = oct,
articleno = {314},
numpages = {30},
keywords = {Datalog, Formulog, SMT solving, compilation, parallel evaluation}
}

@inproceedings{10.1145/3661167.3661233,
author = {Phan, Hung and Jannesari, Ali},
title = {Leveraging Statistical Machine Translation for Code Search},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661233},
doi = {10.1145/3661167.3661233},
abstract = {Machine Translation (MT) has numerous applications in Software Engineering (SE). Recently, it has been employed not only for programming language translation but also as an oracle for deriving information for various research problems in SE. In this application branch, MT’s impact has been assessed through metrics measuring the accuracy of these problems rather than traditional translation evaluation metrics. For code search, a recent work, ASTTrans, introduced an MT-based model for extracting relevant non-terminal nodes from the Abstract Syntax Tree (AST) of an implementation based on natural language descriptions. While ASTTrans demonstrated the effectiveness of MT in enhancing code search on small datasets with low embedding dimensions, it struggled to improve the accuracy of code search on the standard benchmark CodeSearchNet. In this work, we present Oracle4CS, a novel approach that integrates the classical MT model called Statistical Machine Translation to support modernized models for code search. To accomplish this, we introduce a new code representation technique called ASTSum, which summarizes each code snippet using a limited number of AST nodes. Additionally, we devise a fresh approach to code search, replacing natural language queries with a new representation that incorporates the results of our query-to-ASTSum translation process. Through experiments, we demonstrate that Oracle4CS can enhance code search performance on both the original BERT-based model UniXcoder and the optimized BERT-based model CoCoSoDa by up to 1.18\% and 2\% in Mean Reciprocal Rank (MRR) across eight selected well-known datasets. We also explore ASTSum as a promising code representation for supporting code search, potentially improving MRR by over 17\% on average when paired with an optimal SMT model for query-to-ASTSum translation.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {191–200},
numpages = {10},
keywords = {Abstract Syntax Tree, Information Retrieval, Statistical Machine Translation},
location = {Salerno, Italy},
series = {EASE '24}
}

@article{10.1109/TASLP.2023.3250825,
author = {Zhang, Chen and D'Haro, Luis Fernando and Zhang, Qiquan and Friedrichs, Thomas and Li, Haizhou},
title = {PoE: A Panel of Experts for Generalized Automatic Dialogue Assessment},
year = {2023},
issue_date = {2023},
publisher = {IEEE Press},
volume = {31},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2023.3250825},
doi = {10.1109/TASLP.2023.3250825},
abstract = {Chatbots are expected to be knowledgeable across multiple domains, e.g. for daily chit-chat, exchange of information, and grounding in emotional situations. To effectively measure the quality of such conversational agents, a model-based automatic dialogue evaluation metric (ADEM) is expected to perform well across multiple domains. Despite significant progress, existing ADEMs tend to perform well only on data that are similar to its training data (overfit to its training domain). This calls for a domain-generalized metric that can assess dialogues of different characteristics. To this end, we propose a &lt;italic&gt;Panel of Experts&lt;/italic&gt; (PoE), a multitask network that consists of a shared transformer encoder and a collection of lightweight adapters. The shared encoder captures the general knowledge of dialogues across domains, while each adapter specializes in one specific domain and serves as a domain expert. To validate the idea, we construct a high-quality multi-domain dialogue dataset leveraging data augmentation and pseudo-labeling. The PoE network is comprehensively assessed on 16 dialogue evaluation datasets spanning a wide range of dialogue domains. It achieves state-of-the-art performance in terms of mean Spearman correlation over all the evaluation datasets. It exhibits better zero-shot generalization than existing state-of-the-art ADEMs and the ability to easily adapt to new domains with few-shot transfer learning.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = mar,
pages = {1234–1250},
numpages = {17}
}

@inproceedings{10.1145/3637528.3671801,
author = {Zhang, Wentao and Zhao, Lingxuan and Xia, Haochong and Sun, Shuo and Sun, Jiaze and Qin, Molei and Li, Xinyi and Zhao, Yuqing and Zhao, Yilei and Cai, Xinyu and Zheng, Longtao and Wang, Xinrun and An, Bo},
title = {A Multimodal Foundation Agent for Financial Trading: Tool-Augmented, Diversified, and Generalist},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671801},
doi = {10.1145/3637528.3671801},
abstract = {Financial trading is a crucial component of the markets, informed by a multimodal information landscape encompassing news, prices, and Kline charts, and encompasses diverse tasks such as quantitative trading and high-frequency trading with various assets. While advanced AI techniques like deep learning and reinforcement learning are extensively utilized in finance, their application in financial trading tasks often faces challenges due to inadequate handling of multimodal data and limited generalizability across various tasks. To address these challenges, we present FinAgent, a multimodal foundational agent with tool augmentation for financial trading. FinAgent's market intelligence module processes a diverse range of data-numerical, textual, and visual-to accurately analyze the financial market. Its unique dual-level reflection module not only enables rapid adaptation to market dynamics but also incorporates a diversified memory retrieval system, enhancing the agent's ability to learn from historical data and improve decision-making processes. The agent's emphasis on reasoning for actions fosters trust in its financial decisions. Moreover, FinAgent integrates established trading strategies and expert insights, ensuring that its trading approaches are both data-driven and rooted in sound financial principles. With comprehensive experiments on 6 financial datasets, including stocks and Crypto, FinAgent significantly outperforms 12 state-of-the-art baselines in terms of 6 financial metrics with over 36\% average improvement on profit. Specifically, a 92.27\% return (a 84.39\% relative improvement) is achieved on one dataset. Notably, FinAgent is the first advanced multimodal foundation agent designed for financial trading tasks.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4314–4325},
numpages = {12},
keywords = {financial ai agents, large language models, quantitative trading},
location = {Barcelona, Spain},
series = {KDD '24}
}

@article{10.1145/3485477,
author = {Verbruggen, Gust and Le, Vu and Gulwani, Sumit},
title = {Semantic programming by example with pre-trained models},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {OOPSLA},
url = {https://doi.org/10.1145/3485477},
doi = {10.1145/3485477},
abstract = {The ability to learn programs from few examples is a powerful technology with disruptive applications in many domains, as it allows users to automate repetitive tasks in an intuitive way. Existing frameworks on inductive synthesis only perform syntactic manipulations, where they rely on the syntactic structure of the given examples and not their meaning. Any semantic manipulations, such as transforming dates, have to be manually encoded by the designer of the inductive programming framework. Recent advances in large language models have shown these models to be very adept at performing semantic transformations of its input by simply providing a few examples of the task at hand. When it comes to syntactic transformations, however, these models are limited in their expressive power. In this paper, we propose a novel framework for integrating inductive synthesis with few-shot learning language models to combine the strength of these two popular technologies. In particular, the inductive synthesis is tasked with breaking down the problem in smaller subproblems, among which those that cannot be solved syntactically are passed to the language model. We formalize three semantic operators that can be integrated with inductive synthesizers. To minimize invoking expensive semantic operators during learning, we introduce a novel deferred query execution algorithm that considers the operators to be oracles during learning. We evaluate our approach in the domain of string transformations: the combination methodology can automate tasks that cannot be handled using either technologies by themselves. Finally, we demonstrate the generality of our approach via a case study in the domain of string profiling.},
journal = {Proc. ACM Program. Lang.},
month = oct,
articleno = {100},
numpages = {25},
keywords = {programming by example, program synthesis, language models}
}

@inproceedings{10.1145/3624062.3626283,
author = {Bader, Jonathan and Belak, Jim and Bement, Matthew and Berry, Matthew and Carson, Robert and Cassol, Daniela and Chan, Stephen and Coleman, John and Day, Kastan and Duque, Alejandro and Fagnan, Kjiersten and Froula, Jeff and Jha, Shantenu and Katz, Daniel S. and Kica, Piotr and Kindratenko, Volodymyr and Kirton, Edward and Kothadia, Ramani and Laney, Daniel and Lehmann, Fabian and Leser, Ulf and Licho\l{}ai, Sabina and Malawski, Maciej and Melara, Mario and Player, Elais and Rolchigo, Matt and Sarrafan, Setareh and Sul, Seung-Jin and Syed, Abdullah and Thamsen, Lauritz and Titov, Mikhail and Turilli, Matteo and Caino-Lores, Silvina and Mandal, Anirban},
title = {Novel Approaches Toward Scalable Composable Workflows in Hyper-Heterogeneous Computing Environments},
year = {2023},
isbn = {9798400707858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624062.3626283},
doi = {10.1145/3624062.3626283},
abstract = {The annual Workshop on Workflows in Support of Large-Scale Science (WORKS) is a premier venue for the scientific workflow community to present the latest advances in research and development on the many facets of scientific workflows throughout their life-cycle. The Lightning Talks at WORKS focus on describing a novel tool, scientific workflow, or concept, which are work-in-progress and address emerging technologies and frameworks to foster discussion in the community. This paper summarizes the lightning talks at the 2023 edition of WORKS, covering five topics: leveraging large language models to build and execute workflows; developing a common workflow scheduler interface; scaling uncertainty workflow applications on exascale computing systems; evaluating a transcriptomics workflow for cloud vs. HPC systems; and best practices in migrating legacy workflows to workflow management systems.},
booktitle = {Proceedings of the SC '23 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {2097–2108},
numpages = {12},
keywords = {Scientific workflows, cloud computing, high-performance computing, large language models, legacy workflows., workflow scheduling},
location = {Denver, CO, USA},
series = {SC-W '23}
}

@inproceedings{10.1145/3689493.3689980,
author = {Gordon, Colin S.},
title = {Mocking Temporal Logic},
year = {2024},
isbn = {9798400712166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689493.3689980},
doi = {10.1145/3689493.3689980},
abstract = {Temporal logics cover important classes of system specifications dealing with system behavior over time. Despite the prevalence of long-running systems that accept repeated input and output, and thus the clear relevance of temporal specifications to training software engineers, temporal logics are rarely taught to undergraduates.    We motivate and describe an approach to teaching temporal specifications and temporal reasoning indirectly through teaching students about mocking dependencies, which is widely used in software testing of large systems (and therefore of more obvious relevance to students), less notationally intimidating to students, and still teaches similar reasoning principles. We report on 7 years of experience using this indirect approach to behavioral specifications in a software quality course.},
booktitle = {Proceedings of the 2024 ACM SIGPLAN International Symposium on SPLASH-E},
pages = {98–109},
numpages = {12},
keywords = {software engineering education, software specification, software testing, temporal logic},
location = {Pasadena, CA, USA},
series = {SPLASH-E '24}
}

@article{10.1145/3705306,
author = {Reiss, Steven P. and Wei, Xuan and Yuan, Jiahao and Xin, Qi},
title = {ROSE: An IDE-Based Interactive Repair Framework for Debugging},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3705306},
doi = {10.1145/3705306},
abstract = {Debugging is costly. Automated program repair (APR) holds the promise of reducing its cost by automatically fixing errors. However, current techniques are not easily applicable in a realistic debugging scenario because they assume a high-quality test suite and frequent program re-execution, have low repair efficiency, and only handle a limited set of errors. To improve the practicality of APR for debugging, we propose ROSE, an interactive repair framework that is able to suggest quick and effective repairs of semantic errors while debugging in an Integrated Development Environment (IDE). ROSE allows an easy integration of existing APR patch generators and can do program repair without assuming the existence of a test suite and without requiring program re-execution. It works in conjunction with an IDE debugger and assumes a debugger stopping point where a problem symptom is observed. ROSE asks the developer to quickly describe the symptom. Then it uses the stopping point, the identified symptom, and the current environment to identify potentially faulty lines, uses a variety of APR techniques to suggest repairs at those lines, and validates those repairs without re-executing the program. Finally, it presents the results so the developer can examine, select, and make the appropriate repair. ROSE uses novel approaches to achieve effective fault localization and patch validation without a test suite or program re-execution. For fault localization, ROSE builds on a fast abstract interpretation-based flow analysis to compute a static backward slice approximating the real dynamic slice while taking into account the symptom and the current execution. For patch validation without re-running the program, ROSE generates simulated traces based on a live-programming system for both the original and repaired executions and compares the traces with respect to the problem symptoms to infer patch correctness. We implemented a prototype of ROSE that works in an Eclipse-based IDE and evaluated its potency and utility with an effectiveness study and a user study. We found that ROSE’s fault localization and validation are highly effective and a ROSE-based tool using existing APR patch generators generated correct repair suggestions for many errors in only seconds. Moreover, the user study demonstrated that ROSE was helpful for debugging and developers liked to use it.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {112},
numpages = {39},
keywords = {Debugging, Interactive Repair Framework, Automated Program Repair, Integrated Development Environment}
}

@article{10.1145/3591280,
author = {Li, Ziyang and Huang, Jiani and Naik, Mayur},
title = {Scallop: A Language for Neurosymbolic Programming},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {PLDI},
url = {https://doi.org/10.1145/3591280},
doi = {10.1145/3591280},
abstract = {We present Scallop, a language which combines the benefits of deep learning and logical reasoning. Scallop enables users to write a wide range of neurosymbolic applications and train them in a data- and compute-efficient manner. It achieves these goals through three key features: 1) a flexible symbolic representation that is based on the relational data model; 2) a declarative logic programming language that is based on Datalog and supports recursion, aggregation, and negation; and 3) a framework for automatic and efficient differentiable reasoning that is based on the theory of provenance semirings. We evaluate Scallop on a suite of eight neurosymbolic applications from the literature. Our evaluation demonstrates that Scallop is capable of expressing algorithmic reasoning in diverse and challenging AI tasks, provides a succinct interface for machine learning programmers to integrate logical domain knowledge, and yields solutions that are comparable or superior to state-of-the-art models in terms of accuracy. Furthermore, Scallop's solutions outperform these models in aspects such as runtime and data efficiency, interpretability, and generalizability.},
journal = {Proc. ACM Program. Lang.},
month = jun,
articleno = {166},
numpages = {25},
keywords = {Neurosymbolic methods, Differentiable reasoning}
}

@article{10.1145/3664522,
author = {Tsiakas, Konstantinos and Murray-Rust, Dave},
title = {Unpacking Human-AI interactions: From Interaction Primitives to a Design Space},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {3},
issn = {2160-6455},
url = {https://doi.org/10.1145/3664522},
doi = {10.1145/3664522},
abstract = {This article aims to develop a semi-formal representation for Human-AI (HAI) interactions, by building a set of interaction primitives which can specify the information exchanges between users and AI systems during their interaction. We show how these primitives can be combined into a set of interaction patterns which can capture common interactions between humans and AI/ML models. The motivation behind this is twofold: firstly, to provide a compact generalization of existing practices for the design and implementation of HAI interactions; and secondly, to support the creation of new interactions by extending the design space of HAI interactions. Taking into consideration frameworks, guidelines, and taxonomies related to human-centered design and implementation of AI systems, we define a vocabulary for describing information exchanges based on the model’s characteristics and interactional capabilities. Based on this vocabulary, a message passing model for interactions between humans and models is presented, which we demonstrate can account for existing HAI interaction systems and approaches. Finally, we build this into design patterns which can describe common interactions between users and models, and we discuss how this approach can be used toward a design space for HAI interactions that creates new possibilities for designs as well as keeping track of implementation issues and concerns.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = aug,
articleno = {18},
numpages = {51},
keywords = {Human-AI interaction, interaction patterns, explainable AI, human-in-the-loop, hybrid intelligence}
}

@article{10.1145/3704740,
author = {Pathak, Agnibh and Bhattacharjee, Soham and Saha, Tulika and Saha, Sriparna},
title = {Do Sentiment and Emotion Affect Mental Health? A Multi-task Classification Framework for Comprehensive Understanding of Mental Health, Emotion, and Sentiment from Motivational Conversations},
year = {2025},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {2},
url = {https://doi.org/10.1145/3704740},
doi = {10.1145/3704740},
abstract = {In light of the escalating challenges posed by our modern lifestyle, cultivating a nuanced approach for addressing mental health issues becomes imperative. Navigating the complexities of daily life demands a thoughtful and comprehensive strategy to identify and address the diverse array of mental health issues that may manifest. The challenges in accurately identifying mental health expressions stem from their complex character of communication, which frequently shares linguistic patterns and similar expressive nuances as communicated by humans. However, we hypothesize that mental health conditions are closely associated with affective factors in particular feelings, moods, and emotions. These states define how we think, feel, and behave. Thus, in this article, we aim to explore and analyze the association of the affective states such as sentiment and emotion with mental health in the view of identifying mental health conditions accurately once the feelings and emotions of humans are understood. In this regard, this article investigates multi-task classification encompassing mental health disorder identification (MHDI), emotion recognition (ER), and sentiment analysis (SA) in non-clinical conversations where MHDI forms the primary task and ER-SA the auxiliary tasks boosting the identification of the primary one. To demonstrate our hypothesis, we propose Core Fusion Network (CFN), a variation of multi-tasking in light of the significance that sentiment and emotion plays in understanding mental health. This method adeptly considers private and shared features across tasks, significantly enhancing classification precision. For our study, we extend the recently released MotiVAte dataset containing dyadic conversations between support seekers and a virtual assistant imparting hope and motivation to enclose emotion and sentiment tags for each conversation in a semi-supervised manner. Our hypothesis is reinforced by an extensive ablation study with state-of-the-art multi-task models and the proposed Core Fusion Network (CFN), which exhibits increased accuracy of 89.12\% for MHDI, 64.24\% for ER, and 79.04\% for SA in the tri-task variant as opposed to its corresponding uni-task and bi-task variants. These outcomes underscore the potential of multi-task learning in streamlining mental health classification by integrating emotional and sentiment dimensions.},
journal = {ACM Trans. Comput. Healthcare},
month = apr,
articleno = {28},
numpages = {16},
keywords = {Mental Health Disorder, Emotion, Sentiment, Dialogue, Multi-task Learning, Classification}
}

@inproceedings{10.1145/3712716.3712726,
author = {Korol, Allan and Sikos, Leslie F.},
title = {FEAR: A Novel Framework for Representing Digital Forensic Artifacts in Knowledge Graphs},
year = {2025},
isbn = {9798400710766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3712716.3712726},
doi = {10.1145/3712716.3712726},
abstract = {In digital forensics, knowledge graphs have demonstrated significant potential via software agent automation and knowledge discovery using encoded expert knowledge in, for example, the form of Semantic Web rules. These advancements have been limited in terms of efficiently encoding extracted digital artifacts into graph representation, the associated overhead of implementing frameworks to handle digital forensic evidence, and the lack of sharing of such code that is often a preamble to other research. This paper introduces a digital forensic framework, Forensic Extraction and Representation (FEAR), that enables a simplified process of accessing and encoding extracted digital forensic artifacts in semantic knowledge graphs. The adoption of such a framework can facilitate the sharing of expert knowledge and reduce the burden of development for researchers exploring the application of knowledge graphs, software agents, and automated reasoning in the field of digital forensics, while accelerating the adoption of emerging research by practitioners.},
booktitle = {Proceedings of the Digital Forensics Doctoral Symposium},
articleno = {9},
numpages = {8},
keywords = {digital forensic artifacts, semantic knowledge graph, digital forensic software agent, digital forensic framework, declarative language},
location = {
},
series = {DFDS '25}
}

@inproceedings{10.1145/3594536.3595162,
author = {Servantez, Sergio and Lipka, Nedim and Siu, Alexa and Aggarwal, Milan and Krishnamurthy, Balaji and Garimella, Aparna and Hammond, Kristian and Jain, Rajiv},
title = {Computable Contracts by Extracting Obligation Logic Graphs},
year = {2023},
isbn = {9798400701979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594536.3595162},
doi = {10.1145/3594536.3595162},
abstract = {The emergence of contract specific programming languages has struggled to translate into widespread adoption of computable contracts due largely to high conversion costs. In this work, we present the first system for converting natural language contracts into code through the extraction of key entities, relationships, and formulas into a graph representation called the Obligation Logic Graph (OLG). This approach allows the semantic meaning of contract obligations, including dependencies between obligations, to be captured through the OLG and mapped to code downstream. We also introduce OLG extraction as a new joint entity and relation prediction task for legal contracts, and present the Contract-OLG dataset, consisting of 1,876 contract provisions, 18,597 entities and 18,170 relationships. We perform detailed experiments to understand the capabilities of state-of-the-art Transformer and graph-based models at completing these tasks, and identify where there is currently a significant gap between human expert and machine performance, particularly for relation extraction.},
booktitle = {Proceedings of the Nineteenth International Conference on Artificial Intelligence and Law},
pages = {267–276},
numpages = {10},
keywords = {computable contracts, information extraction, natural language processing, obligation logic graph},
location = {Braga, Portugal},
series = {ICAIL '23}
}

@article{10.1145/3588958,
author = {Miao, Xiaoye and Wu, Yangyang and Peng, Jiazhen and Gao, Yunjun and Yin, Jianwei},
title = {Efficient and Effective Cardinality Estimation for Skyline Family},
year = {2023},
issue_date = {May 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {1},
url = {https://doi.org/10.1145/3588958},
doi = {10.1145/3588958},
abstract = {Cardinality estimation, predicting the query result size, is a fundamental problem in databases. Existing skyline cardinality estimation methods are computationally infeasible for massive skyline queries over the large-scale database. In this paper, we introduce a unified skyline family w.r.t. various skyline variants. We propose an efficient and effective skyline family cardinality estimation model, named EECE, in an end-to-end manner. EECE consists of two modules, unsupervised data distribution learning (DDL) and supervised monotonic cardinality estimation (MCE). DDL leverages the mixture data guided transformer to learn the distribution of database and query parameters for model pre-training. MCE further incorporates supervised learning and parameter clamping to enhance the estimation under monotonicity guarantees. We develop an efficient incremental learning algorithm for EECE to adapt the database and query logs update. Extensive experiments on several real-world and synthetic datasets demonstrate that, EECE speeds up the cardinality estimation by six orders of magnitude, with more than 39\% accuracy gain, compared to the state-of-the-art approaches.},
journal = {Proc. ACM Manag. Data},
month = may,
articleno = {104},
numpages = {21},
keywords = {cardinality estimation, data distribution learning, monotonic cardinality estimation, skyline family}
}

@inproceedings{10.1145/3576915.3616652,
author = {Naseh, Ali and Krishna, Kalpesh and Iyyer, Mohit and Houmansadr, Amir},
title = {Stealing the Decoding Algorithms of Language Models},
year = {2023},
isbn = {9798400700507},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576915.3616652},
doi = {10.1145/3576915.3616652},
abstract = {A key component of generating text from modern language models (LM) is the selection and tuning of decoding algorithms. These algorithms determine how to generate text from the internal probability distribution generated by the LM. The process of choosing a decoding algorithm and tuning its hyperparameters takes significant time, manual effort, and computation, and it also requires extensive human evaluation. Therefore, the identity and hyperparameters of such decoding algorithms are considered to be extremely valuable to their owners. In this work, we show, for the first time, that an adversary with typical API access to an LM can steal the type and hyperparameters of its decoding algorithms at very low monetary costs. Our attack is effective against popular LMs used in text generation APIs, including GPT-2, GPT-3 and GPT-Neo. We demonstrate the feasibility of stealing such information with only a few dollars, e.g., 0.8, 1, 4, and 40 for the four versions of GPT-3.},
booktitle = {Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1835–1849},
numpages = {15},
keywords = {decoding algorithms, hyperparameter stealing, language models},
location = {Copenhagen, Denmark},
series = {CCS '23}
}

@inproceedings{10.1145/3658644.3690356,
author = {Baldimtsi, Foteini and Chalkias, Konstantinos Kryptos and Ji, Yan and Lindstr\o{}m, Jonas and Maram, Deepak and Riva, Ben and Roy, Arnab and Sedaghat, Mahdi and Wang, Joy},
title = {zkLogin: Privacy-Preserving Blockchain Authentication with Existing Credentials},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3690356},
doi = {10.1145/3658644.3690356},
abstract = {For many users, a private key based wallet serves as the primary entry point to blockchains. Commonly recommended wallet authentication methods, such as mnemonics or hardware wallets, can be cumbersome. This difficulty in user onboarding has significantly hindered the adoption of blockchain-based applications.We develop zkLogin, a novel technique that leverages identity tokens issued by popular platforms (any OpenID Connect enabled platform e.g., Google, Facebook, etc.) to authenticate transactions. At the heart of zkLogin lies a signature scheme allowing the signer to sign using their existing OpenID accounts and nothing else. This improves the user experience significantly as users do not need to remember a new secret and can reuse their existing accounts.zkLogin provides strong security and privacy guarantees. Unlike prior works, zkLogin's security relies solely on the underlying platform's authentication mechanism without the need for any additional trusted parties (e.g., trusted hardware or oracles). As the name suggests, zkLogin leverages zero-knowledge proofs (ZKP) to ensure that the sensitive link between a user's off-chain and on-chain identities is hidden, even from the platform itself.zkLogin enables a number of important applications outside blockchains. It allows billions of users to produce verifiable digital content leveraging their existing digital identities, e.g., email address. For example, a journalist can use zkLogin to sign a news article with their email address, allowing verification of the article's authorship by any party.We have implemented and deployed zkLogin on the Sui blockchain as an additional alternative to traditional digital signature-based addresses. Due to the ease of web3 on-boarding just with social login, many hundreds of thousands of zkLogin accounts have already been generated in various industries such as gaming, DeFi, direct payments, NFT collections, sports racing, cultural heritage, and many more.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {3182–3196},
numpages = {15},
keywords = {authentication, blockchain, privacy, zero-knowledge},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3488932.3517393,
author = {Dib, Mirabelle and Torabi, Sadegh and Bou-Harb, Elias and Bouguila, Nizar and Assi, Chadi},
title = {EVOLIoT: A Self-Supervised Contrastive Learning Framework for Detecting and Characterizing Evolving IoT Malware Variants},
year = {2022},
isbn = {9781450391405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3488932.3517393},
doi = {10.1145/3488932.3517393},
abstract = {Recent years have witnessed the emergence of new and more sophisticated malware targeting the Internet of Things. Moreover, the public release of the source code of popular malware families such as Mirai has spawned diverse variants, making it harder to disambiguate their ownership, lineage, and correct label. Such a rapidly evolving landscape makes it also harder to deploy and generalize effective learning models against retired, updated, and/or new threat campaigns. In this paper, we present EVOLIoT, a novel approach aiming at combating "concept drift" and the limitations of inter-family IoT malware classification by detecting drifting IoT malware families and understanding their diverse evolutionary trajectories. We introduce a robust and effective contrastive method that learns and compares semantically meaningful representations of IoT malware binaries and codes without the need for expensive target labels. We find that the evolution of IoT binaries can be used as an augmentation strategy to learn effective representations to contrast (dis)similar variant pairs. We discuss the impact and findings of our analysis and present several evaluation studies to highlight the tangled relationships of IoT malware, as well as the efficiency of our contrastively learned feature vectors in preserving semantics and reducing out-of-vocabulary size in cross-architecture IoT malware binaries.},
booktitle = {Proceedings of the 2022 ACM on Asia Conference on Computer and Communications Security},
pages = {452–466},
numpages = {15},
keywords = {iot malware classification, contrastive learning, concept drift},
location = {Nagasaki, Japan},
series = {ASIA CCS '22}
}

@inproceedings{10.1145/3669940.3707260,
author = {Jayashankar, Siddharth and Chen, Edward and Tang, Tom and Zheng, Wenting and Skarlatos, Dimitrios},
title = {Cinnamon: A Framework for Scale-Out Encrypted AI},
year = {2025},
isbn = {9798400706981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3669940.3707260},
doi = {10.1145/3669940.3707260},
abstract = {Fully homomorphic encryption (FHE) is a promising cryptographic solution that enables computation on encrypted data, but its adoption remains a challenge due to steep performance overheads. Although recent FHE architectures have made valiant efforts to narrow the performance gap, they not only have massive monolithic chip designs but also only target small ML workloads. We present Cinnamon, a framework for accelerating state-of-the-art ML workloads that are encrypted using FHE. Cinnamon accelerates encrypted computing by exploiting parallelism at all levels of a program, using novel algorithms, compilers, and hardware techniques to create a scale-out design for FHE as opposed to a monolithic chip design. Our evaluation of the Cinnamon framework on small programs shows a 2.3\texttimes{} improvement in performance compared to prior state-of-the-art designs. Further, we use Cinnamon to show for the first time the scalability of large ML models such as the BERT language model in FHE. Cinnamon achieves a speedup of 36,600\texttimes{} compared to a CPU bringing down the inference time from 17 hours to 1.67 seconds thereby enabling new opportunities for privacy-preserving machine learning. Finally, Cinnamon's parallelization strategies and architectural extensions reduce the required resources per-chip leading to a 5\texttimes{} and 2.68\texttimes{} improvement in performance-per-dollar compared to state-of-the-art monolithic and chiplet architectures respectively.},
booktitle = {Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 1},
pages = {133–150},
numpages = {18},
keywords = {accelerators, encrypted ai, fully homomorphic encryption, parallelism},
location = {Rotterdam, Netherlands},
series = {ASPLOS '25}
}

@inproceedings{10.1145/3659677.3659825,
author = {Silkhi, Hassan and Bakkas, Brahim and Housni, Khalid},
title = {Comparative Analysis of Rule-Based Chatbot Development Tools for Education Orientation: A RAD Approach},
year = {2024},
isbn = {9798400709296},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3659677.3659825},
doi = {10.1145/3659677.3659825},
abstract = {In today’s educational world, chatbots are essential for helping students find their way through school. These bots give students quick answers and support whenever they need it. But how well a chatbot works depends on how it’s made. Rapid Application Development (RAD) methods make building software faster and more flexible. This paper compares three tools for making chatbots: BotPress, DialogFlow, and Rasa Framework. Each has its own features and uses. By testing them in case study using RAD methods, we’ll see which one works best for helping students in education. Through this comparison, we’ll find out which tool is best for making rule-based chatbots. This will help developers and educators choose the right tool for giving students the support they need in school..},
booktitle = {Proceedings of the 7th International Conference on Networking, Intelligent Systems and Security},
articleno = {51},
numpages = {7},
keywords = {• Chatbot • Natural Language Processing • Intelligence Artificial • RAD • Education Orientation • BotPress • DialogFlow • Rasa framework},
location = {Meknes, AA, Morocco},
series = {NISS '24}
}

@inproceedings{10.1145/3544548.3580817,
author = {Liu, Michael Xieyang and Sarkar, Advait and Negreanu, Carina and Zorn, Benjamin and Williams, Jack and Toronto, Neil and Gordon, Andrew D.},
title = {“What It Wants Me To Say”: Bridging the Abstraction Gap Between End-User Programmers and Code-Generating Large Language Models},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580817},
doi = {10.1145/3544548.3580817},
abstract = {Code-generating large language models map natural language to code. However, only a small portion of the infinite space of naturalistic utterances is effective at guiding code generation. For non-expert end-user programmers, learning this is the challenge of abstraction matching. We examine this challenge in the specific context of data analysis in spreadsheets, in a system that maps the user’s natural language query to Python code using the Codex generator, executes the code, and shows the result. We propose grounded abstraction matching, which bridges the abstraction gap by translating the code back into a systematic and predictable naturalistic utterance. In a between-subjects, think-aloud study (n=24), we compare grounded abstraction matching to an ungrounded alternative based on previously established query framing principles. We find that the grounded approach improves end-users’ understanding of the scope and capabilities of the code-generating model, and the kind of language needed to use it effectively.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {598},
numpages = {31},
keywords = {Human-AI Interaction, Large Language Models, Natural Language Programming, Spreadsheets},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3665939.3665966,
author = {H\"{a}ttasch, Benjamin and Binnig, Carsten},
title = {More of that, please: Domain Adaptation of Information Extraction through Examples \&amp; Feedback},
year = {2024},
isbn = {9798400706936},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665939.3665966},
doi = {10.1145/3665939.3665966},
abstract = {Automatic information extraction, e.g., into a tabular format, is crucial for leveraging knowledge in large text collections. Yet, creating such extraction pipelines for custom target attributes can cause high overheads, while off-the-shelf tools might miss domain-specific information. Therefore, in this paper, we propose an interactive system that augments generic extractions and aligns them with a target definition. The necessary domain adaptation is reached through examples provided by the users during the interaction with the system. As part of this, we propose different low-overhead extractors and evaluate them individually and end-to-end to demonstrate how our approach minimizes the necessary interactions. We publish our code as open source.},
booktitle = {Proceedings of the 2024 Workshop on Human-In-the-Loop Data Analytics},
pages = {1–7},
numpages = {7},
location = {Santiago, AA, Chile},
series = {HILDA  24}
}

@inproceedings{10.1145/3426425.3426937,
author = {Perianez-Pascual, Jorge and Rodriguez-Echeverria, Roberto and Burgue\~{n}o, Loli and Cabot, Jordi},
title = {Towards the optical character recognition of DSLs},
year = {2020},
isbn = {9781450381765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3426425.3426937},
doi = {10.1145/3426425.3426937},
abstract = {OCR engines aim to identify and extract text strings fromdocuments or images. While current efforts focus mostly inmainstream languages, there is little support for program-ming or domain-specific languages (DSLs). In this paper, wepresent our vision about the current state of OCR recognitionfor DSLs and its challenges. We discuss some strategies toimprove the OCR quality applied to DSL textual expressionsby leveraging DSL specifications and domain data. To bettersupport our ideas we present the preliminary results of anempirical study and outline a research roadmap.},
booktitle = {Proceedings of the 13th ACM SIGPLAN International Conference on Software Language Engineering},
pages = {126–132},
numpages = {7},
keywords = {text recognition, optical character recognition, domain-specific languages},
location = {Virtual, USA},
series = {SLE 2020}
}

@inproceedings{10.1145/3583131.3590502,
author = {Pantridge, Edward and Helmuth, Thomas},
title = {Solving Novel Program Synthesis Problems with Genetic Programming using Parametric Polymorphism},
year = {2023},
isbn = {9798400701191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583131.3590502},
doi = {10.1145/3583131.3590502},
abstract = {Contemporary genetic programming (GP) systems for general program synthesis have been primarily concerned with evolving programs that can manipulate values from a standard set of primitive data types and simple indexed data structures. In contrast, human programmers do not limit themselves to a small finite set of data types and use polymorphism to express an unbounded number of types including nested data structures, product types, and generic functions. Code-building Genetic Programming (CBGP) is a recently introduced method that compiles type-safe programs from linear genomes using stack-based compilation and a formal type system. Although prior work with CBGP has shown initial demonstrations of polymorphism inside evolved programs, we have provided a deeper exploration of these capabilities through the evolution of programs which make use of generic data types such as key-value maps, tuples, and sets, as well as higher order functions and functions with polymorphic type signatures. In our experiments, CBGP is able to solve problems with all of these properties, where every other GP system that we know of has restrictions that make it unable to even consider problems with these properties. This demonstration provides a significant step towards fully aligning the expressiveness of GP to real world programming.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {1175–1183},
numpages = {9},
keywords = {polymorphism, inductive program synthesis, genetic programming, automatic programming},
location = {Lisbon, Portugal},
series = {GECCO '23}
}

@inproceedings{10.1145/3711896.3737140,
author = {Liu, Yu and Tao, Weiyao and Xia, Tong and Knight, Simon and Zhu, Tingting},
title = {SurvUnc: A Meta-Model Based Uncertainty Quantification Framework for Survival Analysis},
year = {2025},
isbn = {9798400714542},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711896.3737140},
doi = {10.1145/3711896.3737140},
abstract = {Survival analysis, which estimates the probability of event occurrence over time from censored data, is fundamental in numerous real-world applications, particularly in high-stakes domains such as healthcare and risk assessment. Despite advances in numerous survival models, quantifying the uncertainty of predictions from these models remains underexplored and challenging. The lack of reliable uncertainty quantification limits the interpretability and trustworthiness of survival models, hindering their adoption in clinical decision-making and other sensitive applications. To bridge this gap, in this work, we introduce SurvUnc, a novel meta-model based framework for post-hoc uncertainty quantification for survival models. SurvUnc introduces an anchor-based learning strategy that integrates concordance knowledge into meta-model optimization, leveraging pairwise ranking performance to estimate uncertainty effectively. Notably, our framework is model-agnostic, ensuring compatibility with any survival model without requiring modifications to its architecture or access to its internal parameters. Especially, we design a comprehensive evaluation pipeline tailored to this critical yet overlooked problem. Through extensive experiments on four publicly available benchmarking datasets and five representative survival models, we demonstrate the superiority of SurvUnc across multiple evaluation scenarios, including selective prediction, misprediction detection, and out-of-domain detection. Our results highlight the effectiveness of SurvUnc in enhancing model interpretability and reliability, paving the way for more trustworthy survival predictions in real-world},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2},
pages = {1903–1914},
numpages = {12},
keywords = {meta model, out-of-domain detection, survival analysis, uncertainty quantification},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3487351.3489443,
author = {Paschalides, Demetris and Pallis, George and Dikaiakos, Marios D.},
title = {POLAR: a holistic framework for the modelling of polarization and identification of polarizing topics in news media},
year = {2022},
isbn = {9781450391283},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3487351.3489443},
doi = {10.1145/3487351.3489443},
abstract = {Polarization is an alarming trend in modern societies with serious implications on social cohesion and the democratic process. Typically, polarization manifests itself in the public discourse in politics, governance and ideology. In recent years, however, polarization arises increasingly in a wider range of issues, from identity and culture to healthcare and the environment. As the public and private discourse moves online, polarization feeds in and is fed by phenomena like fake news and hate speech. The identification and analysis of online polarization is challenging because of the massive scale, diversity, and unstructured nature of online content, and the rapid and unpredictable evolution of polarizing issues. Therefore, we need effective ways to identify, quantify, and represent polarization and polarizing topics algorithmically and at scale. In this work, we introduce POLAR - an unsupervised, large-scale framework for modeling and identifying polarizing topics in any domain, without prior domain-specific knowledge. POLAR comprises a processing pipeline that analyzes a corpus of an arbitrary number of news articles to construct a hierarchical knowledge graph that models polarization and identify polarizing topics discussed in the corpus. Our evaluation shows that POLAR is able to identify and rank polarizing topics accurately and efficiently.},
booktitle = {Proceedings of the 2021 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {348–355},
numpages = {8},
keywords = {inter-group conflict, natural language processing, polarization, polarizing topic extraction, signed networks},
location = {Virtual Event, Netherlands},
series = {ASONAM '21}
}

@inproceedings{10.1145/3605159.3605855,
author = {Ferrando, Angelo and Gatti, Andrea and Mascardi, Viviana},
title = {RV4Rasa: A Formalism-Agnostic Runtime Verification Framework for Verifying ChatBots in Rasa},
year = {2023},
isbn = {9798400702495},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605159.3605855},
doi = {10.1145/3605159.3605855},
abstract = {Chatbots are here to stay, and are going to be deployed in various application domains. Unfortunately, amongst them, there are safety-critical ones. Thus, we need a way to guarantee our chatbots will always behave as expected. In this paper, we propose RV4Rasa, a Runtime Verification framework that monitors whether a given chatbot deviates from its expected behaviour, when the latter is formalised as an interaction protocol between the end-user and the chatbot. We present RV4Rasa, its engineering, and its instantiation to monitor chatbots implemented using the Rasa framework. After presenting RV4Rasa's structure, we report experiments that we carried out in a simulated robotic scenario, where a chatbot is used to support the design of a factory workfloor.},
booktitle = {Proceedings of the 6th International Workshop on Verification and Monitoring at Runtime Execution},
pages = {1–8},
numpages = {8},
keywords = {Runtime Verification, Rasa, ChatBot},
location = {Seattle, WA, USA},
series = {VORTEX 2023}
}

@article{10.1145/3625228,
author = {Kumar, Akshi and Jain, Dipika and Beniwal, Rohit},
title = {HindiPersonalityNet: Personality Detection in Hindi Conversational Data Using Deep Learning with Static Embedding},
year = {2024},
issue_date = {August 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {8},
issn = {2375-4699},
url = {https://doi.org/10.1145/3625228},
doi = {10.1145/3625228},
abstract = {Personality detection along with other behavioral and cognitive assessment can essentially explain why people act the way they do and can be useful to various online applications such as recommender systems, job screening, matchmaking, and counseling. Additionally, psychometric natural language processing relying on textual cues and distinctive markers in writing style within conversational utterances reveals signs of individual personalities. This work demonstrates a text-based deep neural model, HindiPersonalityNet, of classifying conversations into three personality categories (ambivert, extrovert, introvert) for detecting personality in Hindi conversational data. The model utilizes a gated recurrent unit with BioWordVec embeddings for text classification and is trained/tested on a novel dataset, शख्सियत (pronounced as Shakhsiyat) curated using dialogues from an Indian crime-thriller drama series, Aarya. The model achieves an F1-score of 0.701 and shows the potential for leveraging conversational data from various sources to understand and predict a person's personality traits. It exhibits the ability to capture both semantic and long-distance dependencies in conversations and establishes the effectiveness of our dataset as a benchmark for personality detection in Hindi dialogue data. Further, a comprehensive comparison of various static and dynamic word embedding is done on our standardized dataset to ascertain the most suitable embedding method for personality detection.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = aug,
articleno = {117},
numpages = {13},
keywords = {Personality, low resource, deep learning, word embeddings, NLP, personality psychology, natural language, conversational data}
}

@inproceedings{10.1145/3639478.3639781,
author = {Duque-Torres, Alejandra},
title = {Selecting and Constraining Metamorphic Relations},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3639781},
doi = {10.1145/3639478.3639781},
abstract = {Software testing is a critical aspect of ensuring the reliability and quality of software systems. However, it often poses challenges, particularly in determining the expected output of a System Under Test (SUT) for a given set of inputs, a problem commonly referred to as the test oracle problem. Metamorphic Testing (MT) offers a promising solution to the test oracle problem by examining the relations between input-output pairs in consecutive executions of the SUT. These relations, referred to as Metamorphic Relations (MRs), define the expected changes in the output when specific changes are made to the input. Our research is focused on developing methods and tools to assist testers in the selection of MRs, the definition of constraints, and providing explanations for MR outcomes. The research is divided in three parts. The first part focuses on MR collection and description, entailing the creation of a comprehensive repository of MRs from various sources. A standardised MR representation is devised to promote machine-readability and wide-ranging applicability. The second part introduces MetraTrimmer, a test-data-driven approach for systematically selecting and constraining MRs. This approach acknowledges that MRs may not be universally applicable to all test data space. The final part, evaluation and validation, encompasses empirical studies aimed at assessing the effectiveness of the developed methods and validating their suitability for real-world regression testing scenarios. Through this research, we aim to advance the automation of MR generation, enhance the understanding of MR violations, and facilitate their effective application in regression testing.},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {212–216},
numpages = {5},
keywords = {test oracle, metamorphic testing, metamorphic relations, test data, pattern mining},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

@inproceedings{10.1145/3702634.3702950,
author = {Wang, Li and Jiang, Yankai and Mi, Ningfang},
title = {Advancing Serverless Computing for Scalable AI Model Inference: Challenges and Opportunities},
year = {2024},
isbn = {9798400713361},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702634.3702950},
doi = {10.1145/3702634.3702950},
abstract = {Artificial Intelligence (AI) model inference has emerged as a crucial component across numerous applications. Serverless computing, known for its scalability, flexibility, and cost-efficiency, is an ideal paradigm for executing AI model inference tasks. This survey provides a comprehensive review of recent research on AI model inference systems in serverless environments, focusing on studies published since 2019. We investigate system-level advancements aimed at optimizing performance and cost-efficiency through a range of innovative techniques. By analyzing high-impact papers from leading venues in AI model inference and serverless computing, we highlight key breakthroughs and solutions. This survey serves as a valuable resource for both practitioners and academic researchers, offering critical insights into the current state and future trends in integrating AI model inference with serverless architectures. To the best of our knowledge, this is the first survey that includes Large Language Models (LLMs) inference in the context of serverless computing.},
booktitle = {Proceedings of the 10th International Workshop on Serverless Computing},
pages = {1–6},
numpages = {6},
keywords = {serverless computing, LLMs inference, DL inference, ML inference},
location = {Hong Kong, Hong Kong},
series = {WoSC10 '24}
}

@inproceedings{10.1145/3583780.3614870,
author = {Tiwari, Abhisek and Saha, Anisha and Saha, Sriparna and Bhattacharyya, Pushpak and Dhar, Minakshi},
title = {Experience and Evidence are the eyes of an excellent summarizer! Towards Knowledge Infused Multi-modal Clinical Conversation Summarization},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3614870},
doi = {10.1145/3583780.3614870},
abstract = {With the advancement of telemedicine, both researchers and medical practitioners are working hand-in-hand to develop various techniques to automate various medical operations, such as diagnosis report generation. In this paper, we first present a multi-modal clinical conversation summary generation task that takes a clinician-patient interaction (both textual and visual information) and generates a succinct synopsis of the conversation. We propose a knowledge-infused, multi-modal, multi-tasking medical domain identification and clinical conversation summary generation (MM-CliConSummation) framework. It leverages an adapter to infuse knowledge and visual features and unify the fused feature vector using a gated mechanism. Furthermore, we developed a multi-modal, multi-intent clinical conversation summarization corpus annotated with intent, symptom, and summary. The extensive set of experiments, both quantitatively and qualitatively, led to the following findings: (a) critical significance of visuals, (b) more precise and medical entity preserving summary with additional knowledge infusion, and (c) a correlation between medical department identification and clinical synopsis generation. Furthermore, the dataset and source code are available at https://github.com/NLP-RL/MM-CliConSummation},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {2452–2461},
numpages = {10},
keywords = {text generation, online counselling, multimodal medical dialogue summarization, multimodal infusion},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3664647.3681422,
author = {Naseem, Usman and Dunn, Adam G. and Khushi, Matloob and Kim, Jinman},
title = {Vaccine Misinformation Detection in X using Cooperative Multimodal Framework},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681422},
doi = {10.1145/3664647.3681422},
abstract = {Identifying social media posts that spread vaccine misinformation can inform emerging public health risks and aid in designing effective communication interventions. Existing studies, while promising, often rely on single user posts, potentially leading to flawed conclusions. This highlights the necessity to model users' historical posts for a comprehensive understanding of their stance towards vaccines. However, users' historical posts may contain a diverse range of content that adds noise and leads to low performance. To address this gap, in this study, we present VaxMine, a cooperative multi-agent reinforcement learning method that automatically selects relevant textual and visual content from a user's posts, reducing noise. To evaluate the performance of the proposed method, we create and release a new dataset of 2,072 users with historical posts due to the unavailability of publicly available datasets. The experimental results show that our approach outperforms state-of-the-art methods with an F1-Score of 0.94 (an absolute increase of 13\%), demonstrating that extracting relevant content from users' historical posts and understanding both modalities are essential to detecting anti-vaccine users on social media. We further analyze the robustness and generalizability of VaxMine, showing that extracting relevant textual and visual content from a user's posts improves performance. We conclude with a discussion of the practical implications of our study by explaining how computational methods used in surveillance can benefit from our work, with flow-on effects on the design of health communication interventions to counter vaccine misinformation on social media.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {4034–4042},
numpages = {9},
keywords = {cooperative learning, multimodal posts, vaccine misinformation},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3643832.3661892,
author = {Jia, Fucheng and Jiang, Shiqi and Cao, Ting and Cui, Wei and Xia, Tianrui and Cao, Xu and Li, Yuanchun and Wang, Qipeng and Zhang, Deyu and Ren, Ju and Liu, Yunxin and Qiu, Lili and Yang, Mao},
title = {Empowering In-Browser Deep Learning Inference on Edge Through Just-In-Time Kernel Optimization},
year = {2024},
isbn = {9798400705816},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643832.3661892},
doi = {10.1145/3643832.3661892},
abstract = {Web is increasingly becoming the primary platform to deliver AI services onto edge devices, making in-browser deep learning (DL) inference more prominent. Nevertheless, the heterogeneity of edge devices, combined with the underdeveloped state of Web hardware acceleration practices, hinders current in-browser inference from achieving its full performance potential on target devices.To address this issue, this paper presents the pioneering inbrowser inference system, nnJIT, which enables just-in-time (JIT) auto-generation of optimized computing kernels for edge devices. nnJIT is built upon two novel techniques that significantly reduce kernel search and compilation overhead while improving performance firmly: Tensor-Web Compiling Co-Design lowers compiling costs by around 100\texttimes{} through eliminating redundant and ineffective compiling passes; Web-Specific Lite Kernel Optimization Space reduces kernel tuning costs by focusing on Web programming requirements and efficient device resource utilization, pruning the optimization space from millions to only dozens.nnJIT1 is evaluated for modern models, e.g., BART, T5, and Llama 2, on a range of edge devices including laptops and smartphones using different browsers and hardware from ARM, Intel, AMD and Nvidia. The results show that nnJIT can achieve up to 8.2\texttimes{} faster within 30 seconds compared to the existing baselines.},
booktitle = {Proceedings of the 22nd Annual International Conference on Mobile Systems, Applications and Services},
pages = {438–450},
numpages = {13},
keywords = {in-browser deep learning inference, just-in-time kernel optimizations, WebAssembly, WebGPU},
location = {Minato-ku, Tokyo, Japan},
series = {MOBISYS '24}
}

@article{10.14778/3734839.3734856,
author = {Lai, Eugenie Y. and He, Yeye and Chaudhuri, Surajit},
title = {Auto-Prep: Holistic Prediction of Data Preparation Steps for Self-Service Business Intelligence},
year = {2025},
issue_date = {March 2025},
publisher = {VLDB Endowment},
volume = {18},
number = {7},
issn = {2150-8097},
url = {https://doi.org/10.14778/3734839.3734856},
doi = {10.14778/3734839.3734856},
abstract = {Business Intelligence (BI) plays a critical role in empowering modern enterprises to make informed data-driven decisions, and has grown into a billion-dollar business. Self-service BI tools like Power BI and Tableau have democratized the "dashboarding" phase of BI, by offering user-friendly, drag-and-drop interfaces that are tailored to non-technical enterprise users. However, despite these advances, we observe that the "data preparation" phase of BI continues to be a key pain point for BI users today.In this work, we systematically study around 2K real BI projects harvested from public sources, focusing on the data-preparation phase of the BI workflows. We observe that users often have to program both (1) data transformation steps and (2) table joins steps, before their raw data can be ready for dashboarding and analysis. A careful study of the BI workflows reveals that transformation and join steps are often intertwined in the same BI project, such that considering both holistically is crucial to accurately predict these steps. Leveraging this observation, we develop an Auto-Prep system to holistically predict transformations and joins, using a principled graph-based algorithm inspired by Steiner-tree, with provable quality guarantees. Extensive evaluations using real BI projects suggest that Auto-Prep can correctly predict over 70\% transformation and join steps, significantly more accurate than existing algorithms as well as language-models such as GPT-4.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {2212–2225},
numpages = {14}
}

@article{10.1145/3716892,
author = {Zhang, Liming and Mbuya, Jonathan and Zhao, Liang and Pfoser, Dieter and Anastasopoulos, Antonios},
title = {End-to-end Trajectory Generation - Contrasting Deep Generative Models and Language Models},
year = {2025},
issue_date = {December 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {4},
issn = {2374-0353},
url = {https://doi.org/10.1145/3716892},
doi = {10.1145/3716892},
abstract = {Due to the limited availability of actual large-scale datasets, realistic synthetic trajectory data play a crucial role in various research domains, including spatiotemporal data mining and data management, and domain-driven research related to transportation planning and urban analytics. Existing generation methods rely on predefined heuristics and cannot learn the unknown underlying generative mechanisms. This work introduces two end-to-end approaches for trajectory generation. The first approach comprises deep generative VAE-like models that factorize global and local semantics (habits vs. random routing change). We further enhance this approach by developing novel inference strategies based on variational inference and constrained optimization to ensure the validity of spatiotemporal aspects. This novel deep neural network architecture implements generative and inference models with dynamic latent priors. The second approach introduces a language model (LM) inspired generation as another benchmarking and foundational approach. The LM-inspired approach conceptualizes trajectories as sentences with the aim of predicting the likelihood of subsequent locations on a trajectory, given the locations as context. As a result, the LM-inspired approach implicitly learns the inherent spatiotemporal structure and other embedded semantics within the trajectories. These proposed methods demonstrate substantial quantitative and qualitative improvements over existing approaches, as evidenced by extensive experimental evaluations.},
journal = {ACM Trans. Spatial Algorithms Syst.},
month = aug,
articleno = {17},
numpages = {28},
keywords = {End-to-end trajectory generation, deep generative models, spatiotemporal-validity constraint, variational autoencoders}
}

@article{10.1145/3686921,
author = {Narayanan Venkit, Pranav and Graziul, Christopher and Goodman, Miranda Ardith and Kenny, Samantha Nicole and Wilson, Shomir},
title = {Race and Privacy in Broadcast Police Communications},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3686921},
doi = {10.1145/3686921},
abstract = {Radios are essential for the operations of modern police departments, and they function as both a collaborative communication technology and a sociotechnical system. However, little prior research has examined their usage or their connections to individual privacy and the role of race in policing, two growing topics of concern in the US. As a case study, we examine the Chicago Police Department's (CPD's) use of broadcast police communications (BPC) to coordinate the activity of law enforcement officers (LEOs) in the city. From a recently assembled archive of 80,775 hours of BPC associated with CPD operations, we analyze human-generated text transcripts of radio transmissions broadcast 9:00 AM to 5:00 PM on August 10th, 2018 in one majority Black, one majority White, and one majority Hispanic area of the city (24 hours of audio) to explore four research questions: (1) Do BPC reflect reported racial disparities in policing? (2) How and when is gender, race/ethnicity, and age mentioned in BPC? (3) To what extent do BPC include sensitive information, and who is put at most risk by this practice? (4) To what extent can large language models (LLMs) heighten this risk? We explore the vocabulary and speech acts used by police in BPC, comparing mentions of personal characteristics to local demographics, the personal information shared over BPC, and the privacy concerns that it poses. Analysis indicates (a) policing professionals in the city of Chicago exhibit disproportionate attention to Black members of the public regardless of context, (b) sociodemographic characteristics like gender, race/ethnicity, and age are primarily mentioned in BPC about event information, and (c) disproportionate attention introduces disproportionate privacy risks for Black members of the public. This study shows BPC can provide a novel window into disproportionate attention (i.e., via radio communications) by law enforcement officers to specific racial groups, leading to increased privacy vulnerability for those groups, particularly Black males.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {382},
numpages = {26},
keywords = {broadcast police communication, lexical analysis, policing disparities, privacy vulnerability, qualitative coding, social informatics}
}

@inproceedings{10.1145/3549737.3549753,
author = {Zaikis, Dimitrios and Kokkas, Stylianos and Vlahavas, Ioannis},
title = {Transforming Drug-Drug Interaction Extraction from Biomedical Literature},
year = {2022},
isbn = {9781450395977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3549737.3549753},
doi = {10.1145/3549737.3549753},
abstract = {Language Models (LM) capture the characteristics of the distribution of words sequences in natural language, learning meaningful distributed representations in the process. Recent advancements in Neural Networks and Deep Leaning have led to rapid progress in this area, greatly attributed to the emergence of the attention mechanism. Specifically, the Transformer architecture that implements attention-based encoder-decoder stacks, has advanced research in numerous Natural Language Processing tasks and produced state-of-the-art pre-trained LMs. One important task is Relationship Extraction (RE), which extracts semantic relationships from text and has significant applications in the biomedical domain, especially in literature pertaining to drug safety and Drug-Drug Interactions (DDI). In DDI extraction, the task is divided into two subtasks, Drug Named Entity Recognition and Relation Classification, consequently identifying drug mentions and classifying the potential effect of drug combinations from literature. Various methods for the extraction of DDIs have been proposed that utilize different architectures, however Transformers-based LMs continue to show the most promise. The overwhelming number of available pre-trained LMs, that each provide their own benefits and disadvantages, renders the selection of a clear baseline extremely difficult. In this paper, we investigate the most relevant LMs for biomedical RE and experiment on the DDI Extraction 2013 dataset. We propose a baseline approach for pre-trained Transformer-based LMs with shallow output architectures to effectively utilize the underlying architecture and introduce a foundation that reaches similar to state-of-the-art performance for both subtasks of DDI extraction.},
booktitle = {Proceedings of the 12th Hellenic Conference on Artificial Intelligence},
articleno = {12},
numpages = {8},
keywords = {transformers, neural networks, language model, information retrieval, drug-drug interactions},
location = {Corfu, Greece},
series = {SETN '22}
}

@inproceedings{10.1145/3643991.3644923,
author = {Chen, Binger and Golebiowski, Jacek and Abedjan, Ziawasch},
title = {Data Augmentation for Supervised Code Translation Learning},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3644923},
doi = {10.1145/3643991.3644923},
abstract = {Data-driven program translation has been recently the focus of several lines of research. A common and robust strategy is supervised learning. However, there is typically a lack of parallel training data, i.e., pairs of code snippets in the source and target language. While many data augmentation techniques exist in the domain of natural language processing, they cannot be easily adapted to tackle code translation due to the unique restrictions of programming languages. In this paper, we develop a novel rule-based augmentation approach tailored for code translation data, and a novel retrieval-based approach that combines code samples from unorganized big code repositories to obtain new training data. Both approaches are language-independent. We perform an extensive empirical evaluation on existing Java-C#-benchmarks showing that our method improves the accuracy of state-of-the-art supervised translation techniques by up to 35\%.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {444–456},
numpages = {13},
location = {Lisbon, Portugal},
series = {MSR '24}
}

