@article{10.1145/3603171,
author = {Saha, Swapnil Sayan and Sandha, Sandeep Singh and Aggarwal, Mohit and Wang, Brian and Han, Liying and Briseno, Julian De Gortari and Srivastava, Mani},
title = {TinyNS: Platform-aware Neurosymbolic Auto Tiny Machine Learning},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {3},
issn = {1539-9087},
url = {https://doi.org/10.1145/3603171},
doi = {10.1145/3603171},
abstract = {Machine learning at the extreme edge has enabled a plethora of intelligent, time-critical, and remote applications. However, deploying interpretable artificial intelligence systems that can perform high-level symbolic reasoning and satisfy the underlying system rules and physics within the tight platform resource constraints is challenging. In this article, we introduce TinyNS, the first platform-aware neurosymbolic architecture search framework for joint optimization of symbolic and neural operators. TinyNS provides recipes and parsers to automatically write microcontroller code for five types of neurosymbolic models, combining the context awareness and integrity of symbolic techniques with the robustness and performance of machine learning models. TinyNS uses a fast, gradient-free, black-box Bayesian optimizer over discontinuous, conditional, numeric, and categorical search spaces to find the best synergy of symbolic code and neural networks within the hardware resource budget. To guarantee deployability, TinyNS talks to the target hardware during the optimization process. We showcase the utility of TinyNS by deploying microcontroller-class neurosymbolic models through several case studies. In all use cases, TinyNS outperforms purely neural or purely symbolic approaches while guaranteeing execution on real hardware.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = may,
articleno = {43},
numpages = {48},
keywords = {Neurosymbolic, neural architecture search, TinyML, AutoML, bayesian, platform-aware}
}

@inproceedings{10.1145/3696410.3714928,
author = {Wu, Zhiying and Wu, Jiajing and Zhang, Hui and Zheng, Zibin and Wang, Weiqiang},
title = {Hunting in the Dark Forest: A Pre-trained Model for On-chain Attack Transaction Detection in Web3},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714928},
doi = {10.1145/3696410.3714928},
abstract = {In recent years, a large number of on-chain attacks have emerged in the blockchain empowered Web3 ecosystem. In the year of 2023 alone, on-chain attacks have caused losses of over 585 million. Attackers use blockchain transactions to carry out on-chain attacks, for example, exploiting vulnerabilities or business logic flaws in Web3 applications. A wealth of efforts have been devoted to detecting on-chain attack transactions through expert patterns and machine learning techniques. However, in this ever-evolving ecosystem, the performance of current methods is limited in detecting new on-chain attacks, due to the obsoleting of attack recognition patterns or the reliance on on-chain attack samples. In this paper, we propose a universal approach for detecting on-chain attacks even when there are few or even no new on-chain attack samples. Specifically, an in-depth analysis of the transaction characteristics is conducted, and we propose a new insight to train a generic attack transaction detecting model, i.e., transaction reconstruction. Particularly, to overcome the over-fitting in the transaction reconstruction task, we use the web-scale function comments related to transactions as supervision information, rather than expert-confirmed labels. Experimental results demonstrate that the proposed approach surpasses the supervised state-of-the-art by 13\% in AUC, with just 30 known on-chain attack samples. Moreover, without any known attack samples, our method can still detect new on-chain attacks in the wild (with a precision of 61.83\%). Among attacks detected in the wild, we confirm 1,692 address poisoning attacks, a new type of on-chain attack targeting token holders. Our code is available at: https://github.com/wuzhy1ng/attack_trans_detection_www25.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {4519–4530},
numpages = {12},
keywords = {attack detection, blockchain transaction analysis, web3},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3665939.3665960,
author = {Strasser, Sebastian and Klettke, Meike},
title = {Transparent Data Preprocessing for Machine Learning},
year = {2024},
isbn = {9798400706936},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665939.3665960},
doi = {10.1145/3665939.3665960},
abstract = {Data preprocessing is an important task in machine learning which can significantly improve model outcomes. However, evaluating the impact of data preprocessing is often difficult. There is a need for tools which make it transparent to the user on how certain transformations conducted in preprocessing affect the data. Thus, we propose a vision of a transparency system for data preprocessing that provides insights into data preparation pipelines. Our envisioned system consists of a Python library which enables users to log transformations and processed data. Subsequently, the system generates summaries of the data which was processed in the pipeline and so-called change profiles which capture the changes conducted in each processing step. These abstractions offer insight into the transformations and their effects on data. Additionally, the system includes an user interface where users can interactively discover the implemented pipeline and the changes made during preprocessing. This paper presents an initial concept of such a system. It also examines further challenges related to making preprocessing transparent and discusses potential solutions to address these challenges.},
booktitle = {Proceedings of the 2024 Workshop on Human-In-the-Loop Data Analytics},
pages = {1–6},
numpages = {6},
keywords = {data preprocessing, data profiles, change profiles, transparency},
location = {Santiago, AA, Chile},
series = {HILDA  24}
}

@article{10.1145/3709374,
author = {Thiagarajan, Kedar and Carisimo, Esteban and Bustamante, Fabi\'{a}n E.},
title = {The Aleph: Decoding Geographic Information from DNS PTR Records Using Large Language Models},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {CoNEXT1},
url = {https://doi.org/10.1145/3709374},
doi = {10.1145/3709374},
abstract = {Geolocating network devices is essential for various research areas. Yet, despite notable advancements, it continues to be one of the most challenging issues for experimentalists. An approach for geolocating that has proved effective is leveraging geolocating hints in PTR records associated with network devices. Extracting and interpreting geo-hints from PTR records is challenging because the labels are primarily intended for human interpretation rather than computational processing. Additionally, a lack of standardization across operators -- and even within a single operator, due to factors like rebranding, mergers, and acquisitions -- complicates the process. We argue that Large Language Models (LLMs), rather than humans, are better equipped to identify patterns in DNS PTR records, and significantly scale the coverage of tools like Hoiho. We introduce The Aleph, an approach and system for network device geolocation that utilizes information embedded in PTR records. The Aleph leverages LLMs to classify PTR records, generate regular expressions for these classes, and establish hint-to-location mapping per operator. We present results showing the applicability of using LLMs as a scalable approach to leverage PTR records for infrastructure geolocation.},
journal = {Proc. ACM Netw.},
month = mar,
articleno = {7},
numpages = {20},
keywords = {dns ptr records, internet geolocation, large language models (llms)}
}

@inproceedings{10.1145/3723498.3723809,
author = {Lyu, Qianwen and Millard, David and Gibbins, Nicholas},
title = {Stories from the Bottom Up: Emergent Narratives with Composable Story Sifting Patterns},
year = {2025},
isbn = {9798400718564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723498.3723809},
doi = {10.1145/3723498.3723809},
abstract = {Emergent Narratives (EN) are a popular approach in game design where stories naturally emerge from players’ interactions with the game world. Story sifting is an EN technique where the player’s attention is drawn to particularly interesting narrative patterns, but these story sifting patterns can be complex and difficult to create. To address this, we have developed an event-based rules system that supports composable patterns: building blocks that allow higher-level stories to be constructed from lower level ones. We demonstrate our approach through a simulation (of an alien invasion scenario) alongside a powerful incremental story sifter that curates compound events. We conduct agent ratio and stability testing to demonstrate the system’s robustness, and a complexity test to show how the performance of the sifter scales with agent numbers and map size. Our findings show that the system remains stable throughout. Our work demonstrates that an event-based rules approach can effectively support composite patterns, ultimately enabling the curation of more complex EN stories.},
booktitle = {Proceedings of the 20th International Conference on the Foundations of Digital Games},
articleno = {2},
numpages = {11},
keywords = {Emergent Narrative, Story Sifting, Composable Patterns},
location = {
},
series = {FDG '25}
}

@inproceedings{10.1145/3580305.3599907,
author = {Bashlovkina, Vasilisa and Matthews, Riley and Kuang, Zhaobin and Baumgartner, Simon and Bendersky, Michael},
title = {SMILE: Evaluation and Domain Adaptation for Social Media Language Understanding},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599907},
doi = {10.1145/3580305.3599907},
abstract = {We study the ability of transformer-based language models (LMs) to understand social media language. Social media (SM) language is distinct from standard written language, yet existing benchmarks fall short of capturing LM performance in this socially, economically, and politically important domain. We quantify the degree to which social media language differs from conventional language and conclude that the difference is significant both in terms of token distribution and rate of linguistic shift. Next, we introduce a new benchmark for Social MedIa Language Evaluation (SMILE) that covers four SM platforms and eleven tasks. Finally, we show that learning a tokenizer and pretraining on a mix of social media and conventional language yields an LM that outperforms the best similar-sized alternative by 4.2 points on the overall SMILE score.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3737–3749},
numpages = {13},
keywords = {datasets, language modeling, neural networks, social media, t5, transfer learning},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3643690.3648243,
author = {Yang, Nan and Siemon, Dominik and Hyrynsalmi, Sami},
title = {Modeling 6G Software Business Ecosystem: A Look Ahead},
year = {2024},
isbn = {9798400705717},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643690.3648243},
doi = {10.1145/3643690.3648243},
abstract = {The 6G technology is under development and is expected to be realized by 2030. How to commercialize 6G needs to be considered from a business perspective before technology matures. Understanding the 6G software business ecosystem offers valuable insight into the opportunities and challenges that stakeholders can grasp or overcome. As an open and Software-Defined Network (SDN), 6G business is highly software-intensive, which shifts the previous linear value chains to the future complex value networks. However, existing 6G research mainly focuses on technology standardization and network orchestration, lacking sufficient discussion from the software-intensive business perspective. To address this gap, this study aims to model the 6G software business ecosystem, by adopting methodologies from the Future Studies field, primarily Morphological Analysis (MA). Meanwhile, we follow the five-stage business ecosystem modeling approach as the guideline for decomposing the 6G software business ecosystem into key building blocks. This study identifies four building blocks, namely the 6G vision, stakeholders, their complex relationships, and key opportunities and challenges. Each building block is precisely depicted, moreover, the complex roles and dynamic relationships between stakeholders from software-intensive industries are highlighted.},
booktitle = {Proceedings of the 7th ACM/IEEE International Workshop on Software-Intensive Business},
pages = {64–71},
numpages = {8},
keywords = {6G, software ecosystem, business ecosystem, morphological analysis, business ecosystem modeling},
location = {Lisbon, Portugal},
series = {IWSiB '24}
}

@article{10.1145/3727638,
author = {Hakimi, Yacine and Baghdadi, Riyadh and Challal, Yacine},
title = {Supporting Dynamic Program Sizes in Deep Learning-Based Cost Models for Code Optimization},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {2},
issn = {1544-3566},
url = {https://doi.org/10.1145/3727638},
doi = {10.1145/3727638},
abstract = {Automatic code optimization enables developers to write high-level code relying on compilers to optimize it and generate efficient code for target hardware. State-of-the-art methods for automatic code optimization leverage deep learning to build cost models that predict the impact of code optimizations on execution time. However, these models are typically limited in terms of the size and complexity of the programs they support. This research presents a novel approach to developing deep learning-based cost models that address these limitations. Our approach introduces a new program representation that efficiently represents programs with complex structures and large sizes such as varying loop depths, buffer numbers, and dimensions. Furthermore, we propose a novel deep learning architecture, that can handle this dynamic program representation. This allows the model to work on larger and more complex programs than those it was trained on. We implemented this model in Tiramisu, a state-of-the-art compiler. Our evaluation shows that our proposed model can generalize to programs larger than those seen during training, while the original Tiramisu cost model cannot. We also show that such generality does not lead to a significant increase in our proposed model’s Mean Absolute Percentage Error or a decrease in the quality of code optimizations found when the model is used for automatic code optimization. In contrast, our proposed model on average achieves a 41.89\% improvement in speed compared to the original cost model when both models are trained on the same dataset, showing better generalization over unseen programs. This is a significant advantage over previous approaches, which typically do not support program sizes beyond those seen during the training.},
journal = {ACM Trans. Archit. Code Optim.},
month = jul,
articleno = {67},
numpages = {25},
keywords = {Automatic code optimization, deep learning, cost model, tiramisu}
}

@inproceedings{10.1145/3689031.3717466,
author = {Pan, Lichen and Liu, Juncheng and Fu, Yongquan and Yuan, Jinhui and Zhang, Rongkai and Li, Pengze and Xiao, Zhen},
title = {Comprehensive Deadlock Prevention for GPU Collective Communication},
year = {2025},
isbn = {9798400711961},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689031.3717466},
doi = {10.1145/3689031.3717466},
abstract = {Distributed deep neural network training necessitates efficient GPU collective communications, which are inherently susceptible to deadlocks. GPU collective deadlocks arise easily in distributed deep learning applications when multiple collectives circularly wait for each other. GPU collective deadlocks pose a significant challenge to the correct functioning and efficiency of distributed deep learning, and no general effective solutions are currently available. Only in specific scenarios, ad-hoc methods, making an application invoke collectives in a consistent order across GPUs, can be used to prevent circular collective dependency and deadlocks.This paper presents DFCCL, a novel GPU collective communication library that provides a comprehensive approach for GPU collective deadlock prevention while maintaining high performance. DFCCL achieves preemption for GPU collectives at the bottom library level, effectively preventing deadlocks even if applications cause circular collective dependency. DFCCL ensures high performance with its execution and scheduling methods for collectives. Experiments show that DFCCL effectively prevents GPU collective deadlocks in various situations. Moreover, extensive evaluations demonstrate that DFCCL delivers performance comparable to or superior to NCCL, the state-of-the-art collective communication library highly optimized for NVIDIA GPUs.},
booktitle = {Proceedings of the Twentieth European Conference on Computer Systems},
pages = {541–557},
numpages = {17},
keywords = {Collective Communication, Deadlock Prevention, GPU, Preemption},
location = {Rotterdam, Netherlands},
series = {EuroSys '25}
}

@inproceedings{10.1145/3503161.3548390,
author = {Wang, Run and Li, Haoxuan and Mu, Lingzhou and Ren, Jixing and Guo, Shangwei and Liu, Li and Fang, Liming and Chen, Jing and Wang, Lina},
title = {Rethinking the Vulnerability of DNN Watermarking: Are Watermarks Robust against Naturalness-aware Perturbations?},
year = {2022},
isbn = {9781450392037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503161.3548390},
doi = {10.1145/3503161.3548390},
abstract = {Training Deep Neural Networks (DNN) is a time-consuming process and requires a large amount of training data, which motivates studies working on protecting the intellectual property (IP) of DNN models by employing various watermarking techniques. Unfortunately, in recent years, adversaries have been exploiting the vulnerabilities of the employed watermarking techniques to remove the embedded watermarks. In this paper, we investigate and introduce a novel watermark removal attack, called AdvNP, against all the existing four different types of DNN watermarking schemes via input preprocessing by injecting &lt;u&gt;Adv&lt;/u&gt;ersarial &lt;u&gt;N&lt;/u&gt;aturalness-aware &lt;u&gt;P&lt;/u&gt;erturbations. In contrast to the prior studies, our proposed method is the first work that generalizes all the existing four watermarking schemes well without involving any model modification, which preserves the fidelity of the target model. We conduct the experiments against four state-of-the-art (SOTA) watermarking schemes on two real tasks (e.g., image classification on ImageNet, face recognition on CelebA) across multiple DNN models. Overall, our proposed AdvNP significantly invalidates the watermarks against the four watermarking schemes on two real-world datasets, i.e., 60.9\% on the average attack success rate and up to 97\% in the worse case. Moreover, our AdvNP could well survive the image denoising techniques and outperforms the baseline in both the fidelity preserving and watermark removal. Furthermore, we introduce two defense methods to enhance the robustness of DNN watermarking against our AdvNP. Our experimental results pose real threats to the existing watermarking schemes and call for more practical and robust watermarking techniques to protect the copyright of pre-trained DNN models. The source code and models are available at ttps://github.com/GitKJ123/AdvNP.},
booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
pages = {1808–1818},
numpages = {11},
keywords = {dnn watermarking, naturalness-aware perturbations, relighting},
location = {Lisboa, Portugal},
series = {MM '22}
}

@inproceedings{10.1145/3611643.3616322,
author = {Wang, Bo and Li, Ruishi and Li, Mingkai and Saxena, Prateek},
title = {TransMap: Pinpointing Mistakes in Neural Code Translation},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3616322},
doi = {10.1145/3611643.3616322},
abstract = {Automated code translation between programming languages can greatly reduce the human effort needed in learning new languages or in migrating code. Recent neural machine translation models, such as Codex, have been shown to be effective on many code generation tasks including translation. However, code produced by neural translators often has semantic mistakes. These mistakes are difficult to eliminate from the neural translator itself because the translator is a black box, which is difficult to interpret or control compared to rule-based transpilers. We propose the first automated approach to pinpoint semantic mistakes in code obtained after neural code translation. Our techniques are implemented in a prototype tool called TransMap which translates Python to JavaScript, both of which are popular scripting languages. On our created micro-benchmarks of Python programs with 648 semantic mistakes in total, TransMap accurately pinpoints the correct location for a fix for 87.96\%, often highlighting 1-2 lines for the user to inspect per mistake. We report on our experience in translating 5 Python libraries with up to 1k lines of code with TransMap. Our preliminary user study suggests that TransMap can reduce the time for fixing semantic mistakes by around 70\% compared to using a standard IDE with debuggers.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {999–1011},
numpages = {13},
keywords = {Code Translation, Large Language Models, Semantic Mistakes},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@article{10.1145/3650206,
author = {Kaur, Ravleen and Bhatia, M. P. S. and Kumar, Akshi},
title = {Am I Hurt?: Evaluating Psychological Pain Detection in Hindi Text Using Transformer-based Models},
year = {2024},
issue_date = {August 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {8},
issn = {2375-4699},
url = {https://doi.org/10.1145/3650206},
doi = {10.1145/3650206},
abstract = {The automated evaluation of pain is critical for developing effective pain management approaches that seek to alleviate pain while preserving patients’ functioning. Transformer-based models can aid in detecting pain from Hindi text data gathered from social media by leveraging their ability to capture complex language patterns and contextual information. By understanding the nuances and context of Hindi text, transformer models can effectively identify linguistic cues and sentiments and expressions associated with pain, enabling the detection and analysis of pain-related content present in social media posts. The purpose of this research is to analyze the feasibility of utilizing NLP techniques to automatically identify pain within Hindi textual data, providing a valuable tool for pain assessment in Hindi-speaking populations. The research showcases the HindiPainNet model, a deep neural network that employs the IndicBERT model, classifying the dataset into two class labels {pain, no_pain} for detecting pain in Hindi textual data. The model is trained and tested using a novel dataset, दर्द-ए-शायरी (pronounced as Dard-e-Shayari), curated using posts from social media platforms. The results demonstrate the model's effectiveness, achieving an accuracy of 70.5\%. This pioneer research highlights the potential of utilizing textual data from diverse sources to identify and understand pain experiences based on psychosocial factors. This research could pave the path for the development of automated pain assessment tools that help medical professionals comprehend and treat pain in Hindi-speaking populations. Additionally, it opens avenues to conduct further NLP-based multilingual pain detection research, addressing the needs of diverse language communities.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = aug,
articleno = {125},
numpages = {17},
keywords = {Pain detection, social media, word embeddings, transformer-based models, emotional pain}
}

@inproceedings{10.1145/3613904.3642172,
author = {Zhou, Tongyu and Huang, Jeff and Chan, Gromit Yeuk-Yin},
title = {Epigraphics: Message-Driven Infographics Authoring},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642172},
doi = {10.1145/3613904.3642172},
abstract = {The message a designer wants to convey plays a pivotal role in directing the design of an infographic, yet most authoring workflows start with creating the visualizations or graphics first without gauging whether they fit the message. To address this gap, we propose Epigraphics, a web-based authoring system that treats an “epigraph” as the first-class object, and uses it to guide infographic asset creation, editing, and syncing. The system uses the text-based message to recommend visualizations, graphics, data filters, color palettes, and animations. It further supports between-asset interactions and fine-tuning such as recoloring, highlighting, and animation syncing that enhance the aesthetic cohesiveness of the assets. A gallery and case studies show that our system can produce infographics inspired by existing popular ones, and a task-based usability study with 10 designers show that a text-sourced workflow can standardize content, empower users to think more about the big picture, and facilitate rapid prototyping.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {200},
numpages = {18},
keywords = {data visualization, infographics authoring, visual storytelling},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@article{10.1145/3733598,
author = {Zheng, Kai and Wang, Zan and Zhao, Yingquan and Chen, Junjie and You, Hanmo and Wang, Haoyu and Du, Yiheng and Gao, Tianchang},
title = {Exploring JVM Garbage Collector Testing with Event-Coverage},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3733598},
doi = {10.1145/3733598},
abstract = {Garbage Collection (GC) in the Java Virtual Machine (JVM) serves as an automatic memory management mechanism, efficiently reclaiming unused memory space in different production scenarios. To optimize JVM performance, developers typically fine-tune the garbage collector by identifying an optimal set of GC configurations for specific scenarios. Despite the sophisticated design of garbage collectors, they still have the potential for bugs in different settings, and these bugs can result in more severe consequences. Hence, comprehensive testing of these garbage collectors is imperative before their release. Code coverage criteria are typically employed to assess the comprehensiveness of a test suite. However, traditional code coverage metrics, such as branch coverage, are hardly applicable for GC testing due to their inherent concurrency. Additionally, existing JVM testing techniques do not adequately consider the characteristics of garbage collectors, making it difficult to test these garbage collectors sufficiently. In this paper, we make the first effort to design coverage criteria against garbage collectors based on the events of GC called Event-Coverage. Its key insight is to measure the diversity of GC executions for testing purposes by assessing the range of GC events these executions cover. Furthermore, we design a new testing method for maximizing Event-Coverage called GCFuzz. GCFuzz conducts an exhaustive investigation of the memory state space of GC and thoroughly explores the memory state under various GC configurations. To enhance GCFuzz’s efficiency in achieving higher Event-Coverage, we have further designed a coverage-driven strategy for preserving candidate seed programs and selecting GC configurations. Extensive evaluations demonstrate a positive correlation between Event-Coverage and the bug-revealing efficiency. Moreover, GCFuzz outperforms state-of-the-art techniques in detecting unique GC-related inconsistencies and achieving higher Event-Coverage. Remarkably, GCFuzz has identified 20 previously undetected GC bugs, with 15 of them already confirmed or fixed by developers.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
keywords = {Java Virtual Machine, Program Generation, JVM Testing, Garbage Collection, GC Testing, Event-Coverage}
}

@inproceedings{10.1145/3726302.3730277,
author = {Chen, Qiaosheng and Huang, Kaijia and Zhou, Xiao and Luo, Weiqing and Cui, Yuanning and Cheng, Gong},
title = {Benchmarking Recommendation, Classification, and Tracing Based on Hugging Face Knowledge Graph},
year = {2025},
isbn = {9798400715921},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3726302.3730277},
doi = {10.1145/3726302.3730277},
abstract = {The rapid growth of open source machine learning (ML) resources, such as models and datasets, has accelerated IR research. However, existing platforms like Hugging Face do not explicitly utilize structured representations, limiting advanced queries and analyses such as tracing model evolution and recommending relevant datasets. To fill the gap, we construct HuggingKG, the first large-scale knowledge graph built from the Hugging Face community for ML resource management. With 2.6 million nodes and 6.2 million edges, HuggingKG captures domain-specific relations and rich textual attributes. It enables us to further present HuggingBench, a multi-task benchmark with three novel test collections for IR tasks including resource recommendation, classification, and tracing. Our experiments reveal unique characteristics of HuggingKG and the derived tasks. Both resources are publicly available, expected to advance research in open source resource sharing and management.},
booktitle = {Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {3433–3443},
numpages = {11},
keywords = {hugging face, knowledge graph, model tracing, resource recommendation, task classification, test collection},
location = {Padua, Italy},
series = {SIGIR '25}
}

@inproceedings{10.1145/3708394.3708452,
author = {Sun, Weiwei and Qin, Minwu and Yin, Zhenyao},
title = {Exploring Educational Transformation and Innovation Pathways in the Era of Artificial Intelligence},
year = {2025},
isbn = {9798400710650},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708394.3708452},
doi = {10.1145/3708394.3708452},
abstract = {This study analyzes the profound impact of artificial intelligence (AI) on education, exploring the applications of educational reform theory, technological innovation theory, and the theory of equal educational opportunities in the context of AI-driven educational transformation. The rapid advancement of AI technologies—particularly deep learning, intelligent image recognition, big data, and educational robotics—is driving education from traditional models toward personalization, lifelong learning, and intelligent approaches. Technological innovation not only revamps teaching tools and resources but also enables differentiated instruction through intelligent data analysis, promoting educational equity and enhancing students’ self-learning abilities. AI demonstrates immense potential in supporting lifelong learning, optimizing educational processes, and enriching the educational ecosystem; however, it also raises ethical challenges, including privacy concerns and risks of educational alienation. Consequently, educators should focus on the responsible application of AI technologies, leveraging the intrinsic strengths of education, to improve teaching quality and foster harmonious development between humans and machines.},
booktitle = {Proceeding of the 2024 International Conference on Artificial Intelligence and Future Education},
pages = {338–346},
numpages = {9},
keywords = {Artificial Intelligence, Educational Transformation, Intelligent Classroom, Personalized Learning, Teaching Innovation},
location = {
},
series = {AIFE '24}
}

@article{10.1145/3666005,
author = {Metzger, Andreas and Laufer, Jan and Feit, Felix and Pohl, Klaus},
title = {A User Study on Explainable Online Reinforcement Learning for Adaptive Systems},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {3},
issn = {1556-4665},
url = {https://doi.org/10.1145/3666005},
doi = {10.1145/3666005},
abstract = {Online reinforcement learning (RL) is increasingly used for realizing adaptive systems in the presence of design time uncertainty because Online RL can leverage data only available at run time. With Deep RL gaining interest, the learned knowledge is no longer represented explicitly but hidden in the parameterization of the underlying artificial neural network. For a human, it thus becomes practically impossible to understand the decision-making of Deep RL, which makes it difficult for (1) software engineers to perform debugging, (2) system providers to comply with relevant legal frameworks, and (3) system users to build trust. The explainable RL technique XRL-DINE, introduced in earlier work, provides insights into why certain decisions were made at important time steps. Here, we perform an empirical user study concerning XRL-DINE involving 73 software engineers split into treatment and control groups. The treatment group is given access to XRL-DINE, while the control group is not. We analyze (1) the participants’ performance in answering concrete questions related to the decision-making of Deep RL, (2) the participants’ self-assessed confidence in giving the right answers, (3) the perceived usefulness and ease of use of XRL-DINE, and (4) the concrete usage of the XRL-DINE dashboard.},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = sep,
articleno = {15},
numpages = {44},
keywords = {adaptive system, machine learning, reinforcement learning, explainability, interpretability, debugging}
}

@inproceedings{10.1145/3555776.3577715,
author = {Lefebvre, Guillaume and Elghazel, Haytham and Guillet, Th\'{e}odore and Aussem, Alexandre and Sonnati, Matthieu},
title = {BERTEPro : A new Sentence Embedding Framework for the Education and Professional Training domain},
year = {2023},
isbn = {9781450395175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3555776.3577715},
doi = {10.1145/3555776.3577715},
abstract = {FlauBERT and CamemBERT have established a new state-of-the-art performance for French language understanding. Recently, SBERT has transformed the use of BERT, in order to reduce the computational effort of sentence similarity, while maintaining the accuracy of BERT.However, these models have been trained on non-specific texts of the French language, which does not allow for a fine-grained representation of texts from specific domains, such as the Education and professional training domain.In this paper, we present BERTEPro, a sentence embedding framework based on FlauBERT, whose pre-training using MLM (Masked Language Modeling) has been extended on education and professional training texts, before being fine-tuned on NLI (Natural Language Inference) and STS (Semantic Textual Similarity) tasks.The performance evaluation of BERTEPro on STS tasks, as well as on classification tasks, confirmed that the proposed methodology has significant advantages over other state-of-the-art methods.},
booktitle = {Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing},
pages = {929–935},
numpages = {7},
keywords = {education and professional training domain, sentence embedding, sentence similarity, transformers, NLP},
location = {Tallinn, Estonia},
series = {SAC '23}
}

@article{10.1109/TCBB.2024.3442199,
author = {He, Xinyu and Tang, Yujie and Yu, Bo and Li, Shixin and Ren, Yonggong},
title = {Joint Extraction of Biomedical Events Based on Dynamic Path Planning Strategy and Hybrid Neural Network},
year = {2024},
issue_date = {Nov.-Dec. 2024},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {21},
number = {6},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2024.3442199},
doi = {10.1109/TCBB.2024.3442199},
abstract = {Biomedical event detection is a pivotal information extraction task in molecular biology and biomedical research, which provides inspiration for the medical search, disease prevention, and new drug development. The existing methods usually detect simple biomedical events and complex events with the same model, and the performance of the complex biomedical event extraction is relatively low. In this paper, we build different neural networks for simple and complex events respectively, which helps to promote the performance of complex event extraction. To avoid redundant information, we design dynamic path planning strategy for argument detection. To take full use of the information between the trigger identification and argument detection subtasks, and reduce the cascading errors, we build a joint event extraction model. Experimental results demonstrate our approach achieves the best F-score on the biomedical benchmark MLEE dataset and outperforms the recent state-of-the-art methods.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = aug,
pages = {2064–2075},
numpages = {12}
}

@inproceedings{10.1145/3559009.3569656,
author = {Zhao, Jie and Bastoul, C\'{e}dric and Yi, Yanzhi and Hu, Jiahui and Nie, Wang and Zhang, Renwei and Geng, Zhen and Li, Chong and Tachon, Thibaut and Gan, Zhiliang},
title = {Parallelizing Neural Network Models Effectively on GPU by Implementing Reductions Atomically},
year = {2023},
isbn = {9781450398688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3559009.3569656},
doi = {10.1145/3559009.3569656},
abstract = {Due to the missing of a good orchestration of loop transformations, existing optimizing compilers for deploying neural networks on GPU either parallelize reductions ineffectively or miss the fusion opportunities with other operators. Neural network models thus exhibit sub-optimal performance on GPU. We present a practical approach called Panamera for the effective parallelization of reductions in neural networks on GPU. Panamera first leverages loop coalescing to flatten the loop dimensions of reductions, converting all reduction operators into canonical forms eligible for the polyhedral model. Next, Panamera uses polyhedral transformations to reduce the data movements caused by unfused reductions and perform multi-block hardware binding not considered by many compilers. Finally, Panamera embeds a highly optimized routine implemented using GPU atomic instructions, further improving the performance of neural network models while guaranteeing the correctness of parallel reductions. The experimental results demonstrate the effectiveness of our approach: for single operators our code obtains a mean speedup of 33.7\texttimes{}, 3.5\texttimes{}, 5.4\texttimes{} and 9.6\texttimes{} over cuDNN, CUB, TVM and Ansor, for sub-graphs our approach outperforms cuDNN, TVM and Ansor by 9.5\texttimes{}, 2.6\texttimes{} and 2.7\texttimes{}, and for end-to-end workloads, a tensor compiler integrated with our approach outperforms them by 122.5\%, 19.3\% and 15.2\%.},
booktitle = {Proceedings of the International Conference on Parallel Architectures and Compilation Techniques},
pages = {451–466},
numpages = {16},
keywords = {reduction, polyhedral compilation, deep learning, GPU},
location = {Chicago, Illinois},
series = {PACT '22}
}

@inproceedings{10.1145/3448139.3448178,
author = {Park, Kyungjin and Sohn, Hyunwoo and Mott, Bradford and Min, Wookhee and Saleh, Asmalina and Glazewski, Krista and Hmelo-Silver, Cindy and Lester, James},
title = {Detecting Disruptive Talk in Student Chat-Based Discussion within Collaborative Game-Based Learning Environments},
year = {2021},
isbn = {9781450389358},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448139.3448178},
doi = {10.1145/3448139.3448178},
abstract = {Collaborative game-based learning environments offer significant promise for creating engaging group learning experiences. Online chat plays a pivotal role in these environments by providing students with a means to freely communicate during problem solving. These chat-based discussions and negotiations support the coordination of students’ in-game learning activities. However, this freedom of expression comes with the possibility that some students might engage in undesirable communicative behavior. A key challenge posed by collaborative game-based learning environments is how to reliably detect disruptive talk that purposefully disrupt team dynamics and problem-solving interactions. Detecting disruptive talk during collaborative game-based learning is particularly important because if it is allowed to persist, it can generate frustration and significantly impede the learning process for students. This paper analyzes disruptive talk in a collaborative game-based learning environment for middle school science education to investigate how such behaviors influence students’ learning outcomes and varies across gender and students’ prior knowledge. We present a disruptive talk detection framework that automatically detects disruptive talk in chat-based group conversations. We further investigate both classic machine learning and deep learning models for the framework utilizing a range of dialogue representations as well as supplementary information such as student gender. Findings show that long short-term memory network (LSTM)-based disruptive talk detection models outperform competitive baseline models, indicating that the LSTM-based disruptive talk detection framework offers significant potential for supporting effective collaborative game-based learning through the identification of disruptive talk.},
booktitle = {LAK21: 11th International Learning Analytics and Knowledge Conference},
pages = {405–415},
numpages = {11},
keywords = {Text Analytics, Disruptive Talk Detection, Collaborative Game-Based Learning},
location = {Irvine, CA, USA},
series = {LAK21}
}

@inproceedings{10.1109/SC41406.2024.00094,
author = {Punniyamurthy, Kishore and Hamidouche, Khaled and Beckmann, Bradford M.},
title = {Optimizing Distributed ML Communication with Fused Computation-Collective Operations},
year = {2024},
isbn = {9798350352917},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SC41406.2024.00094},
doi = {10.1109/SC41406.2024.00094},
abstract = {Machine learning models are distributed across multiple nodes using numerous parallelism strategies. The resulting collective communication is often on the critical path due to a lack of independent coarse-grain computation kernels available to execute.In this work, we propose fusing computation with its subsequent collective communication and leverage GPUs' massive parallelism, along with GPU-initiated communication, to overlap communication and computation. Specifically thread-blocks/workgroups (WGs) immediately communicate their results to remote GPUs after completing their computation,while other WGs within the same kernel perform computation. We developed three prototype fused operators (embedding+All-to-All, GEMV+AllReduce, and GEMM+All-to-All) to address the communication overheads in DLRM, Transformers and MoE model architectures. We expose fused kernels as new PyTorch operators, as well as extend the Triton framework to demonstrate their practicality. Our evaluations show our approach effectively overlaps communication with computations, subsequently reducing their combined execution time achieving 12\% - 31\% lower execution time across all three operators.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis},
articleno = {88},
numpages = {17},
keywords = {Collective communication, DLRM, GPU, MoE, Transformers, distributed ML},
location = {Atlanta, GA, USA},
series = {SC '24}
}

@inbook{10.1145/3676641.3716019,
author = {Gong, Sishuai and Rui, Wang and Altinb\"{u}ken, Deniz and Fonseca, Pedro and Maniatis, Petros},
title = {Snowplow: Effective Kernel Fuzzing with a Learned White-box Test Mutator},
year = {2025},
isbn = {9798400710797},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676641.3716019},
abstract = {Kernel fuzzers rely heavily on program mutation to automatically generate new test programs based on existing ones. In particular, program mutation can alter the test's control and data flow inside the kernel by inserting new system calls, changing the values of call arguments, or performing other program mutations. However, due to the complexity of the kernel code and its user-space interface, finding the effective mutation that can lead to the desired outcome such as increasing the coverage and reaching a target code location is extremely difficult, even with the widespread use of manually-crafted heuristics.This work proposes Snowplow, a kernel fuzzer that uses a learned white-box test mutator to enhance test mutation. The core of Snowplow is an efficient machine learning model that can learn to predict promising mutations given the test program to mutate, its kernel code coverage, and the desired coverage. Snowplow is demonstrated on argument mutations of the kernel tests, and evaluated on recent Linux kernel releases. When fuzzing the kernels for 24 hours, Snowplow shows a significant speedup of discovering new coverage (4.8x~5.2x) and achieves higher overall coverage (7.0\%~8.6\%). In a 7-day fuzzing campaign, Snowplow discovers 86 previously-unknown crashes. Furthermore, the learned mutator is shown to accelerate directed kernel fuzzing by reaching 19 target code locations 8.5x faster and two additional locations that are missed by the state-of-the-art directed kernel fuzzer.},
booktitle = {Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
pages = {1124–1138},
numpages = {15}
}

@article{10.1145/3729352,
author = {Chen, Wei-Hao and Cheoh, Jia Lin and Keim, Manthan and Brunswicker, Sabine and Zhang, Tianyi},
title = {Towards Understanding Fine-Grained Programming Mistakes and Fixing Patterns in Data Science},
year = {2025},
issue_date = {July 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {FSE},
url = {https://doi.org/10.1145/3729352},
doi = {10.1145/3729352},
abstract = {Programming is an essential activity in data science (DS). Unlike regular software developers, DS programmers often use Jupyter notebooks instead of conventional IDEs. Moreover, DS programmers focus on statistics, data analytics, and modeling rather than writing production-ready code following best practices in software engineering. Thus, in order to provide effective tool support to improve their productivity, it is important to understand what kinds of errors they make and how they fix them. Previous studies have analyzed DS code from public code-sharing platforms such as GitHub and Kaggle. However, they only accounted for code changes committed to the version history, omitting many programming mistakes that are resolved before code commits. To bridge the gap, we present an in-depth analysis of the fine-grained logs of a DS competition, which includes 390 Jupyter Notebooks written by participants over six weeks. In addition, we conducted semi-structured interviews with 10 DS programmers from different domains to understand the reasons behind their programming mistakes. We identified several unique programming mistakes and fix patterns that had not been reported before, highlighting opportunities for designing new tool support for DS programming.},
journal = {Proc. ACM Softw. Eng.},
month = jun,
articleno = {FSE082},
numpages = {23},
keywords = {Computational Notebook, Data Science, Programming Practice}
}

@article{10.14778/3636218.3636234,
author = {Zhang, Hailin and Zhao, Penghao and Miao, Xupeng and Shao, Yingxia and Liu, Zirui and Yang, Tong and Cui, Bin},
title = {Experimental Analysis of Large-Scale Learnable Vector Storage Compression},
year = {2023},
issue_date = {December 2023},
publisher = {VLDB Endowment},
volume = {17},
number = {4},
issn = {2150-8097},
url = {https://doi.org/10.14778/3636218.3636234},
doi = {10.14778/3636218.3636234},
abstract = {Learnable embedding vector is one of the most important applications in machine learning, and is widely used in various database-related domains. However, the high dimensionality of sparse data in recommendation tasks and the huge volume of corpus in retrieval-related tasks lead to a large memory consumption of the embedding table, which poses a great challenge to the training and deployment of models. Recent research has proposed various methods to compress the embeddings at the cost of a slight decrease in model quality or the introduction of other overheads. Nevertheless, the relative performance of these methods remains unclear. Existing experimental comparisons only cover a subset of these methods and focus on limited metrics. In this paper, we perform a comprehensive comparative analysis and experimental evaluation of embedding compression. We introduce a new taxonomy that categorizes these techniques based on their characteristics and methodologies, and further develop a modular benchmarking framework that integrates 14 representative methods. Under a uniform test environment, our benchmark fairly evaluates each approach, presents their strengths and weaknesses under different memory budgets, and recommends the best method based on the use case. In addition to providing useful guidelines, our study also uncovers the limitations of current methods and suggests potential directions for future research.},
journal = {Proc. VLDB Endow.},
month = dec,
pages = {808–822},
numpages = {15}
}

@inproceedings{10.5555/3712729.3712738,
author = {Haas, Peter J.},
title = {Tutorial: Artificial Neural Networks for Discrete-Event Simulation},
year = {2025},
isbn = {9798331534202},
publisher = {IEEE Press},
abstract = {This advanced tutorial explores some recent applications of artificial neural networks (ANNs) to stochastic discrete-event simulation (DES). We first review some basic concepts and then give examples of how ANNs are being used in the context of DES to facilitate simulation input modeling, random variate generation, simulation metamodeling, optimization via simulation, and more. Combining ANNs and DES allows exploitation of the deep domain knowledge embodied in simulation models while simultaneously leveraging the ability of modern ML techniques to capture complex patterns and relationships in data.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {116–130},
numpages = {15},
location = {Orlando, Florida, USA},
series = {WSC '24}
}

@inproceedings{10.1145/3696410.3714889,
author = {Gui, Yi and Li, Zhen and Wan, Yao and Shi, Yemin and Zhang, Hongyu and Chen, Bohua and Su, Yi and Chen, Dongping and Wu, Siyuan and Zhou, Xing and Jiang, Wenbin and Jin, Hai and Zhang, Xiangliang},
title = {WebCode2M: A Real-World Dataset for Code Generation from Webpage Designs},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714889},
doi = {10.1145/3696410.3714889},
abstract = {Automatically generating webpage code from webpage designs can significantly reduce the workload of front-end developers, and recent Multimodal Large Language Models (MLLMs) have shown promising potential in this area. However, our investigation reveals that most existing MLLMs are constrained by the absence of high-quality, large-scale, real-world datasets, resulting in inadequate performance in automated webpage code generation. To fill this gap, this paper introduces WebCode2M, a new dataset comprising 2.56 million instances, each containing a design image along with the corresponding webpage code and layout details. Sourced from real-world web resources, WebCode2M offers a rich and valuable dataset for webpage code generation across a variety of applications. The dataset quality is ensured by a scoring model that filters out instances with aesthetic deficiencies or other incomplete elements. To validate the effectiveness of WebCode2M, we introduce a baseline model based on the Vision Transformer (ViT), named WebCoder, and establish a benchmark for fair comparison. Additionally, we introduce a new metric, TreeBLEU, to measure the structural hierarchy recall. The benchmarking results demonstrate that our dataset significantly improves the ability of MLLMs to generate code from webpage designs, confirming its effectiveness and usability for future applications in front-end design tools. Finally, we highlight several practical challenges introduced by our dataset, calling for further research. The code and dataset are publicly available at our project homepage: https://webcode2m.github.io.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {1834–1845},
numpages = {12},
keywords = {code generation, dataset, design to code, ui automation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3691620.3694986,
author = {Xiong, Yiheng and Su, Ting and Wang, Jue and Sun, Jingling and Pu, Geguang and Su, Zhendong},
title = {General and Practical Property-based Testing for Android Apps},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3694986},
doi = {10.1145/3691620.3694986},
abstract = {Finding non-crashing functional bugs for Android apps is challenging for both manual testing and automated GUI testing techniques. This paper introduces and designs a general and practical testing technique based on the idea of property-based testing for finding such bugs. Specifically, our technique incorporates (1) a property description language (PDL) to allow specifying desired app properties, and (2) two exploration strategies as the input generators for effectively validating the properties. We implemented our technique as a tool named Kea and evaluated it on 124 historical bugs from eight real-world, popular Android apps. Our evaluation shows that our PDL can specify all the app properties violated by these historical bugs, demonstrating its generability for finding functional bugs. Kea successfully found 66 (68.0\%) and 92 (94.8\%) of the 97 historical bugs in scope under the two exploration strategies, demonstrating its practicability. Moreover, Kea found 25 new functional bugs on the latest versions of these eight apps, given the specified properties. To date, all these bugs have been confirmed, and 21 have been fixed. In comparison, prior state-of-the-art techniques found only 13 (13.4\%) historical bugs and 1 new bug. We have made all the artifacts publicly available at https://github.com/ecnusse/Kea.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {53–64},
numpages = {12},
keywords = {property-based testing, Android app testing, non-crashing functional bugs},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@article{10.1145/3679200,
author = {Liao, Weibin and Zhu, Yifan and Li, Yanyan and Zhang, Qi and Ou, Zhonghong and Li, Xuesong},
title = {RevGNN: Negative Sampling Enhanced Contrastive Graph Learning for Academic Reviewer Recommendation},
year = {2024},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/3679200},
doi = {10.1145/3679200},
abstract = {Acquiring reviewers for academic submissions is a challenging recommendation scenario. Recent graph learning-driven models have made remarkable progress in the field of recommendation, but their performance in the academic reviewer recommendation task may suffer from a significant false negative issue. This arises from the assumption that unobserved edges represent negative samples. In fact, the mechanism of anonymous review results in inadequate exposure of interactions between reviewers and submissions, leading to a higher number of unobserved interactions compared to those caused by reviewers declining to participate. Therefore, investigating how to better comprehend the negative labeling of unobserved interactions in academic reviewer recommendations is a significant challenge. This study aims to tackle the ambiguous nature of unobserved interactions in academic reviewer recommendations. Specifically, we propose an unsupervised Pseudo Neg-Label strategy to enhance graph contrastive learning (GCL) for recommending reviewers for academic submissions, which we call RevGNN. RevGNN utilizes a two-stage encoder structure that encodes both scientific knowledge and behavior using Pseudo Neg-Label to approximate review preference. Extensive experiments on three real-world datasets demonstrate that RevGNN outperforms all baselines across four metrics. Additionally, detailed further analyses confirm the effectiveness of each component in RevGNN.},
journal = {ACM Trans. Inf. Syst.},
month = nov,
articleno = {1},
numpages = {26},
keywords = {Academic reviewer recommendation, expert finding, GNN-based recommendation, negative sampling in GCL}
}

@article{10.1145/3586034,
author = {Wang, Bo and Kolluri, Aashish and Nikoli\'{c}, Ivica and Baluta, Teodora and Saxena, Prateek},
title = {User-Customizable Transpilation of Scripting Languages},
year = {2023},
issue_date = {April 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {OOPSLA1},
url = {https://doi.org/10.1145/3586034},
doi = {10.1145/3586034},
abstract = {A transpiler converts code from one programming language to another. Many practical uses of transpilers require the user to be able to guide or customize the program produced from a given input program. This customizability is important for satisfying many application-specific goals for the produced code such as ensuring performance, readability, ease of exposition or maintainability, compatibility with external environment or analysis tools, and so on. Conventional transpilers are deterministic rule-driven systems often written without offering customizability per user and per program. Recent advances in transpilers based on neural networks offer some customizability to users, e.g. through interactive prompts, but they are still difficult to precisely control the production of a desired output. Both conventional and neural transpilation also suffer from the "last mile" problem: they produce correct code on average, i.e., on most parts of a given program, but not necessarily for all parts of it. We propose a new transpilation approach that offers fine-grained customizability and reusability of transpilation rules created by others, without burdening the user to understand the global semantics of the given source program. Our approach is mostly automatic and incremental, i.e., constructs translation rules needed to transpile the given program as per the user's guidance piece-by-piece. Users can rely on existing transpilation rules to translate most of the program correctly while focusing their effort locally, only on parts that are incorrect or need customization. This improves the correctness of the end result. We implement the transpiler as a tool called DuoGlot, which translates Python to Javascript programs, and evaluate it on the popular GeeksForGeeks benchmarks. DuoGlot achieves 90\% translation accuracy and so it outperforms all existing translators (both handcrafted and neural-based), while it produces readable code. We evaluate DuoGlot on two additional benchmarks, containing more challenging and longer programs, and similarly observe improved accuracy compared to the other transpilers.},
journal = {Proc. ACM Program. Lang.},
month = apr,
articleno = {82},
numpages = {29},
keywords = {Program Synthesis, Program Translation}
}

@inproceedings{10.1109/ISCA59077.2024.00076,
author = {Wang, Fuyu and Shen, Minghua and Ding, Yufei and Xiao, Nong},
title = {Soter: Analytical Tensor-Architecture Modeling and Automatic Tensor Program Tuning for Spatial Accelerators},
year = {2025},
isbn = {9798350326581},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ISCA59077.2024.00076},
doi = {10.1109/ISCA59077.2024.00076},
abstract = {Spatial accelerator is a specialized hardware to provide noticeable performance speedup for tensor computations. It also brings a challenge to map tensor computations on spatial accelerators. Auto-tuning compiler is one of the most promising directions for tensor mapping. However, existing auto-tuning compilers suffer from either numerous invalid and inefficient programs or inaccurate evaluation of incomplete programs, leading to sub-optimal performance.In this paper, we propose Soter, a novel auto-tuning tensor compilation framework for spatial accelerators. The key is to perform exploration in a both valid and efficient program design space and perform optimization according to accurate evaluation of complete programs. First, we design an analytical model to generate a high-quality program design space, which excludes invalid and inefficient programs. Second, we design an automatic program tuner to efficiently explore the program space and avoid evaluating incomplete programs. Finally, we coordinate the model and the tuner to further improve the quality of program space. The program space is identified by the model and is updated during the exploration of tuner. On average, Soter achieves 2.1\texttimes{} to 3.5\texttimes{} speedup over the state-of-the-art tensor compilers. Moreover, Soter shows better scalability for larger-scale tensor computations and spatial architectures.},
booktitle = {Proceedings of the 51st Annual International Symposium on Computer Architecture},
pages = {991–1004},
numpages = {14},
location = {Buenos Aires, Argentina},
series = {ISCA '24}
}

@inproceedings{10.1145/3462757.3466103,
author = {Rosa, Guilherme Moraes and Rodrigues, Ruan Chaves and de Alencar Lotufo, Roberto and Nogueira, Rodrigo},
title = {To tune or not to tune? zero-shot models for legal case entailment},
year = {2021},
isbn = {9781450385268},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3462757.3466103},
doi = {10.1145/3462757.3466103},
abstract = {There has been mounting evidence that pretrained language models fine-tuned on large and diverse supervised datasets can transfer well to a variety of out-of-domain tasks. In this work, we investigate this transfer ability to the legal domain. For that, we participated in the legal case entailment task of COLIEE 2021, in which we use such models with no adaptations to the target domain. Our submissions achieved the highest scores, surpassing the second-best submission by more than six percentage points. Our experiments confirm a counter-intuitive result in the new paradigm of pretrained language models: given limited labeled data, models with little or no adaption to the target task can be more robust to changes in the data distribution than models fine-tuned on it. Code is available at https://github.com/neuralmind-ai/coliee.},
booktitle = {Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law},
pages = {295–300},
numpages = {6},
keywords = {T5, deberta, legal NLP, legal case entailment, zero-shot},
location = {S\~{a}o Paulo, Brazil},
series = {ICAIL '21}
}

@inproceedings{10.1145/3486607.3486749,
author = {Heyman, Geert and Huysegems, Rafael and Justen, Pascal and Van Cutsem, Tom},
title = {Natural language-guided programming},
year = {2021},
isbn = {9781450391108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3486607.3486749},
doi = {10.1145/3486607.3486749},
abstract = {In today’s software world with its cornucopia of reusable software libraries, when a programmer is faced with a programming task that they suspect can be completed through the use of a library, they often look for code examples using a search engine and then manually adapt found examples to their specific context of use. We put forward a vision based on a new breed of developer tools that have the potential to largely automate this process. The key idea is to adapt code autocompletion tools such that they take into account not only the developer’s already-written code but also the intent of the task the developer is trying to achieve next, formulated in plain natural language. We call this practice of enriching the code with natural language intent to facilitate its completion natural language-guided programming. To show that this idea is feasible we design, implement and benchmark a tool that solves this problem in the context of a specific domain (data science) and a specific programming language (Python). Central to the tool is the use of language models trained on a large corpus of documented code. Our initial experiments confirm the feasibility of the idea but also make it clear that we have only scratched the surface of what may become possible in the future. We end the paper with a comprehensive research agenda to stimulate additional research in the budding area of natural language-guided programming.},
booktitle = {Proceedings of the 2021 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
pages = {39–55},
numpages = {17},
keywords = {natural language-guided programming, example-centric programming, code prediction, code completion},
location = {Chicago, IL, USA},
series = {Onward! 2021}
}

@inproceedings{10.1145/3616855.3635825,
author = {akota, Marija and Peyrard, Maxime and West, Robert},
title = {Fly-Swat or Cannon? Cost-Effective Language Model Choice via Meta-Modeling},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3635825},
doi = {10.1145/3616855.3635825},
abstract = {Generative language models (LMs) have become omnipresent across data science. For a wide variety of tasks, inputs can be phrased as natural language prompts for an LM, from whose output the solution can then be extracted. LM performance has consistently been increasing with model size---but so has the monetary cost of querying the ever larger models. Importantly, however, not all inputs are equally hard: some require larger LMs for obtaining a satisfactory solution, whereas for others smaller LMs suffice. Based on this fact, we design a framework for cost effective language model choice, called ''Fly-swat or cannon'' (FORC). Given a set of inputs and a set of candidate LMs, FORC judiciously assigns each input to an LM predicted to do well on the input according to a so-called meta-model, aiming to achieve high overall performance at low cost. The cost--performance tradeoff can be flexibly tuned by the user. Options include, among others, maximizing total expected performance (or the number of processed inputs) while staying within a given cost budget, or minimizing total cost while processing all inputs. We evaluate FORC on 14 datasets covering five natural language tasks, using four candidate LMs of vastly different size and cost. With FORC, we match the performance of the largest available LM while achieving a cost reduction of 63\%. Via our publicly available library, (https://github.com/epfl-dlab/forc) researchers as well as practitioners can thus save large amounts of money without sacrificing performance.},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {606–615},
numpages = {10},
keywords = {cost-performance tradeoff, generative models, meta-modelling},
location = {Merida, Mexico},
series = {WSDM '24}
}

@article{10.1145/3716133,
author = {Sanctorum, Audrey and Signer, Beat},
title = {eSPACE: Leveraging Theoretical Foundations for the End-User Development of Cross-Device and IoT Applications},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {3},
issn = {1073-0516},
url = {https://doi.org/10.1145/3716133},
doi = {10.1145/3716133},
abstract = {In the rapidly evolving landscape of cross-device computing and the Internet of Things (IoT), there is a need for intuitive and user-friendly solutions empowering end users to create and tailor their applications. To address this need, we analysed the different metaphors for End-User Development (EUD) of cross-device and IoT applications. A key observation is the lack of addressing end user’s mental models when designing interactions among devices, resulting in less intuitive EUD tools. To fill this gap, we introduce eSPACE, an end-user authoring tool facilitating the development of cross-device and IoT applications. In contrast to most existing tools, eSPACE is grounded on strong theoretical foundations, including a conceptual model, reference framework as well as design guidelines and suitable metaphors. The effectiveness of these theoretical foundations in creating an intuitive and user-friendly EUD platform has been validated in a user study. Our study confirms eSPACE’s potential as a useful and easy to use tool for end-user application development. In addition, we present potential future research directions, including automation functionality, intelligibility and human-AI interaction. In discussing these future directions, we aim to foster and advance EUD research towards more end-user-accessible authoring environments for cross-device and IoT applications.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = jun,
articleno = {28},
numpages = {50},
keywords = {end-user development, end-user authoring tool, Internet of Things, cross-device interaction, metaphors}
}

@inproceedings{10.1145/3639478.3639814,
author = {Speth, Sandro},
title = {Architecture-Based Cross-Component Issue Management and Propagation Analysis},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3639814},
doi = {10.1145/3639478.3639814},
abstract = {This paper addresses the challenge of issue management in complex, component-based software architectures. In these systems, issues in one component often propagate across the architecture along the call chains. Yet, traditional issue management systems (IMSs) are limited to the boundaries of a single component and lack mechanisms for managing issues concerning their architectural dependencies. We present Gropius, a novel method that enhances issue management by integrating issues in an architecture graph. Gropius allows semantically linking issues across different components, synchronizes changes with underlying IMSs like GitHub, and allows modeling the architecture ontologically by defining the components' semantics at runtime. We explore whether combining issue and architecture management improves the development of component-based architectures regarding issue management. We hypothesize that this method will improve the efficiency and effectiveness of identifying and resolving cross-component issues, maintaining a comprehensive view of the application's state.},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {145–149},
numpages = {5},
keywords = {issue management, issue propagation analysis, component-based software architecture, model-based analysis},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

@inproceedings{10.1145/3672608.3707840,
author = {Shin, Yong-Jun and Utz, Wilfrid},
title = {A Platform-Independent Software-Intensive Workflow Modeling Language And An Open-Source Visual Programming Tool: A Bottom-Up Approach Using Ontology Integration Of Industrial Workflow Engines},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707840},
doi = {10.1145/3672608.3707840},
abstract = {Many contemporary software-intensive services are developed as workflows of collaborative and interdependent tasks. Industrial workflow platforms (i.e., engines) such as Airflow and Kubeflow automatically execute and monitor the workflow specified in platform-specific code. The code-based workflow specification becomes complex and error-prone as services grow in complexity. Furthermore, differences in platform-specific workflow specifications cause inefficiencies when porting workflows between platforms, even if the different platforms handle semantically the same workflow.In this paper, we propose a bottom-up approach for developing a platform-independent software-intensive workflow modeling language. The approach systematically extends the UML activity diagram by building platform-independent ontologies of the workflow specification from the given target industrial workflow engines. Based on the approach, we develop a platform-independent Workflow Modeling Language (WorkflowML) that covers four famous workflow engines (Airflow, Kubeflow, Argo workflow, and Metaflow). Furthermore, we implement an open-source visual programming tool for WorkflowML using the ADOxx metamodeling platform. We validate our approach by evaluating the expressiveness of WorkflowML based on modeling case studies of 42 simple workflows and two real-case workflow-based services. The evaluation results validate that WorkflowML serves as an effective common visual language for target workflow engines, supported by an open-source visual programming tool.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {1421–1430},
numpages = {10},
keywords = {workflow, domain-specific modeling language, metamodeling, visual programming, tool, ADOxx, ontology},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@article{10.1145/3571284,
author = {P\'{e}rez, V\'{\i}ctor and Sommer, Lukas and Lom\"{u}ller, Victor and Narasimhan, Kumudha and Goli, Mehdi},
title = {User-driven Online Kernel Fusion for SYCL},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {2},
issn = {1544-3566},
url = {https://doi.org/10.1145/3571284},
doi = {10.1145/3571284},
abstract = {Heterogeneous programming models are becoming increasingly popular to support the ever-evolving hardware architectures, especially for new and emerging specialized accelerators optimizing specific tasks. While such programs provide performance portability of the existing applications across various heterogeneous architectures to some extent, short-running device kernels can affect an application performance due to overheads of data transfer, synchronization, and kernel launch. While in applications with one or two short-running kernels the overhead can be negligible, it can be noticeable when these short-running kernels dominate the overall number of kernels in an application, as it is the case in graph-based neural network models, where there are several small memory-bound nodes alongside few large compute-bound nodes. To reduce the overhead, combining several kernels into a single, more optimized kernel is an active area of research. However, this task can be time-consuming and error-prone given the huge set of potential combinations. This can push programmers to seek a tradeoff between (a) task-specific kernels with low overhead but hard to maintain and (b) smaller modular kernels with higher overhead but easier to maintain. While there are DSL-based approaches, such as those provided for machine learning frameworks, which offer the possibility of such a fusion, they are limited to a particular domain and exploit specific knowledge of that domain and, as a consequence, are hard to port elsewhere. This study explores the feasibility of a user-driven kernel fusion through an extension to the SYCL API to address the automation of kernel fusion. The proposed solution requires programmers to define the subgraph regions that are potentially suitable for fusion without any modification to the kernel code or the function signature. We evaluate the performance benefit of our approach on common neural networks and study the performance improvement in detail.},
journal = {ACM Trans. Archit. Code Optim.},
month = mar,
articleno = {21},
numpages = {25},
keywords = {Neural networks, just-in-time compilers, runtime environments}
}

@inproceedings{10.1145/3597503.3639130,
author = {Keim, Jan and Corallo, Sophie and Fuch\ss{}, Dominik and Hey, Tobias and Telge, Tobias and Koziolek, Anne},
title = {Recovering Trace Links Between Software Documentation And Code},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639130},
doi = {10.1145/3597503.3639130},
abstract = {Introduction Software development involves creating various artifacts at different levels of abstraction and establishing relationships between them is essential. Traceability link recovery (TLR) automates this process, enhancing software quality by aiding tasks like maintenance and evolution. However, automating TLR is challenging due to semantic gaps resulting from different levels of abstraction. While automated TLR approaches exist for requirements and code, architecture documentation lacks tailored solutions, hindering the preservation of architecture knowledge and design decisions. Methods This paper presents our approach TransArC for TLR between architecture documentation and code, using component-based architecture models as intermediate artifacts to bridge the semantic gap. We create transitive trace links by combining the existing approach ArDoCo for linking architecture documentation to models with our novel approach ArCoTL for linking architecture models to code.Results We evaluate our approaches with five open-source projects, comparing our results to baseline approaches. The model-to-code TLR approach achieves an average F1-score of 0.98, while the documentation-to-code TLR approach achieves a promising average F1-score of 0.82, significantly outperforming baselines. Conclusion Combining two specialized approaches with an intermediate artifact shows promise for bridging the semantic gap. In future research, we will explore further possibilities for such transitive approaches.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {215},
numpages = {13},
keywords = {software traceability, software architecture, documentation, transitive links, intermediate artifacts, information retrieval},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3658644.3690357,
author = {Gumusel, Ece and Xiao, Yue and Qin, Yue and Qin, Jiaxin and Liao, Xiaojing},
title = {Understanding Legal Professionals' Practices and Expectations in Data Breach Incident Reporting},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3690357},
doi = {10.1145/3658644.3690357},
abstract = {Legal professionals are essential in analyzing data breach incident reports and guiding the response to comply with data privacy laws and regulations. Their expertise helps mitigate privacy and security risks and prevents failures in privacy compliance. However, little research has been done to understand how legal professionals perceive, react to, and face challenges within the data breach incident reporting procedure. In this study, we conducted a simulated incident report assessment experiment and semi-structured interviews with 33 legal professionals who varied in age, gender, and legal background. We reported the criteria used by legal professionals to identify privacy-related items and also uncovered that the agreement among legal professionals on the concepts of privacy-related items is low. Furthermore, we presented findings regarding the perceptions and strategies of legal professionals concerning legal and regulatory compliance, as well as the key features of incident responses that facilitate efficient analysis of data privacy and security law compliance. After taking into account the challenges and suggestions provided by legal professionals, we concluded this study with recommendations for enhancing the effectiveness of legal compliance analysis for incident responses.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {2711–2725},
numpages = {15},
keywords = {GDPR compliance, data breach incident reporting, legal professionals' practices, security and privacy in legal contexts},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1109/ASE56229.2023.00052,
author = {Xiao, Mingxuan and Xiao, Yan and Dong, Hai and Ji, Shunhui and Zhang, Pengcheng},
title = {LEAP: Efficient and Automated Test Method for NLP Software},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00052},
doi = {10.1109/ASE56229.2023.00052},
abstract = {The widespread adoption of DNNs in NLP software has highlighted the need for robustness. Researchers proposed various automatic testing techniques for adversarial test cases. However, existing methods suffer from two limitations: weak error-discovering capabilities, with success rates ranging from 0\% to 24.6\% for BERT-based NLP software, and time inefficiency, taking 177.8s to 205.28s per test case, making them challenging for time-constrained scenarios.To address these issues, this paper proposes LEAP, an automated test method that uses LEvy flight-based Adaptive Particle swarm optimization integrated with textual features to generate adversarial test cases. Specifically, we adopt Levy flight for population initialization to increase the diversity of generated test cases. We also design an inertial weight adaptive update operator to improve the efficiency of LEAP's global optimization of high-dimensional text examples and a mutation operator based on the greedy strategy to reduce the search time.We conducted a series of experiments to validate LEAP's ability to test NLP software and found that the average success rate of LEAP in generating adversarial test cases is 79.1\%, which is 6.1\% higher than the next best approach (PSOattack). While ensuring high success rates, LEAP significantly reduces time overhead by up to 147.6s compared to other heuristic-based methods. Additionally, the experimental results demonstrate that LEAP can generate more transferable test cases and significantly enhance the robustness of DNN-based systems.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1136–1148},
numpages = {13},
keywords = {NLP software testing, particle swarm optimization},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3694715.3695952,
author = {Lattuada, Andrea and Hance, Travis and Bosamiya, Jay and Brun, Matthias and Cho, Chanhee and LeBlanc, Hayley and Srinivasan, Pranav and Achermann, Reto and Chajed, Tej and Hawblitzel, Chris and Howell, Jon and Lorch, Jacob R. and Padon, Oded and Parno, Bryan},
title = {Verus: A Practical Foundation for Systems Verification},
year = {2024},
isbn = {9798400712517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3694715.3695952},
doi = {10.1145/3694715.3695952},
abstract = {Formal verification is a promising approach to eliminate bugs at compile time, before they ship. Indeed, our community has verified a wide variety of system software. However, much of this success has required heroic developer effort, relied on bespoke logics for individual domains, or sacrificed expressiveness for powerful proof automation.Building on prior work on Verus, we aim to enable faster, cheaper verification of rich properties for realistic systems. We do so by integrating and optimizing the best choices from prior systems, tuning our design to overcome barriers encountered in those systems, and introducing novel techniques.We evaluate Verus's effectiveness with a wide variety of case-study systems, including distributed systems, an OS page table, a library for NUMA-aware concurrent data structure replication, a crash-safe storage system, and a concurrent memory allocator, together comprising 6.1K lines of implementation and 31K lines of proof. Verus verifies code 3--61\texttimes{} faster and with less effort than the state of the art.Our results suggest that Verus offers a platform for exploring the next frontiers in system-verification research. Because Verus builds on Rust, Verus is also positioned for wider use in production by developers who have already adopted Rust in the pursuit of more robust systems.},
booktitle = {Proceedings of the ACM SIGOPS 30th Symposium on Operating Systems Principles},
pages = {438–454},
numpages = {17},
location = {Austin, TX, USA},
series = {SOSP '24}
}

@article{10.1145/3622815,
author = {Wang, Shangwen and Lin, Bo and Sun, Zhensu and Wen, Ming and Liu, Yepang and Lei, Yan and Mao, Xiaoguang},
title = {Two Birds with One Stone: Boosting Code Generation and Code Search via a Generative Adversarial Network},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {OOPSLA2},
url = {https://doi.org/10.1145/3622815},
doi = {10.1145/3622815},
abstract = {Automatically transforming developers' natural language descriptions into source code has been a longstanding goal in software engineering research.   Two types of approaches have been proposed in the literature to achieve this: code generation, which involves generating a new code snippet, and code search, which involves reusing existing code.   However, despite existing efforts, the effectiveness of the state-of-the-art techniques remains limited.   To seek for further advancement, our insight is that code generation and code search can help overcome the limitation of each other:   the code generator can benefit from feedback on the quality of its generated code, which can be provided by the code searcher, while the code searcher can benefit from the additional training data augmented by the code generator to better understand code semantics.   Drawing on this insight, we propose a novel approach that combines code generation and code search techniques using a generative adversarial network (GAN), enabling mutual improvement through the adversarial training.   Specifically, we treat code generation and code search as the generator and discriminator in the GAN framework, respectively, and incorporate several customized designs for our tasks.   We evaluate our approach in eight different settings, and consistently observe significant performance improvements for both code generation and code search.   For instance, when using NatGen, a state-of-the-art code generator, as the generator and GraphCodeBERT, a state-of-the-art code searcher, as the discriminator, we achieve a 32\% increase in CodeBLEU score for code generation, and a 12\% increase in mean reciprocal rank for code search on a large-scale Python dataset, compared to their original performances.},
journal = {Proc. ACM Program. Lang.},
month = oct,
articleno = {239},
numpages = {30},
keywords = {Code Generation, Code Search, Generative Adversarial Network}
}

@inproceedings{10.1145/3603216.3624953,
author = {Pulls, Tobias and Witwer, Ethan},
title = {Maybenot: A Framework for Traffic Analysis Defenses},
year = {2023},
isbn = {9798400702358},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3603216.3624953},
doi = {10.1145/3603216.3624953},
abstract = {In light of the increasing ubiquity of end-to-end encryption and the use of technologies such as Tor and VPNs, analyzing communications metadata---traffic analysis---is a last resort for network adversaries. Traffic analysis attacks are more effective thanks to improvements in deep learning, raising the importance of deploying defenses. This paper introduces Maybenot, a framework for traffic analysis defenses. Maybenot is an evolution and generalization of the Tor Circuit Padding Framework by Perry and Kadianakis, designed to support a wide range of protocols and use cases. Defenses are probabilistic state machines that trigger padding and blocking actions based on events. A lightweight simulator enables rapid development and testing of defenses. In addition to describing the Maybenot framework, machines, and simulator, we implement and thoroughly evaluate the state-of-the-art website fingerprinting defenses FRONT and RegulaTor as Maybenot machines. Our evaluation identifies challenges associated with state machine-based frameworks as well as possible enhancements that will further improve Maybenot's support for effective defenses moving forward.},
booktitle = {Proceedings of the 22nd Workshop on Privacy in the Electronic Society},
pages = {75–89},
numpages = {15},
keywords = {framework, traffic analysis, website fingerprinting defenses},
location = {Copenhagen, Denmark},
series = {WPES '23}
}

@inproceedings{10.1145/3718958.3750514,
author = {Liu, Tongrui and Hei, Chenyang and Li, Fuliang and Gao, Chengxi and Cao, Jiamin and Wang, Tianshu and Zhai, Ennan and Wang, Xingwei},
title = {ResCCL: Resource-Efficient Scheduling for Collective Communication},
year = {2025},
isbn = {9798400715242},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3718958.3750514},
doi = {10.1145/3718958.3750514},
abstract = {As distributed deep learning training (DLT) systems scale, collective communication has become a significant performance bottleneck. While current approaches optimize bandwidth utilization and task completion time, existing communication libraries (CCLs) backends fail to efficiently manage GPU resources during algorithm execution, limiting the performance of advanced algorithms. This paper proposes ResCCL, a novel CCL backend designed for Resource-Efficient Scheduling to address key limitations in current systems. ResCCL enhances execution efficiency by optimizing scheduling at the primitive level (e.g., send and recvReduceCopy), enabling flexible thread block (TB) allocation, and generating lightweight communication kernels to minimize runtime overhead. Our approach tackles the global scheduling problem, reduces idle TB resources, and enhances communication bandwidth. Evaluation results demonstrate that ResCCL achieves up to 2.5\texttimes{} improvement in bandwidth performance compared to both NCCL and MSCCL. It reduces SM resource overhead by 77.8\% and increases TB utilization by 41.6\% while running the same algorithms. In end-to-end DLT, ResCCL boosts Megatron's throughput by up to 39\%.},
booktitle = {Proceedings of the ACM SIGCOMM 2025 Conference},
pages = {55–70},
numpages = {16},
keywords = {collective communication, deep learning, scheduling algorithm},
location = {S\~{a}o Francisco Convent, Coimbra, Portugal},
series = {SIGCOMM '25}
}

@inproceedings{10.1145/3626772.3657833,
author = {Dong, Xingning and Feng, Zipeng and Zhou, Chunluan and Yu, Xuzheng and Yang, Ming and Guo, Qingpei},
title = {M2-RAAP: A Multi-Modal Recipe for Advancing Adaptation-based Pre-training towards Effective and Efficient Zero-shot Video-text Retrieval},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657833},
doi = {10.1145/3626772.3657833},
abstract = {We present a Recipe for Effective and Efficient zero-shot video-text Retrieval, dubbed M2-RAAP. Upon popular image-text models like CLIP, most current adaptation-based video-text pre-training methods are confronted by three major issues, i.e., noisy data corpus, time-consuming pre-training, and limited performance gain. Towards this end, we conduct a comprehensive study including four critical steps in video-text pre-training. Specifically, we investigate 1) data filtering and refinement, 2) video input type selection, 3) temporal modeling, and 4) video feature enhancement. We then summarize this empirical study into the M2-RAAP recipe, where our technical contributions lie in 1) the data filtering and text re-writing pipeline resulting in 1M high-quality bilingual video-text pairs, 2) the promotion of video inputs with key-frames to accelerate pre-training, and 3) the Auxiliary-Caption-Guided (ACG) strategy to enhance video features. We conduct extensive experiments by adapting three image-text foundation models on two refined video-text datasets from different languages, validating the robustness and reproducibility of M2-RAAP for adaptation-based pre-training. Results demonstrate that M2-RAAP yields superior performance with significantly less data (-90\%) and time consumption (-95\%), establishing a new SOTA on four English zero-shot retrieval datasets and two Chinese ones. Codebase and refined bilingual data annotations are available at https://github.com/alipay/Ant-Multi-Modal-Framework/tree/main/prj/M2_RAAP.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2156–2166},
numpages = {11},
keywords = {auxiliary-caption-guided video feature enhancement, video key-frame extraction, video-text data filtering and refinement, video-text pre-training, zero-shot video-text retrieval},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@article{10.1145/3643756,
author = {Deb, Sourav and Jain, Kush and van Tonder, Rijnard and Le Goues, Claire and Groce, Alex},
title = {Syntax Is All You Need: A Universal-Language Approach to Mutant Generation},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3643756},
doi = {10.1145/3643756},
abstract = {While mutation testing has been a topic of academic interest for  decades, it is only recently that “real-world” developers, including  industry leaders such as Google and Meta, have adopted mutation  testing. We propose a new approach to the development of mutation  testing tools, and in particular the core challenge of  generating mutants. Current practice tends towards two  limited approaches to mutation generation: mutants are either (1)  generated at the bytecode/IR level, and thus neither human readable nor adaptable to source-level features of languages or projects, or  (2) generated at the source level by language-specific tools that are  hard to write and maintain, and in fact are often abandoned by both  developers and users. We propose instead that source-level mutation  generation is a special case of program transformation in  general, and that adopting this approach allows for a single tool that  can effectively generate source-level mutants for essentially  any programming language. Furthermore, by using parser  parser combinators many of the seeming limitations of an  any-language approach can be overcome, without the need to parse  specific languages. We compare this new  approach to mutation to existing tools, and demonstrate the advantages  of using parser parser combinators to improve on a regular-expression  based approach to generation. Finally, we show that our approach  can provide effective mutant generation even for a language for which  it lacks any language-specific operators, and that is not very similar  in syntax to any language it has been applied to previously.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {30},
numpages = {21},
keywords = {Mutants, Mutation Generation, Software Testing}
}

@article{10.14778/3685800.3685810,
author = {Yi, Peng and Liang, Lei and Zhang, Da and Chen, Yong and Zhu, Jinye and Liu, Xiangyu and Tang, Kun and Chen, Jialin and Lin, Hao and Qiu, Leijie and Zhou, Jun},
title = {KGFabric: A Scalable Knowledge Graph Warehouse for Enterprise Data Interconnection},
year = {2024},
issue_date = {August 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3685800.3685810},
doi = {10.14778/3685800.3685810},
abstract = {Based on the diversified application scenarios at Ant Group, we built the Ant Knowledge Graph Platform (AKGP). It has constructed numerous domain-specific knowledge graphs related to merchants, companies, accounts, products, and more. AKGP manages trillions of structured knowledge graphs, serving search, recommendation, risk control and other businesses. However, as the demand increasing for various workloads such as graph pattern matching, graph representation learning, and cross-domain knowledge reuse, the existing warehouse systems based on relational DBMS or graph databases are unable to meet the requirements. To address these issues, we propose KGFabric, an industrial-scale knowledge graph management system built on the distributed file system (DFS). KGFabric offers a nearline knowledge storage engine that utilizes a Semantic-enhanced Programmable Graph (SPG) model, which is compatible with the Labeled Property Graph (LPG) model. The data is persistently stored in DFS, such as HDFS, which leverages the POSIX file system API, making it suitable for deployment in multi-cloud environment at low cost. KGFabric provides a native graph-based and hybrid storage format that can serve as a shared backend for parallel graph computing systems, significantly accelerating the analysis of multi-workload. Additionally, KGFabric includes a graph fabric framework that minimizes data duplication and guarantees data security.KGFabric is able to manage Peta-scale data and has supported graph fabric and analysis with over 100 billion relations at Ant Group. We conduct experiments on various datasets to evaluate the performance of KGFabric. Compared with popular relational DBMS and graph databases, the storage space for semantic relations is reduced by over 90\%. The performance of graph fabric improves by 21\texttimes{} in real-world workloads. In multi-hop semantic graph analysis, KGFabric enhances performance by 100\texttimes{}.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {3841–3854},
numpages = {14}
}

@inproceedings{10.1145/3447548.3469053,
author = {Wang, Yu and Li, Jinchao and Naumann, Tristan and Xiong, Chenyan and Cheng, Hao and Tinn, Robert and Wong, Cliff and Usuyama, Naoto and Rogahn, Richard and Shen, Zhihong and Qin, Yang and Horvitz, Eric and Bennett, Paul N. and Gao, Jianfeng and Poon, Hoifung},
title = {Domain-Specific Pretraining for Vertical Search: Case Study on Biomedical Literature},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3469053},
doi = {10.1145/3447548.3469053},
abstract = {Information overload is a prevalent challenge in many high-value domains. A prominent case in point is the explosion of the biomedical literature on COVID-19, which swelled to hundreds of thousands of papers in a matter of months. In general, biomedical literature expands by two papers every minute, totalling over a million new papers every year. Search in the biomedical realm, and many other vertical domains is challenging due to the scarcity of direct supervision from click logs. Self-supervised learning has emerged as a promising direction to overcome the annotation bottleneck. We propose a general approach for vertical search based on domain-specific pretraining and present a case study for the biomedical domain. Despite being substantially simpler and not using any relevance labels for training or development, our method performs comparably or better than the best systems in the official TREC-COVID evaluation, a COVID-related biomedical search competition. Using distributed computing in modern cloud infrastructure, our system can scale to tens of millions of articles on PubMed and has been deployed as Microsoft Biomedical Search, a new search experience for biomedical literature: https://aka.ms/biomedsearch.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \&amp; Data Mining},
pages = {3717–3725},
numpages = {9},
keywords = {search, domain-specific pretraining, biomedical, NLP, COVID-19},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@article{10.14778/3632093.3632111,
author = {Singh, Mukul and Cambronero, Jos\'{e} and Gulwani, Sumit and Le, Vu and Negreanu, Carina and Nouri, Elnaz and Raza, Mohammad and Verbruggen, Gust},
title = {FormaT5: Abstention and Examples for Conditional Table Formatting with Natural Language},
year = {2023},
issue_date = {November 2023},
publisher = {VLDB Endowment},
volume = {17},
number = {3},
issn = {2150-8097},
url = {https://doi.org/10.14778/3632093.3632111},
doi = {10.14778/3632093.3632111},
abstract = {Formatting is an important property in tables for visualization, presentation, and analysis. Spreadsheet software allows users to automatically format their tables by writing data-dependent conditional formatting (CF) rules. Writing such rules is often challenging for users as it requires understanding and implementing the underlying logic. We present FormaT5, a transformer-based model that can generate a CF rule given the target table and a natural language description of the desired formatting logic. We find that user descriptions for these tasks are often under-specified or ambiguous, making it harder for code generation systems to accurately learn the desired rule in a single step. To tackle this problem of under-specification and minimise argument errors, FormaT5 learns to predict placeholders though an abstention objective. These placeholders can then be filled by a second model or, when examples of rows that should be formatted are available, by a programming-by-example system. To evaluate FormaT5 on diverse and real scenarios, we create an extensive benchmark of 1053 CF tasks, containing real-world descriptions collected from four different sources. We release our benchmarks to encourage research in this area. Abstention and filling allow FormaT5 to outperform 8 different neural approaches on our benchmarks, both with and without examples. Our results illustrate the value of building domain-specific learning systems.},
journal = {Proc. VLDB Endow.},
month = nov,
pages = {497–510},
numpages = {14}
}

