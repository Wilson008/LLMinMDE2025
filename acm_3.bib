@inproceedings{10.1145/3708036.3708114,
author = {Qiu, Han and Sun, Chuanqiang and Chen, Hongyun and Zou, Baoyu and Dong, Zizheng},
title = {Design and Implementation of an Intelligent Document Extraction and Review System Based on Multimodal Large Language Models},
year = {2025},
isbn = {9798400709999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708036.3708114},
doi = {10.1145/3708036.3708114},
abstract = {This study aims to address the issues of low efficiency and high manual involvement in existing government affairs processes by proposing an automated system based on large model technology. The system integrates modules such as data collection, natural language processing, business rule engine, process generation, and intelligent applications. Innovations include using large models to transform unstructured government information into executable rules, automatically generating process models and documents, and implementing intelligent approval and automated verification at key nodes. Experimental results indicate that the system significantly enhances the automation level and execution efficiency of government affairs processes, providing a new solution for the intelligent transformation of government management.},
booktitle = {Proceedings of the 2024 5th International Conference on Computer Science and Management Technology},
pages = {455–465},
numpages = {11},
keywords = {Government Affairs Process Automation, Intelligent Governance, Large Language Model, Natural Language Processing},
location = {
},
series = {ICCSMT '24}
}

@inproceedings{10.1145/3652620.3687778,
author = {Charles, Joel and Michael, Judith and Netz, Lukas and Rumpe, Bernhard},
title = {Teaching Model-Driven Low-Code Development Platforms},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687778},
doi = {10.1145/3652620.3687778},
abstract = {We present and evaluate a method called grammar masking, which is used to guide large language models (LLMs) toward producing syntactically correct models for a given context-free grammar. Prompt engineering methods such as few-shot learning or priming can be used to improve the chances of an LLM producing correct syntax, but the more complex the grammar, the more time-consuming and less promising these methods become. Previous work is focused primarily on the usage of either language model training or prompt engineering. In this work, a method is presented that restricts the output to a given grammar using constrained decoding to ensure the output adheres to a valid syntax. We use several domain-specific languages (DSLs) built with MontiCore and task multiple LLMs to produce models with and without constrained decoding. A corresponding parser is used to confirm the syntactic correctness of each model. We show that grammar masking can dramatically improve the modeling capabilities of several LLMs, reducing the need for well-refined prompting while increasing the chance of producing correct models.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {570–577},
numpages = {8},
keywords = {LLM, MDSE, guidance, CFG, constrained decoding},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@article{10.1109/TCBB.2024.3480088,
author = {Su, Fangfang and Teng, Chong and Li, Fei and Li, Bobo and Zhou, Jun and Ji, Donghong},
title = {Generative Biomedical Event Extraction With Constrained Decoding Strategy},
year = {2024},
issue_date = {Nov.-Dec. 2024},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {21},
number = {6},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2024.3480088},
doi = {10.1109/TCBB.2024.3480088},
abstract = {Currently, biomedical event extraction has received considerable attention in various fields, including natural language processing, bioinformatics, and computational biomedicine. This has led to the emergence of numerous machine learning and deep learning models that have been proposed and applied to tackle this complex task. While existing models typically adopt an extraction-based approach, which requires breaking down the extraction of biomedical events into multiple subtasks for sequential processing, making it prone to cascading errors. This paper presents a novel approach by constructing a biomedical event generation model based on the framework of the pre-trained language model &lt;italic&gt;T5&lt;/italic&gt;. We employ a sequence-to-sequence generation paradigm to obtain events, the model utilizes constrained decoding algorithm to guide sequence generation, and a curriculum learning algorithm for efficient model learning. To demonstrate the effectiveness of our model, we evaluate it on two public benchmark datasets, Genia 2011 and Genia 2013. Our model achieves superior performance, illustrating the effectiveness of generative modeling of biomedical events.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = oct,
pages = {2471–2484},
numpages = {14}
}

@inproceedings{10.1145/3708282.3708296,
author = {Qiu, Han and Chen, Hongyun and Zou, Baoyu and Dong, Zizheng},
title = {Intelligent Design and Implementation of Government Affairs Processes Driven by Large Language Models},
year = {2025},
isbn = {9798400709869},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708282.3708296},
doi = {10.1145/3708282.3708296},
abstract = {This study aims to address the issues of low efficiency and high manual involvement in existing government affairs processes by proposing an automated system based on large model technology. The system integrates modules such as data collection, natural language processing, business rule engine, process generation, and intelligent applications. Innovations include using large models to transform unstructured government information into executable rules, automatically generating process models and documents, and implementing intelligent approval and automated verification at key nodes. Experimental results indicate that the system significantly enhances the automation level and execution efficiency of government affairs processes, providing a new solution for the intelligent transformation of government management.},
booktitle = {Proceedings of the 2024 International Conference on Artificial Intelligence of Things and Computing},
pages = {70–79},
numpages = {10},
keywords = {Government Affairs Process Automation, Intelligent Governance, Large Language Model, Natural Language Processing},
location = {
},
series = {AITC '24}
}

@inproceedings{10.1145/3543873.3587554,
author = {Chen, Eason and Roche, Niall and Tseng, Yuen-Hsien and Hernandez, Walter and Shangguan, Jiangbo and Moore, Alastair},
title = {Conversion of Legal Agreements into Smart Legal Contracts using NLP},
year = {2023},
isbn = {9781450394192},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543873.3587554},
doi = {10.1145/3543873.3587554},
abstract = {A Smart Legal Contract (SLC) is a specialized digital agreement comprising natural language and computable components. The Accord Project provides an open-source SLC framework containing three main modules: Cicero, Concerto, and Ergo. Currently, we need lawyers, programmers, and clients to work together with great effort to create a usable SLC using the Accord Project. This paper proposes a pipeline to automate the SLC creation process with several Natural Language Processing (NLP) models to convert law contracts to the Accord Project’s Concerto model. After evaluating the proposed pipeline, we discovered that our NER pipeline accurately detects CiceroMark from Accord Project template text with an accuracy of 0.8. Additionally, our Question Answering method can extract one-third of the Concerto variables from the template text. We also delve into some limitations and possible future research for the proposed pipeline. Finally, we describe a web interface enabling users to build SLCs. This interface leverages the proposed pipeline to convert text documents to Smart Legal Contracts by using NLP models.},
booktitle = {Companion Proceedings of the ACM Web Conference 2023},
pages = {1112–1118},
numpages = {7},
keywords = {Blockchain, Domain Specific Language, Human-AI collaboration, Information Retrieval, Smart Legal Contract},
location = {Austin, TX, USA},
series = {WWW '23 Companion}
}

@inproceedings{10.1145/3691620.3695058,
author = {Muttillo, Vittoriano and Di Sipio, Claudio and Rubei, Riccardo and Berardinelli, Luca and Dehghani, MohammadHadi},
title = {Towards Synthetic Trace Generation of Modeling Operations using In-Context Learning Approach},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695058},
doi = {10.1145/3691620.3695058},
abstract = {Producing accurate software models is crucial in model-driven software engineering (MDE). However, modeling complex systems is an error-prone task that requires deep application domain knowledge. In the past decade, several automated techniques have been proposed to support academic and industrial practitioners by providing relevant modeling operations. Nevertheless, those techniques require a huge amount of training data that cannot be available due to several factors, e.g., privacy issues. The advent of large language models (LLMs) can support the generation of synthetic data although state-of-the-art approaches are not yet supporting the generation of modeling operations. To fill the gap, we propose a conceptual framework that combines modeling event logs, intelligent modeling assistants, and the generation of modeling operations using LLMs. In particular, the architecture comprises modeling components that help the designer specify the system, record its operation within a graphical modeling environment, and automatically recommend relevant operations. In addition, we generate a completely new dataset of modeling events by telling on the most prominent LLMs currently available. As a proof of concept, we instantiate the proposed framework using a set of existing modeling tools employed in industrial use cases within different European projects. To assess the proposed methodology, we first evaluate the capability of the examined LLMs to generate realistic modeling operations by relying on well-founded distance metrics. Then, we evaluate the recommended operations by considering real-world industrial modeling artifacts. Our findings demonstrate that LLMs can generate modeling events even though the overall accuracy is higher when considering human-based operations. In this respect, we see generative AI tools as an alternative when the modeling operations are not available to train traditional IMAs specifically conceived to support industrial practitioners.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {619–630},
numpages = {12},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3652620.3688337,
author = {Mottu, Jean-Marie and Suny\'{e}, Gerson},
title = {Emerging New Roles for Low-Code Software Development Platforms},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3688337},
doi = {10.1145/3652620.3688337},
abstract = {Low- and no-code development platforms have introduced two new development roles: the platform engineer and the citizen developer. While the former are still software developers who implement the low- and no-code platforms, the latter use them to develop their domain applications. In practice, however, we believe that the citizen developer role is shared by two people. For example, in the teaching domain, the citizen developer role is shared between a teacher and his assistant. The first is the domain practitioner, while the second is the domain engineer. The Domain Engineer uses the development platform to create a tailored platform for the teacher, who uses it to create an application that will be for his students, the end users. To explore the possibility of differentiate these two roles in current low-code development platforms, we used two different low-code platforms---Mendix and OutSystems---to implement two case studies. These case studies reveal the limitations of current platforms for specializing platforms with functionalities close to those of low-code development platforms. To compare these two platforms, we consider a list of features that these platforms must satisfy. The results show that current low-code development platforms cannot fully support these new roles.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {905–914},
numpages = {10},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3652620.3688253,
author = {Liu, Xiaoran and David, Istvan},
title = {AI Simulation by Digital Twins: Systematic Survey of the State of the Art and a Reference Framework},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3688253},
doi = {10.1145/3652620.3688253},
abstract = {Insufficient data volume and quality are particularly pressing challenges in the adoption of modern subsymbolic AI. To alleviate these challenges, AI simulation recommends developing virtual training environments in which AI agents can be safely and efficiently developed. Digital twins open new avenues in AI simulation, as these high-fidelity virtual replicas of physical systems are equipped with state-of-the-art simulators and the ability to further interact with the physical system for additional data collection. In this paper, we report on our systematic survey of digital twin-enabled AI simulation. By analyzing 22 primary studies, we identify technological trends and derive a reference framework to situate digital twins and AI components. Finally, we identify challenges and research opportunities for prospective researchers.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {401–412},
numpages = {12},
keywords = {AI, artificial intelligence, data science, deep neural networks, digital twins, lifecycle model, machine learning, neural networks, reinforcement learning, SLR, subsymbolic AI, survey, training},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inbook{10.1145/3712256.3726430,
author = {Vella Zarb, David and Parks, Geoff and Kipouros, Timoleon},
title = {Program Synthesis with LLM-Predicted Minimal Specialized Grammars},
year = {2025},
isbn = {9798400714658},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3712256.3726430},
abstract = {Grammatical evolution (GE) has proven effective at program synthesis. However, its performance is hindered by the exponential growth of search spaces as grammar complexity increases. Methods utilizing recent advances in large language models and genetic programming have outperformed GE on some benchmarks, affirming the need for scalable approaches. This paper addresses the scalability challenge by proposing an in-context learning method to automatically generate minimal specialized grammars (MSGs), which are problem-specific subsets of a larger grammar designed to reduce search space complexity. To the best of our knowledge, this represents the first use of in-context learning for program synthesis within GE. Our approach conditions a language model on examples of Backus-Naur Form grammars to generate MSGs tailored to individual synthesis tasks. We evaluate this framework on a benchmark suite widely used in GE research. Experimental results show our method almost always outperforms the baseline GE approach, improving both the number and frequency of problems solved while reducing computational cost as measured by fitness evaluations.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {1072–1080},
numpages = {9}
}

@inproceedings{10.1145/3715335.3735479,
author = {Behmanush, Hamayoon and Akhtari, Freshta and Nooripour, Roghieh and Weber, Ingmar and Cannanure, Vikram Kamath},
title = {Online Learning and GenAI: Supporting Women’s Aspirations Amid Socio-Political Instability in Afghanistan},
year = {2025},
isbn = {9798400714849},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3715335.3735479},
doi = {10.1145/3715335.3735479},
abstract = {Women in Afghanistan encounter substantial challenges in accessing education and achieving their career aspirations, mainly stemming from cultural norms and ongoing socio-political instability. Since 2021, women have been banned from employment opportunities and formal education beyond the sixth grade. As a result, many women have turned to digital platforms like online courses and utilizing AI tools as an alternative avenue to continue their learning. While these approaches have evidence for impact, their role and utility in unstable socio-political contexts remain unexplored. This mixed-methods study examined how online learning and Generative AI (GenAI) might support Afghanistani women learning introductory programming. Our findings reveal that while online learning was a viable option for participants, learners faced numerous challenges accessing and completing online courses. However, they benefited from GenAI through tutoring, assistance with debugging, and motivational support, which helped them develop programming skills. These skills expanded their career aspirations and improved employment prospects despite ongoing socio-political instability. Based on these insights, we offer initial recommendations for designing GenAI tools to further support women’s career aspirations.},
booktitle = {Proceedings of the 2025 ACM SIGCAS/SIGCHI Conference on Computing and Sustainable Societies},
pages = {401–417},
numpages = {17},
keywords = {Online Learning, GenAI for Education, LLMs, Programming Education, Women, Socio-Political Instability, Aspiration},
location = {
},
series = {COMPASS '25}
}

@inproceedings{10.1145/3550356.3561542,
author = {Cabot, Jordi and Delgado, David and Burgue\~{n}o, Lola},
title = {Combining OCL and natural language: a call for a community effort},
year = {2022},
isbn = {9781450394673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550356.3561542},
doi = {10.1145/3550356.3561542},
abstract = {The growing popularity and availability of pretrained natural language models opens the door to many interesting applications combining natural language (NL) with software artefacts. A couple of examples are the generation of code excerpts from NL instructions or the verbalization of programs in NL to facilitate their comprehension.Many of these language models have been trained with open source software datasets and therefore "understand" a variety of programming languages, but not OCL.We argue that OCL needs to jump into the machine learning bandwagon or it will risk losing its appeal as a constraint specification language. For that, the key first task is to create together an OCL corpus dataset amenable for natural language processing.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
pages = {908–912},
numpages = {5},
keywords = {OCL, community, corpus, dataset, natural language},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.1145/3744915.3748460,
author = {Zine, Nada and Quinton, Cl\'{e}ment and Rouvoy, Romain},
title = {LLM-based Co-Evolution of Configurable Software Systems},
year = {2025},
isbn = {9798400720246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3744915.3748460},
doi = {10.1145/3744915.3748460},
abstract = {Software Product Lines (SPLs) and s are de&nbsp;facto standards for managing variability in software systems. However, maintaining an up-to-date during software evolution is particularly challenging. Ensuring its consistency with the artifacts of an SPL requires co-evolving them alongside the developed system. When performed manually, this co-evolution process is tedious and error-prone, highlighting the need for automated support. Yet, little attention has been given to the automation of co-evolution between and source code. In this paper, we explore the potential of open-source s to fill this gap. Specifically, we investigate the extent to which s can support bidirectional co-evolution: from to source code—where modifications in the drive changes in the code—and from source code to —where updates in the code are reflected back into the. We evaluate our -based approach on a real-world configurable system. Our results demonstrate that co-evolution from source code to achieves F1 scores ranging from 0.93 to 1.0, while co-evolution from to source code achieves F1 scores between 0.41 and 0.99. These findings highlight the potential of s to support this co-evolution process, while also showing limitations and suggesting areas for improvement, particularly for the co-evolution from to code. Additionally, we conduct a comparative study across various s, revealing how choice affects co-evolution and, incidentally, how it affects model and code generation. Up to a certain size limit, larger s tend to produce more accurate and stable outputs than smaller ones, however, this influence is less pronounced in the code generation task. Overall, our work opens a new research avenue where s are leveraged for automating the co-evolution between configurable software systems and variability models.},
booktitle = {Proceedings of the 29th ACM International Systems and Software Product Line Conference - Volume A},
pages = {27–38},
numpages = {12},
keywords = {Software Product Lines, Large Language Models, Feature Models, Co-evolution},
location = {
},
series = {SPLC-A '25}
}

@inproceedings{10.1145/3689031.3696095,
author = {Liu, Hanzhi and Jiang, Yanyan and Xu, Chang},
title = {Understanding the Linux Kernel, Visually},
year = {2025},
isbn = {9798400711961},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689031.3696095},
doi = {10.1145/3689031.3696095},
abstract = {Understanding the Linux kernel is challenging due to its large and complex program state. While existing kernel debugging tools provide full access to kernel states at arbitrary levels of detail, developers often spend a significant amount of time sifting through redundant information to find what is truly useful. Additionally, the textual results provided by traditional debuggers are often insufficient for expressing high-dimensional information in a readable manner.This paper presents Visualinux, the first debugging framework that can simplify the program state of the Linux kernel to a level that can be visually understood with low programming complexity and effort. Visualinux includes a domain-specific language for specifying simplifications of a kernel object graph, an SQL-like domain-specific language for customizing the simplified object graph, and a panel-based interactive debugger. Evaluation results show that Visualinux can visualize various complex kernel components and efficiently assist developers in diagnosing sophisticated kernel bugs.},
booktitle = {Proceedings of the Twentieth European Conference on Computer Systems},
pages = {1044–1060},
numpages = {17},
keywords = {Debugging, Linux Kernel, Software Visualization},
location = {Rotterdam, Netherlands},
series = {EuroSys '25}
}

@inproceedings{10.1145/3639233.3639353,
author = {Maceda, Lany Laguna and Llovido, Jennifer Laraya and Artiaga, Miles Biago and Abisado, Mideth Balawiswis},
title = {Classifying Sentiments on Social Media Texts: A GPT-4 Preliminary Study},
year = {2024},
isbn = {9798400709227},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639233.3639353},
doi = {10.1145/3639233.3639353},
abstract = {In today's digital age, social media has become a hub for people to express their thoughts and feelings. Sentiment classification discerns public opinions and trends to understand their sentiments towards a certain topic. Often, achieving accurate sentiment classifications in large datasets necessitate the use of human-annotated training data which can be costly and time-consuming. Large Language Models (LLMs) like the Generative Pre-trained models by OpenAI have surged in popularity due to its capabilities in understanding the given tasks. In this preliminary study, we report the performance of the latest OpenAI GPT-4 using zero- and one-shot learning approaches on classifying sentiments when fed with social media dataset. Notably, the latter approach written in English which mimics the instructions designed for human annotators, achieved a substantial agreement (k = 0.77) with human annotations, displaying high accuracy, precision, and recall accordingly even without explicit training data. Meanwhile, the fine-tuned mBERT resulted to lower evaluation scores than the GPT-4. Our findings provide foundational insights into the strengths and limitations of GPT-4 for sentiment classification in a social media dataset, setting the groundwork for broad future research in this field.},
booktitle = {Proceedings of the 2023 7th International Conference on Natural Language Processing and Information Retrieval},
pages = {19–24},
numpages = {6},
keywords = {GPT-4, LLM Prompting, Sentiment Annotation, Social Media Data},
location = {Seoul, Republic of Korea},
series = {NLPIR '23}
}

@inproceedings{10.1145/3706598.3713913,
author = {Wang, Huichen Will and Birnbaum, Larry and Setlur, Vidya},
title = {Jupybara: Operationalizing a Design Space for Actionable Data Analysis and Storytelling with LLMs},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713913},
doi = {10.1145/3706598.3713913},
abstract = {Mining and conveying actionable insights from complex data is a key challenge of exploratory data analysis (EDA) and storytelling. To address this challenge, we present a design space for actionable EDA and storytelling. Synthesizing theory and expert interviews, we highlight how semantic precision, rhetorical persuasion, and pragmatic relevance underpin effective EDA and storytelling. We also show how this design space subsumes common challenges in actionable EDA and storytelling, such as identifying appropriate analytical strategies and leveraging relevant domain knowledge. Building on the potential of LLMs to generate coherent narratives with commonsense reasoning, we contribute Jupybara, an AI-enabled assistant for actionable EDA and storytelling implemented as a Jupyter Notebook extension. Jupybara employs two strategies—design-space-aware prompting and multi-agent architectures—to operationalize our design space. An expert evaluation confirms Jupybara’s usability, steerability, explainability, and reparability, as well as the effectiveness of our strategies in operationalizing the design space framework with LLMs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1005},
numpages = {24},
keywords = {Actionable Insights, Human-AI Collaboration, Multi-Agent System, Large Language Model, Exploratory Data Analysis, Data Storytelling, Data Science, Semantics, Rhetoric, Pragmatics.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3726302.3730326,
author = {Nguyen, Le and Jain, Preet and Panchal, Krutik and Alam, Md Tanvirul and Rastogi, Nidhi},
title = {Assessing Effective Token Length of Multimodal Models for Text-to-Image Retrieval},
year = {2025},
isbn = {9798400715921},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3726302.3730326},
doi = {10.1145/3726302.3730326},
abstract = {Multimodal embedding models have been widely adopted in text-to-image retrieval, enabling direct comparison between text and image modalities. However, how well they handle long text is poorly understood. For instance, Long-CLIP found that OpenAI's CLIP model, despite having a 77-token input limit, maintains optimal performance for only 20 tokens- its effective token length. In this paper, we build on the Long-CLIP study, and extend the analysis to other widely used multimodal models and find their effective token length. Unlike Long-CLIP, we examine how domain-specific language influences changes in effective token length and explore its implications on different domains. Based on our findings, we create a comprehensive reference of various models' effective token length across different domains; offering deeper insights into the true limitations of multimodal models used in text-to-image retrieval. Finally, we introduce a systematic benchmark that determines the effective token length of any multimodal model using a given dataset. Our results show that the effective token length is consistently lower than the input token limit for all models, meaning that these models cannot utilize all the text that can be given to them. We also find that the effective token length varies by dataset, with domain-specific language influencing how much text a model can use before retrieval performance plateaus. Our code is available for reproducibility at https://github.com/aiforsec/EffectiveTokenLength-MModels},
booktitle = {Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {3173–3182},
numpages = {10},
keywords = {benchmarking, clip, image retrieval, long text, multimodal, text-to-image},
location = {Padua, Italy},
series = {SIGIR '25}
}

@article{10.1145/3715317,
author = {Taleby Ahvanooey, Milad and Mazurczyk, Wojciech and Lee, Dongwon},
title = {Socioeconomic Threats of Deepfakes and the Role of Cyber-Wellness Education in Defense},
year = {2025},
issue_date = {September 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {68},
number = {9},
issn = {0001-0782},
url = {https://doi.org/10.1145/3715317},
doi = {10.1145/3715317},
abstract = {In recent years, society has witnessed accelerated advancement in generative artificial intelligence (GenAI) technologies, which may be viewed as a double-edged sword. On one hand, GenAI tools can be used to create synthetic content legitimately. For example, advertising agencies may, with permission, generate celebrities’ images or videos using GenAI tools without putting them in front of cameras and thus reducing the overall cost of media construction. On the other hand, scammers may utilize GenAI tools to craft or edit artificial content (for example, texts, images, videos, or audio), so-called deepfakes, to mislead or deceive netizens with robocalls or voice cloning phishing, potentially causing detrimental consequences for society. This article briefly debates emerging socioeconomic threats of deepfakes in today’s society and how cyber-wellness (or digital media literacy) education can help netizens mitigate their risks.To the mitigate the risks of deepfakes, enhanced cyber-wellness programs are needed that empower both producers and consumers of generative AI–based content.},
journal = {Commun. ACM},
month = aug,
pages = {70–79},
numpages = {10}
}

@article{10.1145/3744903,
author = {Abdulhamed, Ahmed and Ranjan, Prabhat and Xiong, Shengwu},
title = {Entity Naming in NLP: Hybrid Approach GPT Transformer and Multi-level RNN},
year = {2025},
issue_date = {July 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {7},
issn = {2375-4699},
url = {https://doi.org/10.1145/3744903},
doi = {10.1145/3744903},
abstract = {This research addresses the limitations of existing entity-naming algorithms in natural language processing when the algorithm faces the complexities of polysemy and intricate sentence structures. We propose a novel Transformer-multi-level fusion recurrent Neural Network (T-MFRNN) model that integrates transformer-based layers for contextual understanding with a multi-level fusion recurrent neural network to capture temporal dependencies. Through rigorous experimentation on prominent NLP models like BERT, GPT2, ELECTRA, and XNet, the proposed T-MFRNN demonstrated a significant performance enhancement. Compared to existing methods, such as the boundary assembly model (BAM), the T-MFRNN exhibits a marked improvement of up to 18.66\% in the F1-score, highlighting its superior ability to accurately label entities in complex biomedical texts. The T-MFRNN model’s outstanding performance underscores its potential as a robust solution for biomedical entity naming applications.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = jul,
articleno = {65},
numpages = {26},
keywords = {Natural language processing, entity naming recognition, transformer models, multi-level fusion RNNs, polysemy, NLP applications}
}

@article{10.1145/3732790,
author = {Taipalus, Toni and Grahn, Hilkka and Ritonummi, Saima and Siitonen, Valtteri and Vartiainen, Tero and Zhidkikh, Denis},
title = {Novice Perceptions on Effective Elements of PostgreSQL Error Messages},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {2},
url = {https://doi.org/10.1145/3732790},
doi = {10.1145/3732790},
abstract = {SQL compiler error messages are the primary way users receive feedback when they encounter syntax errors or other issues in their SQL queries. Effective error messages can enhance the user experience by providing clear, informative, and actionable feedback. Despite the age of SQL compilers, it still remains largely unclear what contributes to an effective SQL error message. With 2,052 answers yielded by 165 participants for qualitative analysis, this study is an attempt to understand what novices perceive as effective elements in SQL error messages. The results uniformly indicate that communicating the precise error position, articulating what is wrong in the query with clear natural language, and showing hints on how to fix the error are perceived as the most effective elements for error recovery. These insights have potential to be utilized in providing more effective error messages in SQL compilers and SQL learning environments, and for guiding generative AI for enhanced error messages in order to minimize frustration caused by cryptic error messages, improving learning and adoption, and reducing debugging time.},
journal = {ACM Trans. Comput. Educ.},
month = jun,
articleno = {24},
numpages = {19},
keywords = {SQL, error, error message, effective, relational database, novice, software development, PostgreSQL}
}

@inproceedings{10.1145/3748355.3748369,
author = {Gao, Xiangyu and Zhu, Xiangfeng and Shobhana, Bhavana Vannarth and Yang, Yiwei and Krishnamurthy, Arvind and Mahajan, Ratul},
title = {Offloading the Tedious Task of Writing eBPF Programs},
year = {2025},
isbn = {9798400720840},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3748355.3748369},
doi = {10.1145/3748355.3748369},
abstract = {eBPF offers a lightweight method to extend the Linux kernel without modifying the source code in existing modules. However, writing correct and efficient eBPF programs is hard due to its unique verifier constraints and cumbersome debugging processes specific to the kernel execution environment. To tackle such an obstacle, we present a system, SimpleBPF, aiming at offloading the tedious eBPF development task. Developers only need to express their intent in a high-level domain-specific language, while the underlying eBPF code generation is handled automatically. SimpleBPF integrates four key components: a concise DSL, an LLM-based generator, a semantic checker, and an LLM-based optimizer. We use few-shot prompting to build both the code generator and optimizer in SimpleBPF, and evaluate the system on programs written in a representative DSL. The preliminary evaluation result shows that SimpleBPF can generate valid eBPF programs that pass the kernel verifier and exhibit competitive runtime performance. We also outline future directions based on current findings.},
booktitle = {Proceedings of the 3rd Workshop on EBPF and Kernel Extensions},
pages = {63–69},
numpages = {7},
keywords = {Code Generation, LLM Inference, Prompt Engineering, eBPF},
location = {Coimbra, Portugal},
series = {eBPF '25}
}

@inproceedings{10.1145/3643661.3643953,
author = {Alshahwan, Nadia and Harman, Mark and Harper, Inna and Marginean, Alexandru and Sengupta, Shubho and Wang, Eddy},
title = {Assured Offline LLM-Based Software Engineering},
year = {2024},
isbn = {9798400705649},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643661.3643953},
doi = {10.1145/3643661.3643953},
abstract = {In this paper we address the following question: How can we use Large Language Models (LLMs) to improve code independently of a human, while ensuring that the improved code(1) does not regress the properties of the original code ?(2) improves the original in a verifiable and measurable way ?To address this question, we advocate Assured LLM-Based Software Engineering; a generate-and-test approach, inspired by Genetic Improvement. Assured LLMSE applies a series of semantic filters that discard code that fails to meet these twin guarantees. This overcomes the potential problem of LLM's propensity to hallucinate. It allows us to generate code using LLMs, independently of any human. The human plays the role only of final code reviewer, as they would do with code generated by other human engineers.This paper is an outline of the content of the keynote by Mark Harman at the International Workshop on Interpretability, Robustness, and Benchmarking in Neural Software Engineering, Monday 15th April 2024, Lisbon, Portugal.},
booktitle = {Proceedings of the ACM/IEEE 2nd International Workshop on Interpretability, Robustness, and Benchmarking in Neural Software Engineering},
pages = {7–12},
numpages = {6},
keywords = {large language models (LLMs), genetic improvement (GI), search based software engineering (SBSE), llama, codellama, automated code generation},
location = {Lisbon, Portugal},
series = {InteNSE '24}
}

@inproceedings{10.1145/3677389.3702523,
author = {Datta, Priyangshu and Datta, Suchana and Roy, Dwaipayan},
title = {RAGing Against the Literature: LLM-Powered Dataset Mention Extraction},
year = {2025},
isbn = {9798400710933},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677389.3702523},
doi = {10.1145/3677389.3702523},
abstract = {Dataset Mention Extraction (DME) is a critical task in the field of scientific information extraction, aiming to identify references to datasets within research papers. In this paper, we explore two advanced methods for DME from research papers, utilizing the capabilities of Large Language Models (LLMs). The first method employs a language model with a prompt-based framework to extract dataset names from text chunks, utilizing patterns of dataset mentions as guidance. The second method integrates the Retrieval-Augmented Generation (RAG) framework, which enhances dataset extraction through a combination of keyword-based filtering, semantic retrieval, and iterative refinement. We observe that both of the proposed methods achieve more than a 25\% improvement in recall compared to the baselines. Further, the RAG-based model achieves an extensive 26\% improvement over the baselines. We also propose exData, a web-based tool for extracting dataset name mentions from a given article.},
booktitle = {Proceedings of the 24th ACM/IEEE Joint Conference on Digital Libraries},
articleno = {29},
numpages = {12},
keywords = {bibliometrics, dataset mention extraction, LLM, RAG},
location = {Hong Kong, China},
series = {JCDL '24}
}

@article{10.1145/3734523,
author = {Reddy, E Bhawani Eswar and Bhattacharyya, Sutirtha and Sarmah, Ankur and Nongpoh, Fedrick and Maddala, Karthik and Karfa, Chandan},
title = {LHS: LLM Assisted Efficient High-level Synthesis of Deep Learning Tasks},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1084-4309},
url = {https://doi.org/10.1145/3734523},
doi = {10.1145/3734523},
abstract = {Deep learning tasks, especially those involving complex convolution neural networks (CNNs), are computationally intensive and pose significant challenges when implemented on hardware. Accelerating these tasks is critical for improving performance. High-level Synthesis (HLS) has the potential to automate the efficient hardware accelerator designs directly from high-level C/C++ specification of trained machine learning (ML) models. Traditional HLS tools cannot synthesize certain high-level constructs, which require manual intervention. Many source code optimizations and the selection of pragmas for HLS optimizations are crucial for generating efficient hardware accelerators with HLS. However, both of these tasks are mostly manual efforts. Recently, Large Language Models (LLMs) have shown remarkable capabilities in various generative tasks. In this work, we explore the application of LLMs to remove these manual efforts in adapting HLS for ML accelerator designs. Our framework called LLM-assisted HLS, i.e., LHS, uses LLMs to automate the resolution of synthesis issues, ensuring compatibility with HLS tools. Furthermore, our framework automates the source code modification and optimization selection through pragma insertion steps, which are crucial for optimizing the synthesized design. Our experimental results with LHS demonstrate a significant improvement in latency for deep learning tasks with underlying complex CNN models without much area overhead. Our LHS allows us to achieve up to 2690 \texttimes{} latency improvement. Promisingly, LHS performs better than the state-of-the-art ML accelerator design tool hls4ml in 4 out of 6 cases in the context of latency improvement at the expense of area overhead (i.e., performance to hardware gain). This work highlights the potential of LLMs to assist and accelerate the HLS process, thereby creating more efficient hardware implementation for deep learning models.},
note = {Just Accepted},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = may,
keywords = {LLM, High-level synthesis, CNN}
}

@inproceedings{10.1145/3700523.3700536,
author = {Ayli, Maroun and Bakouny, Youssef and Jalloul, Nader and Kilany, Rima},
title = {Enhancing the Resiliency of Automated Web Tests with Natural Language},
year = {2024},
isbn = {9798400717840},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700523.3700536},
doi = {10.1145/3700523.3700536},
abstract = {Web application testing has traditionally been the domain of specialized software professionals, with a significant portion still relying on manual execution by individuals with limited programming expertise. This research introduces a novel proof-of-concept tool that democratizes the creation of automated web tests through a restricted natural language interface. Leveraging the GPT-4 language model and introducing “smart web element locators, our tool enables both technical and non-technical professionals to design comprehensive test cases without explicit programming knowledge. The tool comprises three key components: (1) a pseudo-language definition mapping into Selenium actions, (2) a new concept for resilient locators, and (3) a semantic understanding system translating natural language into software assertions. This approach enhances test production speed by offering a no-code interface and improves test resiliency through non-fragile locators. While introducing a slight increase in execution time (approximately 15\% on average), the benefits in creation speed and script resilience far outweigh this trade-off. Empirical evaluation demonstrates the tool’s effectiveness in real-world scenarios, enabling non-technical team members to contribute meaningfully to the testing process. Results show a significant reduction in test suite creation and maintenance time, as well as improved test coverage due to increased participation of domain experts. This research contributes to software testing by combining natural language processing, smart locators, and automated test generation. By lowering the barrier to entry for test automation, our tool has the potential to revolutionize web application testing practices, leading to more efficient, comprehensive, and reliable testing processes across the software development industry.},
booktitle = {Proceedings of the 2024 4th International Conference on Artificial Intelligence, Automation and Algorithms},
pages = {63–69},
numpages = {7},
keywords = {Web automation testing, Restricted natural language, Test case generation, Web application testing, Natural language processing in testing, Automated test scripts, Behavior-driven development, Web UI testing, Test automation frameworks, Domain-specific language for testing},
location = {
},
series = {AI2A '24}
}

@inproceedings{10.1145/3635059.3635062,
author = {Giarelis, Nikolaos and Mastrokostas, Charalampos and Siachos, Ilias and Karacapilidis, Nikos},
title = {A Review of Greek NLP Technologies for Chatbot Development},
year = {2024},
isbn = {9798400716263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3635059.3635062},
doi = {10.1145/3635059.3635062},
abstract = {The advent of Generative AI has certainly boosted the interest in developing innovative chatbot applications. Despite a vast amount of machine learning (ML) and natural language processing (NLP) research and English language resources that greatly improve chatbot technology, the corresponding research and resources for the Greek language are limited. The contribution of this paper is twofold: (i) it reports on the state-of-the-art research in Greek NLP, as far as language resources, embeddings-based techniques, deep learning models, and existing chatbot applications are concerned; (ii) it offers a set of insights on current NLP models and chatbot implementation methodologies, and outlines a set of pending issues and future research directions.},
booktitle = {Proceedings of the 27th Pan-Hellenic Conference on Progress in Computing and Informatics},
pages = {15–20},
numpages = {6},
keywords = {Deep Learning, Greek Language, Large Language Models, Review, Text Classification, Text Summarization, Word Embeddings},
location = {Lamia, Greece},
series = {PCI '23}
}

@article{10.1145/3746060,
author = {Berger, Thorsten and Mahmood, Wardah and Abu Zahra, Ramzi and Vassilevski, Igor and Burger, Andreas and Ji, Wenbin and Antkiewicz, Michal and Czarnecki, Krzysztof},
title = {Cost and Benefit of Tracing Features with Embedded Annotations},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3746060},
doi = {10.1145/3746060},
abstract = {Features are commonly used to describe the functional and non-functional characteristics of software. Especially agile development methods, such as SCRUM, FDD or XP, use features to plan and manage software development. Features are often the main units of software reuse, communication, and configuration, abstracting over code details. Especially in the age of generative AI, where feature requirements are specified as prompts and substantial code is cloned, codebases are becoming increasingly complex and redundant. This requires raising the level of abstraction at which we manage and evolve software systems. However, effectively using features requires knowing their precise locations within codebases, which is especially challenging when they are scattered across the codebase. Once implemented, the knowledge about a feature’s location quickly deteriorates when the software evolves or development teams change, requiring expensive recovery of features. This decades-old problem is known as the feature-location or concept assignment problem in software engineering, which researchers have—unsuccessfully over decades—tried to address with automated feature-location recovery techniques.The problem lies in the common belief that recording and maintaining feature locations during development is laborious and error-prone. In this study, we argue to the contrary. We hypothesize that such information can be effectively embedded into codebases, and that the arising costs will be amortized by the benefits of this information. We validated this hypothesis in a simulation study with three subjects systems: a smaller open-source system, a large commercial firmware system, and an open-source mobile app. We designed a lightweight code annotation technique and simulated its use as if annotations had been added, maintained, and exploited during the original development. We identified evolution patterns and measured the cost and benefit of these annotations. Our results show that not only the cost of adding annotations, but also that of maintaining them is negligible compared to the development and maintenance costs of the actual code. Embedding the annotations into the codebase significantly reduced their maintenance effort, because they naturally co-evolved with the code. The annotations provided a benefit for feature-related maintenance tasks, such as feature cloning or merging the clones into an integrated codebase, that exceeded the costs of using them.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = aug,
keywords = {features, feature location, software evolution, traceability, annotation system, simulation study}
}

@inproceedings{10.1145/3726302.3730117,
author = {Hadad, Guy and Roitman, Haggai and Eshel, Yotam and Shapira, Bracha and Rokach, Lior},
title = {X-Cross: Dynamic Integration of Language Models for Cross-Domain Sequential Recommendation},
year = {2025},
isbn = {9798400715921},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3726302.3730117},
doi = {10.1145/3726302.3730117},
abstract = {As new products are emerging daily, recommendation systems are required to quickly adapt to possible new domains without needing extensive retraining. This work presents ''X-Cross'' -- a novel cross-domain sequential-recommendation model that recommends products in new domains by integrating several domain-specific language models; each model is fine-tuned with low-rank adapters (LoRA). Given a recommendation prompt, operating layer by layer, X-Cross dynamically refines the representation of each source language model by integrating knowledge from all other models. These refined representations are propagated from one layer to the next, leveraging the activations from each domain adapter to ensure domain-specific nuances are preserved while enabling adaptability across domains. Using Amazon datasets for sequential recommendation, X-Cross achieves performance comparable to a model that is fine-tuned with LoRA, while using only 25\% of the additional parameters. In cross-domain tasks, such as adapting from Toys domain to Tools, Electronics or Sports, X-Cross demonstrates robust performance, while requiring about 50\%-75\% less fine-tuning data than LoRA to make fine-tuning effective. Furthermore, X-Cross achieves significant improvement in accuracy over alternative cross-domain baselines. Overall, X-Cross enables scalable and adaptive cross-domain recommendations, reducing computational overhead and providing an efficient solution for data-constrained environments.},
booktitle = {Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1497–1507},
numpages = {11},
keywords = {cross-domain recommendation, dynamic integration, language models, lora, natural language processing, parameter and data efficiency},
location = {Padua, Italy},
series = {SIGIR '25}
}

@inproceedings{10.1145/3711896.3736838,
author = {Tang, Ziyi and Chen, Zechuan and Yang, Jiarui and Mai, Jiayao and Zheng, Yongsen and Wang, Keze and Chen, Jinrui and Lin, Liang},
title = {AlphaAgent: LLM-Driven Alpha Mining with Regularized Exploration to Counteract Alpha Decay},
year = {2025},
isbn = {9798400714542},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711896.3736838},
doi = {10.1145/3711896.3736838},
abstract = {Alpha mining, a critical component in quantitative investment, focuses on discovering predictive signals for future asset returns in increasingly complex financial markets. However, the pervasive issue of alpha decay-where factors lose their predictive power over time-poses a significant challenge for alpha mining. Traditional methods such as genetic programming are prone to rapid alpha decay, primarily due to their susceptibility to overfitting. At the same time, approaches driven by Large Language Models (LLMs), despite their promise, often fail to impose regularization against factor homogenization-resulting in crowded signals and accelerated decay. To address this challenge, we propose AlphaAgent, an autonomous framework that effectively integrates LLM-driven agents with ad hoc regularization for mining decay-resistant alpha factors. AlphaAgent employs three key mechanisms: (i) originality enforcement through a similarity measure based on abstract syntax trees (ASTs) against existing alphas(ii) hypothesis-factor alignment via LLM-evaluated semantic consistency between market hypotheses and generated factors, and (iii) complexity control via AST-based structural constraints, preventing over-engineered constructions that are prone to overfitting. These mechanisms collectively guide the alpha generation process to balance originality, financial rationale, and adaptability to evolving market conditions, mitigating the risk of alpha decay. Extensive evaluations show that AlphaAgent outperforms traditional and LLM-based methods in mitigating alpha decay across bull and bear markets, consistently delivering significant alpha in Chinese CSI 500 and U.S. S&amp;P 500 markets over the past four years. Notably, AlphaAgent showcases remarkable resistance to alpha decay, elevating the potential for yielding powerful factors.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2},
pages = {2813–2822},
numpages = {10},
keywords = {alpha mining, autonomous agents, large language models, quantitative investment},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@article{10.1145/3731559,
author = {Pezz\`{e}, Mauro and Abrah\~{a}o, Silvia and Penzenstadler, Birgit and Poshyvanyk, Denys and Roychoudhury, Abhik and Yue, Tao},
title = {A 2030 Roadmap for Software Engineering},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3731559},
doi = {10.1145/3731559},
abstract = {The landscape of software engineering has dramatically changed in recent years. The impressive advances of artificial intelligence are just the latest and most disruptive innovation that has remarkably changed the software engineering research and practice. This special issue shares a roadmap to guide the software engineering community in this confused era. This roadmap is the outcome of a 2-day intensive discussion at the 2030 Software Engineering workshop. The roadmap spotlights and discusses seven main landmarks in the new software engineering landscape: artificial intelligence for software engineering, human aspects of software engineering, software security, verification and validation, sustainable software engineering, automatic programming, and quantum software engineering. This editorial summarizes the core aspects discussed in the 37 papers that comprise the seven sections of the special issue and guides the interested readers throughout the issue. This roadmap is a living body that we will refine with follow-up workshops that will update the roadmap for a series of forthcoming ACM TOSEM special issues.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {118},
numpages = {55},
keywords = {A roadmap for software engineering, AI and software engineering, Human factor in software engineering, Automatic Programming, Sustainable software engineering, Quantum software engineering, AI for verification and validation, security and software engineering, generative AI for software engineering, Large language models for software engineering}
}

@inproceedings{10.1145/3532213.3532254,
author = {Zhang, Xiangliang and Jia, Yangli and Zhang, Zhenling and Kang, Qi and Zhang, Yongchen and Jia, Hongling},
title = {Improving End-to-End Biomedical Question Answering System},
year = {2022},
isbn = {9781450396110},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3532213.3532254},
doi = {10.1145/3532213.3532254},
abstract = {Biomedical question answering refers to extracting an answer based on given questions and related documents. Existing biomedical question answering research either focuses on a specific stage, such as machine reading comprehension, or uses traditional rule-based methods and ontology with complex construction processes. In this paper, we demonstrate the application of simple but powerful neural-based approaches in improving the end-to-end biomedical question answering system. We employ the BM25-based documents retriever, BERT-based neural ranker, and an answer extraction stage using the BioBERT pre-trained language model. In view of the lack of sufficient training data in the biomedical domain, domain adaptation and data augmentation are adopted to address the question answering task, so as to further reinforce the system performance. Based on our self-built standard large-volume retrieve corpus and neural ranker corpus, we get competitive results on BioASQ8b.},
booktitle = {Proceedings of the 8th International Conference on Computing and Artificial Intelligence},
pages = {274–279},
numpages = {6},
keywords = {Biomedical question answering, Data augmentation, Document re-ranking},
location = {Tianjin, China},
series = {ICCAI '22}
}

@inproceedings{10.1145/3706598.3713932,
author = {Kretzer, Felix and Kolthoff, Kristian and Bartelt, Christian and Ponzetto, Simone Paolo and Maedche, Alexander},
title = {Closing the Loop between User Stories and GUI Prototypes: An LLM-Based Assistant for Cross-Functional Integration in Software Development},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713932},
doi = {10.1145/3706598.3713932},
abstract = {Graphical user interfaces (GUIs) are at the heart of almost every software we encounter. GUIs are often created through a collaborative effort involving UX designers, product owners, and software developers, constantly facing changing requirements. Historically, problems in GUI development include a fragmented, poorly integrated tool landscape and high synchronization efforts between stakeholders. Recent approaches suggest using large language models (LLMs) to recognize requirements fulfillment in GUIs and automatically propose new GUI components. Based on ten interviews with practitioners, this paper proposes an LLM-based assistant as a Figma plug-in that bridges the gap between user stories and GUI prototyping. We evaluated the prototype with 40 users and 40 crowd-workers, showing that the effectiveness of GUI creation is improved by using LLMs to detect requirements’ completion and generate new GUI components. We derive design rationales to support cross-functional integration in software development, ensuring that our plug-in integrates well into established processes.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {879},
numpages = {19},
keywords = {GUI Prototypes; User Stories; Requirements; Assistance},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3696593.3696605,
author = {Tong, Chao and Pournik, Omid and N.Arvanitis, Theodoros and Yilmaz, Gokhan and Caballero Garcia, Jessica and Largo Arana, Araitz},
title = {Leveraging Drools Workbench for Effective Clinical Decision Support System Design},
year = {2025},
isbn = {9798400707292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696593.3696605},
doi = {10.1145/3696593.3696605},
abstract = {This paper explores the conception, development, and real-world evaluation of a Clinical Decision Support System (CDSS) aimed at enhancing health-care decision-making. Utilizing the Drools Workbench for rule-based logic, a visual clinical flowchart, and seamless integration with Fast Healthcare Interoperability Resources (FHIR) input, the CDSS offers a robust solution for dynamic and evidence-based decision support. In this paper, we present a generalized method for creating complex CDSS using Drools Workbench. Our approach begins with original clinical guidelines, which are converted into clinical flowcharts and computer interpretable guidelines. We then perform a guideline reconciliation process on these computer interpretable guidelines to accommodate comorbidity requirements. Clinical concepts extracted from the reconciled guidelines are translated into Domain-Specific Language (DSL) files in Drools Workbench. Based on these DSL files and computer interpretable guidelines, we create a set of business processes that form a comprehensive CDSS for individual diseases. By running multiple CDSS within a single system, we develop a CDSS for comorbidities. Functional testing is conducted by both technical personnel and healthcare professionals to ensure that the output aligns with real-world practices. The innovation of this paper lies in presenting a more general method for creating CDSS with minimal programmer assistance, addressing not just a single disease but a range of diseases, with consideration of their comorbidities.},
booktitle = {Proceedings of the 11th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-Exclusion},
pages = {277–281},
numpages = {5},
keywords = {CDSS, Drools workbench, EHR, rules-based},
location = {
},
series = {DSAI '24}
}

@inproceedings{10.1145/3594806.3596542,
author = {Othman, Achraf and Dhouib, Amira and Nasser Al Jabor, Aljazi},
title = {Fostering websites accessibility: A case study on the use of the Large Language Models ChatGPT for automatic remediation},
year = {2023},
isbn = {9798400700699},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594806.3596542},
doi = {10.1145/3594806.3596542},
abstract = {The use of automated accessibility testing tools remains a common practice for evaluating web accessibility. However, the results obtained from these tools may not always provide a comprehensive and complete view of a site's accessibility status. The main purpose of this study is to improve web accessibility by automatically remediating non-accessible ones using Large Language Models (LLM), particularly ChatGPT. The effectiveness of the used model in detecting and remediating accessibility issues to ensure compliance with the Web Content Accessibility Guidelines (WCAG 2.1) is also discussed. By using ChatGPT as a remediation tool, this study investigates the potential of LLM in improving web accessibility. In the case study, two websites that did not adhere to the WCAG 2.1 guidelines were selected as the primary experimental subjects for the study. These websites were assessed using the web accessibility evaluation tool, WAVE, to detect accessibility issues. The identified issues served then as the basis for remediation using ChatGPT. The effectiveness of the used advanced language model as a web accessibility remediation tool was evaluated by comparing its findings with those obtained from manual accessibility testing. The results of this comparison have significant implications for stakeholders involved in achieving WCAG compliance and contribute to the development of more accessible online platforms for individuals with disabilities.},
booktitle = {Proceedings of the 16th International Conference on PErvasive Technologies Related to Assistive Environments},
pages = {707–713},
numpages = {7},
location = {Corfu, Greece},
series = {PETRA '23}
}

@inproceedings{10.1145/3613904.3642319,
author = {Barnaby, Celeste and Chen, Qiaochu and Wang, Chenglong and Dillig, Isil},
title = {PhotoScout: Synthesis-Powered Multi-Modal Image Search},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642319},
doi = {10.1145/3613904.3642319},
abstract = {Due to the availability of increasingly large amounts of visual data, there is a growing need for tools that can help users find relevant images. While existing tools can perform image retrieval based on similarity or metadata, they fall short in scenarios that necessitate semantic reasoning about the content of the image. This paper explores a new multi-modal image search approach that allows users to conveniently specify and perform semantic image search tasks. With our tool, PhotoScout, the user interactively provides natural language descriptions, positive and negative examples, and object tags to specify their search tasks. Under the hood, PhotoScout is powered by a program synthesis engine that generates visual queries in a domain-specific language and executes the synthesized program to retrieve the desired images. In a study with 25 participants, we observed that PhotoScout allows users to perform image retrieval tasks more accurately and with less manual effort.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {896},
numpages = {15},
keywords = {Interface design, multi-modal interfaces, program synthesis},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3662739.3664740,
author = {Zhan, Liuchun and Huang, Changjiang},
title = {Research on Computer Intelligent ChatGPT Natural Language Processing System Based on Scientific Knowledge Graph},
year = {2024},
isbn = {9798400718144},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3662739.3664740},
doi = {10.1145/3662739.3664740},
abstract = {A synonym mining method is proposed by combining the character vector graph and noise robust learning method. The model uses paired word vectors pre-trained by ChatGPT to enhance entity semantic representation. Classify marks with noise. Then the cross optimal processing is carried out to identify the true and false marks. The two-layer construction system of knowledge extraction and knowledge fusion is constructed to realize the independent construction and answer of software engineering questions. The system effectively improves the efficiency of software project understanding and software reuse.},
booktitle = {Proceedings of the 2024 International Conference on Machine Intelligence and Digital Applications},
pages = {47–51},
numpages = {5},
keywords = {ChatGPT, Software knowledge extraction, Natural language processing system, Software knowledge graph},
location = {Ningbo, China},
series = {MIDA '24}
}

@article{10.1145/3712006,
author = {Autili, Marco and De Sanctis, Martina and Inverardi, Paola and Pelliccione, Patrizio},
title = {Engineering Digital Systems for Humanity: A Research Roadmap},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3712006},
doi = {10.1145/3712006},
abstract = {As testified by new regulations like the European AI Act, worries about the human and societal impact of (autonomous) software technologies are becoming of public concern. Human, societal, and environmental values, alongside traditional software quality, are increasingly recognized as essential for sustainability and long-term well-being. Traditionally, systems are engineered taking into account business goals and technology drivers. Considering the growing awareness in the community, in this article, we argue that engineering of systems should also consider human, societal, and environmental drivers. Then, we identify the macro and technological challenges by focusing on humans and their role while co-existing with digital systems. The first challenge considers humans in a proactive role when interacting with digital systems, i.e., taking initiative in making things happen instead of reacting to events. The second concerns humans having a reactive role in interacting with digital systems, i.e., humans interacting with digital systems as a reaction to events. The third challenge focuses on humans with a passive role, i.e., they experience, enjoy or even suffer the decisions and/or actions of digital systems. The fourth challenge concerns the duality of trust and trustworthiness, with humans playing any role. Building on the new human, societal, and environmental drivers and the macro and technological challenges, we identify a research roadmap of digital systems for humanity. The research roadmap is concretized in a number of research directions organized into four groups: development process, requirements engineering, software architecture and design, and verification and validation.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {130},
numpages = {33},
keywords = {Human values, Societal values, Environmental values, Research directions, Research roadmap, Software engineering}
}

@article{10.1145/3746226,
author = {Chafik, Salmane and Ezzini, Saad and Berrada, Ismail},
title = {Towards Automating Domain-Specific Data Generation for Text-to-SQL: A Comprehensive Approach},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3746226},
doi = {10.1145/3746226},
abstract = {As software systems increasingly rely on natural language interfaces, ensuring the reliability of these systems is crucial. One critical component is the ability to accurately translate natural language queries into corresponding SQL queries, a field known as Text-to-SQL. However, the scarcity of high-quality, large-scale, and domain-specific Text-to-SQL datasets hinders the development of reliable and robust models. To tackle these challenges, we propose SelectCraft, a novel automatic generation approach designed to create realistic Text-to-SQL datasets tailored to specific domains. Our method leverages existing databases and their structures to generate complex text-SQL pairs that mirror real-world usage scenarios. As a proof of concept, we have successfully generated a substantial financial Text-to-SQL dataset, denominated as BanQies, encompassing over 1 million samples utilizing our proposed approach. Moreover, we introduce BanQL, a new large language model (LLM) based on StarCoder2, a state-of-the-art code-based LLM, and fine-tuned on our newly created dataset. We evaluate BanQL performance against several state-of-the-art models, demonstrating significant enhancements in accuracy and generalizability, highlighting the advantages of incorporating domain-specific data in Text-to-SQL tasks. We firmly believe that our contributions have the potential to improve the overall reliability of Text-to-SQL software systems.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jun,
keywords = {Text-to-SQL, SQL-to-Text, Code Generation, Data Generation, Synthetic Data}
}

@inproceedings{10.1145/3605098.3635889,
author = {Arrieta, Kutz and Fillottrani, Pablo R and Keet, C. Maria},
title = {CoSMo: A multilingual modular language for Content Selection Modelling},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605098.3635889},
doi = {10.1145/3605098.3635889},
abstract = {Representing snippets of information abstractly is a task that needs to be performed for various purposes, such as database view specification and the first stage in the natural language generation pipeline for generative AI from structured input, i.e., the content selection stage to determine what needs to be verbalised. For the Abstract Wikipedia project, requirements analysis revealed that such an abstract representation requires multilingual modelling, content selection covering declarative content and functions, and both classes and instances. There is no modelling language that meets either of the three features, let alone a combination. Following a rigorous language design process inclusive of broad stakeholder consultation, we created CoSMo, a novel Content Selection Modeling language that meets these and other requirements so that it may be useful both in Abstract Wikipedia as well as other contexts. We describe the design process, rationale and choices, the specification, and preliminary evaluation of the language.},
booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
pages = {706–713},
numpages = {8},
keywords = {modeling language, query language, wikidata, multilingualism},
location = {Avila, Spain},
series = {SAC '24}
}

@inproceedings{10.1145/3613904.3642016,
author = {Arawjo, Ian and Swoopes, Chelse and Vaithilingam, Priyan and Wattenberg, Martin and Glassman, Elena L.},
title = {ChainForge: A Visual Toolkit for Prompt Engineering and LLM Hypothesis Testing},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642016},
doi = {10.1145/3613904.3642016},
abstract = {Evaluating outputs of large language models (LLMs) is challenging, requiring making—and making sense of—many responses. Yet tools that go beyond basic prompting tend to require knowledge of programming APIs, focus on narrow domains, or are closed-source. We present ChainForge, an open-source visual toolkit for prompt engineering and on-demand hypothesis testing of text generation LLMs. ChainForge provides a graphical interface for comparison of responses across models and prompt variations. Our system was designed to support three tasks: model selection, prompt template design, and hypothesis testing (e.g., auditing). We released ChainForge early in its development and iterated on its design with academics and online users. Through in-lab and interview studies, we find that a range of people could use ChainForge to investigate hypotheses that matter to them, including in real-world settings. We identify three modes of prompt engineering and LLM hypothesis testing: opportunistic exploration, limited evaluation, and iterative refinement.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {304},
numpages = {18},
keywords = {auditing, language models, prompt engineering, toolkits, visual programming environments},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@article{10.1145/3709155,
author = {Villena, Fabi\'{a}n and Quiroga, Tamara and Dunstan, Jocelyn},
title = {Clinical Analogy Resolution Performance for Foundation Language Models},
year = {2025},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {2},
url = {https://doi.org/10.1145/3709155},
doi = {10.1145/3709155},
abstract = {Using extensive data sources to create foundation language models has revolutionized the performance of deep learning-based architectures. This remarkable improvement has led to state-of-the-art results for various downstream NLP tasks, including clinical tasks. However, more research is needed to measure model performance intrinsically, especially in the clinical domain. We revisit the use of analogy questions as an effective method to measure the intrinsic performance of language models for the clinical domain in English. We tested multiple Transformer-based language models s over analogy questions constructed from the Unified Medical Language System (UMLS), a massive knowledge graph of clinical concepts. Our results show that large language models are significantly more performant for analogy resolution than small language models. Similarly, domain-specific language models perform better than general domain language models. We also found a correlation between intrinsic and extrinsic performance, validated through PubMedQA extrinsic task. Creating clinical-specific and language-specific language models is essential for advancing biomedical and clinical NLP and will ensure a valid application in clinical practice. Finally, given that our proposed intrinsic test is based on a term graph available in multiple languages, the dataset can be built to measure the performance of models in languages other than English.},
journal = {ACM Trans. Comput. Healthcare},
month = apr,
articleno = {25},
numpages = {12},
keywords = {Foundation Models, Clinical NLP, Intrinsic Tests}
}

@inproceedings{10.1145/3650212.3680314,
author = {Nguyen, Thanh-Dat and Do-Viet, Tung and Nguyen-Duy, Hung and Luu, Tuan-Hai and Le, Hung and Le, Bach and Thongtanunam, Patanamon},
title = {VRDSynth: Synthesizing Programs for Multilingual Visually Rich Document Information Extraction},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680314},
doi = {10.1145/3650212.3680314},
abstract = {Businesses often need to query visually rich documents (VRDs), e.g., purchase receipts, medical records, and insurance forms, among many other forms from multiple vendors, to make informed decisions. As such, several techniques have been proposed to automatically extract independent entities of interest from VRDs such as extracting price tags from purchase receipts, etc. However, for extracting semantically linked entities, such as finding corresponding price tags for each item, these techniques either have limited capability in handling new layouts, e.g., template-based approaches, or require extensive amounts of pre-training data and do not perform well, e.g., deep-learning approaches.                                                                In this work, we introduce a program synthesis method, namely VRDSynth, to automatically generate programs to extract entity relations from multilingual VRDs. Two key novelties, which empower VRDSynth to tackle flexible layouts while requiring no pre-training data for extracting entity relations, include: (1) a new domain-specific language (DSL) to effectively capture the spatial and textual relations between document entities, and (2) a novel synthesis algorithm that makes use of frequent spatial relations between entities to construct initial programs, equivalent reduction to prune the search space, and a combination of positive, negative, and mutually exclusive programs to improve the coverage of programs.                                                                We evaluate our method on two popular VRD understanding benchmarks, namely FUNSD and XFUND, on the semantic entity linking task, consisting of 1,600 forms in 8 different languages. Experiments show that VRDSynth, despite having no prior pre-training data, outperforms the state-of-the-art pre-trained deep-learning approach, namely LayoutXLM, in 5 out of 8 languages. Noticeably, VRDSynth achieved an improvement of 42\% over LayoutXLM in terms of F1 score on FUNSD while being complementary to LayoutXLM in 7/8 languages. Regarding efficiency, VRDSynth significantly improves the memory footprint required for storage and inference over LayoutXLM (1M and 380MB versus that of 1.48GB and 3GB required by LayoutXLM), while maintaining similar time efficiency despite the speed differences between the languages used for implementation (Python vs C++).},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {704–716},
numpages = {13},
keywords = {Automatic Programming, Information Extraction, Program Synthesis, Programming By Example, Visually-Rich Document},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1145/3534678.3539460,
author = {Yang, Qingping and Cao, Yixuan and Luo, Ping},
title = {Numerical Tuple Extraction from Tables with Pre-training},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539460},
doi = {10.1145/3534678.3539460},
abstract = {Tables are omnipresent on the web and in various vertical domains, storing massive amounts of valuable data. However, the great flexibility in the table layout hinders the machine from understanding this valuable data. In order to unlock and utilize knowledge from tables, extracting data as numerical tuples is the first and critical step. As a form of relational data, numerical tuples have direct and transparent relationships between their elements and are therefore easy for machines to use. Extracting numerical tuples requires a deep understanding of intricate correlations between cells. The correlations are presented implicitly in texts and visual appearances of tables, which can be roughly classified into Hierarchy and Juxtaposition. Although many studies have made considerable progress in data extraction from tables, most of them only consider hierarchical relationships but neglect the juxtapositions. Meanwhile, they only evaluate their methods on relatively small corpora. This paper proposes a new framework to extract numerical tuples from tables and evaluate it on a large test set. Specifically, we convert this task into a relation extraction problem between cells. To represent cells with their intricate correlations in tables, we propose a BERT-based pre-trained language model, TableLM, to encode tables with diverse layouts. To evaluate the framework, we collect a large finance dataset that includes 19,264 tables and 604K tuples. Extensive experiments on the dataset are conducted to demonstrate the superiority of our framework compared to a well-designed baseline.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2233–2241},
numpages = {9},
keywords = {pre-training, tabular representation, tuple extraction},
location = {Washington DC, USA},
series = {KDD '22}
}

@article{10.1145/3728913,
author = {Zhang, Zhiyu and Li, Longxing and Liang, Ruigang and Chen, Kai},
title = {Unlocking Low Frequency Syscalls in Kernel Fuzzing with Dependency-Based RAG},
year = {2025},
issue_date = {July 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {ISSTA},
url = {https://doi.org/10.1145/3728913},
doi = {10.1145/3728913},
abstract = {Most coverage-guided kernel fuzzers test operating system kernels based on syscall sequence synthesis. However, there are still syscalls rarely or not covered (called low frequency syscalls, LFS) in a period of fuzzing, meaning the relevant code branches remain unexplored. This is due to the complex dependencies of the LFS and mutation uncertainty, which makes it difficult for fuzzers to generate corresponding syscall sequences. Since many kernel fuzzers can dynamically learn syscall dependencies from the current corpus based on the choice table mechanism, providing comprehensive and high-quality seeds could help fuzzers cover LFS. However, constructing such seeds relies heavily on expert experience to resolve the syscall dependencies. In this paper, we propose SyzGPT, the first kernel fuzzing framework to automatically generate effective seeds for LFS via Large Language Model (LLM). We leverage a dependency-based retrieval-augmented generation (DRAG) method to unlock the potential of LLM and design a series of steps to improve the effectiveness of the generated seeds. First, SyzGPT automatically extracts syscall dependencies from the existing documentation via LLM. Second, SyzGPT retrieves programs from the fuzzing corpus based on the dependencies to construct adaptive context for LLM. Last, SyzGPT periodically generates and repairs seeds with feedback to enrich the fuzzing corpus for LFS. We propose a novel set of evaluation metrics for seed generation in kernel domain. Our evaluation shows that SyzGPT can generate seeds with a high valid rate of 87.84\% and can be extended to offline and fine-tuned LLMs. Compared to seven state-of-the-art kernel fuzzers, SyzGPT improves code coverage by 17.73\%, LFS coverage by 58.00\%, and vulnerability detection by 323.22\% on average. Besides, SyzGPT independently discovered 26 unknown kernel bugs (10 are LFS-related), with 11 confirmed.},
journal = {Proc. ACM Softw. Eng.},
month = jun,
articleno = {ISSTA038},
numpages = {23},
keywords = {Kernel Fuzzing, RAG, Seed Generation, Syscall Dependency}
}

@inproceedings{10.1145/3638530.3664121,
author = {Guo, Ping and Liu, Fei and Lin, Xi and Zhao, Qingchuan and Zhang, Qingfu},
title = {L-AutoDA: Large Language Models for Automatically Evolving Decision-based Adversarial Attacks},
year = {2024},
isbn = {9798400704956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638530.3664121},
doi = {10.1145/3638530.3664121},
abstract = {In the rapidly evolving field of machine learning, adversarial attacks pose a significant threat to the robustness and security of models. Amongst these, decision-based attacks are particularly insidious due to their nature of requiring only the model's decision output, which makes them notably challenging to counteract. This paper presents L-AutoDA (Large Language Model-based Automated Decision-based Adversarial Attacks), an innovative methodology that harnesses the generative capabilities of large language models (LLMs) to streamline the creation of such attacks. L-AutoDA employs an evolutionary strategy, where iterative interactions with LLMs lead to the autonomous generation of potent attack algorithms, thereby reducing human intervention. The performance of L-AutoDA was evaluated on the CIFAR-10 dataset, where it demonstrated substantial superiority over existing baseline methods in terms of success rate and computational efficiency. Ultimately, our results highlight the formidable utility of language models in crafting adversarial attacks and reveal promising directions for constructing more resilient AI systems.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1846–1854},
numpages = {9},
keywords = {large language models, adversarial attacks, automated algorithm design, evolutionary algorithms},
location = {Melbourne, VIC, Australia},
series = {GECCO '24 Companion}
}

@inproceedings{10.1145/3711896.3736879,
author = {Zhang, Yiqing and Liu, Xiaozhong and Murai, Fabricio},
title = {CLaDMoP: Learning Transferrable Models from Successful Clinical Trials via LLMs},
year = {2025},
isbn = {9798400714542},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711896.3736879},
doi = {10.1145/3711896.3736879},
abstract = {Many existing models for clinical trial outcome prediction are optimized using task-specific loss functions on trial phase-specific data. While this scheme may boost prediction for common diseases and drugs, it can hinder the learning of generalizable representations, leading to more false positives/negatives. To address this limitation, we introduce CLaDMoP, a new pre-training approach for clinical trial outcome prediction, alongside the Successful Clinical Trials dataset (SCT), specifically designed for this task. CLaDMoP leverages a Large Language Model-to encode trials' eligibility criteria-linked to a lightweight Drug-Molecule branch through a novel multi-level fusion technique. To efficiently fuse long embeddings across levels, we incorporate a grouping block, drastically reducing computational overhead. CLaDMoP avoids reliance on task-specific objectives by pre-training on a ''pair matching'' proxy task. Compared to established zero-shot and few-shot baselines, our method significantly improves both PR-AUC and ROC-AUC, especially for phase I and phase II trials. We further evaluate and perform ablation on CLaDMoP after Parameter-Efficient Fine-Tuning, comparing it to state-of-the-art supervised baselines, including MEXA-CTP, on the Trial Outcome Prediction (TOP) benchmark. CLaDMoP achieves up to 10.5\% improvement in PR-AUC and 3.6\% in ROC-AUC, while attaining comparable F1 score to MEXA-CTP, highlighting its potential for clinical trial outcome prediction. Code and SCT dataset can be downloaded from https://github.com/murai-lab/CLaDMoP.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2},
pages = {3901–3911},
numpages = {11},
keywords = {clinical trial outcome prediction, llms, multi-modal data fusion, representation learning, self-supervised pre-training},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3604237.3627721,
author = {Kim, Seonmi and Kim, Seyoung and Kim, Yejin and Park, Junpyo and Kim, Seongjin and Kim, Moolkyeol and Sung, Chang Hwan and Hong, Joohwan and Lee, Yongjae},
title = {LLMs Analyzing the Analysts: Do BERT and GPT Extract More Value from Financial Analyst Reports?},
year = {2023},
isbn = {9798400702402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604237.3627721},
doi = {10.1145/3604237.3627721},
abstract = {This paper examines the use of Large Language Models (LLMs), specifically BERT-based models and GPT-3.5, in the sentiment analysis of Korean financial analyst reports. Due to the specialized language in these reports, traditional natural language processing techniques often prove insufficient, making LLMs a better alternative. These models are capable of understanding the complexity and subtlety of the language, allowing for a more nuanced interpretation of the data. We focus our study on the extraction of sentiment scores from these reports, using them to construct and test investment strategies. Given that Korean analyst reports present unique linguistic challenges and a significant ‘buy’ recommendation bias, we employ LLMs fine-tuned for the Korean language and Korean financial texts. The aim of this study is to investigate and compare the effectiveness of LLMs in enhancing the sentiment analysis of financial reports, and subsequently utilize the sentiment scores to construct and test investment strategies, thereby evaluating these models’ potential in extracting valuable insights from the reports. The code is available at https://github.com/msraask3.},
booktitle = {Proceedings of the Fourth ACM International Conference on AI in Finance},
pages = {383–391},
numpages = {9},
location = {Brooklyn, NY, USA},
series = {ICAIF '23}
}

@article{10.1145/3658147,
author = {He, Kai and Yao, Kaixin and Zhang, Qixuan and Yu, Jingyi and Liu, Lingjie and Xu, Lan},
title = {DressCode: Autoregressively Sewing and Generating Garments from Text Guidance},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3658147},
doi = {10.1145/3658147},
abstract = {Apparel's significant role in human appearance underscores the importance of garment digitalization for digital human creation. Recent advances in 3D content creation are pivotal for digital human creation. Nonetheless, garment generation from text guidance is still nascent. We introduce a text-driven 3D garment generation framework, DressCode, which aims to democratize design for novices and offer immense potential in fashion design, virtual try-on, and digital human creation. We first introduce SewingGPT, a GPT-based architecture integrating cross-attention with text-conditioned embedding to generate sewing patterns with text guidance. We then tailor a pre-trained Stable Diffusion to generate tile-based Physically-based Rendering (PBR) textures for the garments. By leveraging a large language model, our framework generates CG-friendly garments through natural language interaction. It also facilitates pattern completion and texture editing, streamlining the design process through user-friendly interaction. This framework fosters innovation by allowing creators to freely experiment with designs and incorporate unique elements into their work. With comprehensive evaluations and comparisons with other state-of-the-art methods, our method showcases superior quality and alignment with input prompts. User studies further validate our high-quality rendering results, highlighting its practical utility and potential in production settings. Our project page is https://IHe-KaiI.github.io/DressCode/.},
journal = {ACM Trans. Graph.},
month = jul,
articleno = {72},
numpages = {13},
keywords = {garment generation, sewing patterns, autoregressive model}
}

@inproceedings{10.1145/3696410.3714790,
author = {Chen, Eason and Tang, Xinyi and Xiao, Zimo and Li, Chuangji and Li, Shizhuo and Wu, Tingguan and Wang, Siyun and Chalkias, Kostas Kryptos},
title = {SuiGPT MAD: Move AI Decompiler to Improve Transparency and Auditability on Non-Open-Source Blockchain Smart Contract},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714790},
doi = {10.1145/3696410.3714790},
abstract = {The vision of Web3 is to improve user control over data and assets, but one challenge that complicates this vision is the prevalence of non-transparent, scam-prone applications and vulnerable smart contracts that put Web3 users at risk. While code audits are one solution to this problem, the lack of smart contracts source code on many blockchain platforms, such as Sui, hinders the ease of auditing. A promising approach to this issue is the use of a decompiler to reverse-engineer smart contract bytecode. However, existing decompilers for Sui produce code that is difficult to understand and cannot be directly recompiled. To address this, we developed the SuiGPT Move AI Decompiler (MAD), a Large Language Model (LLM)-powered web application that decompiles smart contract bytecodes on Sui into logically correct, human-readable, and re-compilable source code with prompt engineering. Our evaluation shows that MAD's output successfully passes original unit tests and achieves a 73.33\% recompilation success rate on real-world smart contracts. Additionally, newer models tend to deliver improved performance, suggesting that MAD's approach will become increasingly effective as LLMs continue to advance. In a user study involving 12 developers, we found that MAD significantly reduced the auditing workload compared to using traditional decompilers. Participants found MAD's outputs comparable to the original source code, improving accessibility for understanding and auditing non-open-source smart contracts. Through qualitative interviews with these developers and Web3 projects, we further discussed the strengths and concerns of MAD. MAD has practical implications for blockchain smart contract transparency, auditing, and education. It empowers users to easily and independently review and audit non-open-source smart contracts, fostering accountability and decentralization. Moreover, MAD's methodology could potentially extend to other smart contract languages, like Solidity, further enhancing Web3 transparency.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {1567–1576},
numpages = {10},
keywords = {auditing tools, large language models, move, prompt engineering, smart contract, sui, transparency, web applications, web3},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.5555/3643142.3643346,
author = {Bellamy, Elijah and Beskow, David M.},
title = {Using Simulated Narratives to Understand Attribution in the Information Dimension},
year = {2024},
isbn = {9798350369663},
publisher = {IEEE Press},
abstract = {Conducting a measured response to cyber or information attack is predicated on attribution. When these operations are conducted covertly or through proxies, uncertainty in attribution limits response options. To increase attribution certainty in the information dimension, the authors have developed a suite of supervised machine learning models that attribute an emerging narrative to historical narratives from known actors. These models were first developed on simulated narratives produced with a Large Language Model. Once the supervised classification models were developed and tested on the simulated narratives, they are evaluated on known actor social media narratives from three known actors. The attribution models are language agnostic and offer one-vs-rest and multi-class options. All models performed at relatively high accuracy and can provide decision support for cyber response decisions.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {2460–2469},
numpages = {10},
location = {San Antonio, Texas, USA},
series = {WSC '23}
}

@inproceedings{10.1145/3510003.3510125,
author = {Chai, Yitian and Zhang, Hongyu and Shen, Beijun and Gu, Xiaodong},
title = {Cross-domain deep code search with meta learning},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510125},
doi = {10.1145/3510003.3510125},
abstract = {Recently, pre-trained programming language models such as CodeBERT have demonstrated substantial gains in code search. Despite their success, they rely on the availability of large amounts of parallel data to fine-tune the semantic mappings between queries and code. This restricts their practicality in domain-specific languages with relatively scarce and expensive data. In this paper, we propose CDCS, a novel approach for domain-specific code search. CDCS employs a transfer learning framework where an initial program representation model is pre-trained on a large corpus of common programming languages (such as Java and Python), and is further adapted to domain-specific languages such as Solidity and SQL. Unlike cross-language CodeBERT, which is directly fine-tuned in the target language, CDCS adapts a few-shot meta-learning algorithm called MAML to learn the good initialization of model parameters, which can be best reused in a domain-specific language. We evaluate the proposed approach on two domain-specific languages, namely Solidity and SQL, with model transferred from two widely used languages (Python and Java). Experimental results show that CDCS significantly outperforms conventional pre-trained code models that are directly fine-tuned in domain-specific languages, and it is particularly effective for scarce data.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {487–498},
numpages = {12},
keywords = {code search, deep learning, few-shot learning, meta learning, pre-trained code models},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

